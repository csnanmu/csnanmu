{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csnanmu/csnanmu/blob/main/DL4H_Team_136.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GOxzj48J8hp"
      },
      "source": [
        "# DL4H_Team_136 Gimlet: A unified graph-text model for instruction-based molecule zero-shot learning\n",
        "\n",
        "### Team Member\n",
        "* Nan Mu(nanmu2@illinois.edu)\n",
        "* Ruqian Cheng (ruqianc2@illinois.edu)\n",
        "\n",
        "Video Representation: https://mediaspace.illinois.edu/media/t/1_7rhinu8d\n",
        "\n",
        "Link to the google drive folder contains dataset and colab:\n",
        "\n",
        "https://drive.google.com/drive/folders/18GAdnJBlnigaF5ZZ0_m8mG5IOE1ZhI5N?usp=sharing\n",
        "\n",
        "This colab can be run end to end after mount this google drive folder to colab runtime.\n",
        "\n",
        "\n",
        "Link to this colab in google drive:\n",
        "\n",
        "https://colab.research.google.com/drive/1bhVXhgOTuEDiygYUOWVXq_aU3imLvubc?usp=sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0sNuMePBXx"
      },
      "source": [
        "# Introduction\n",
        "*   Background of the problem\n",
        "\n",
        "\n",
        "Predicting molecular properties is a critical yet challenging aspect of drug discovery, hindered significantly by the scarcity of labeled data, which typically comes from costly and time-consuming laboratory experiments. Current models are often inadequate in settings where labeled data is minimal, particularly in zero-shot scenarios where the model must perform tasks using natural language instructions without prior specific training. This challenge is compounded by the limitations of existing models that struggle to effectively integrate complex instructions with the intricate details of molecular graphs.\n",
        "\n",
        "*   Paper explanation\n",
        "\n",
        "\n",
        "The paper presents GIMLET, an innovative model that integrates natural language instructions with molecular graph data to predict molecular properties, thereby minimizing the reliance on extensive labeled datasets. By leveraging a pretraining strategy on a diverse dataset that includes both molecular tasks and corresponding instructions, GIMLET facilitates zero-shot learning, enabling it to predict properties of new molecules without direct prior exposure. This approach not only addresses the issue of data scarcity but also streamlines the process of drug discovery and chemical analysis, offering a more efficient pathway through the use of enriched natural language processing and graph analysis techniques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# Scope of Reproducibility:\n",
        "This section outlines the hypothesis to be tested and the corresponding experiments to be conducted.\n",
        "\n",
        "## Hypothesis\n",
        "\n",
        "1. Hypothesis 1: GIMLET model has better performance using few show prompts vs zero shot prompts\n",
        "2. Hypothesis 2: GIMLET model is robust to test against variations of prompts than the original prompts it was trained on.\n",
        "\n",
        "\n",
        "## Planned Experiments\n",
        "1. Compare the original GIMLET model with Few shots (4 shot, 8 shot) trained models. For a dataset that GIMLET model doesn't pre-trained for, split into training and test set. Using training set to train 4/8 prompts per molecule models for each molecule. Compare the performance on the test set.\n",
        "2. Augment existing prompts in the test set using rewrite, expand, detail, shorten transformations. Test the performace of the models on the new test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# Methodology\n",
        "\n",
        "The methodology consists of run-able codes with necessary annotations to show the experiment executed for testing the hypotheses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PIAYLHK2uwl"
      },
      "source": [
        "## Environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNNc7QYI225K"
      },
      "source": [
        "### Python Version\n",
        "\n",
        "Python version 3.10.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bylKn1ES24C9",
        "outputId": "5c73cdc7-08a9-474a-b372-01fdca947239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O4Bt9CvkUx2"
      },
      "source": [
        "\n",
        "### Import Python Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgJt9fQdklc7"
      },
      "source": [
        "#### Install Missing Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jzrldK0kMvO",
        "outputId": "c22c4edc-b656-4473-9eff-6c6e6ff75c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.6)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.10/dist-packages (1.3.6)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.11.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.0.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.4.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt22cu121)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt22cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.25.2)\n",
            "Requirement already satisfied: torch_geometric==1.7.2 in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (4.66.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (1.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (3.3)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (0.16)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (1.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (2.0.3)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (7.0.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (3.1.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==1.7.2) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==1.7.2) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->torch_geometric==1.7.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch_geometric==1.7.2) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch_geometric==1.7.2) (2024.1)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->torch_geometric==1.7.2) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==1.7.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==1.7.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==1.7.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==1.7.2) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==1.7.2) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==1.7.2) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib->torch_geometric==1.7.2) (1.16.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.29.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: commentjson in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: lark-parser<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from commentjson) (0.7.8)\n"
          ]
        }
      ],
      "source": [
        "! pip install pytorch-lightning wandb rdkit ogb datasets\n",
        "import torch\n",
        "VERSION = torch.__version__\n",
        "! pip install torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-{VERSION}.html\n",
        "! pip install torch_geometric==1.7.2\n",
        "! pip install transformers[torch]\n",
        "! pip install commentjson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y10QDAP6kwsK"
      },
      "source": [
        "#### Import Python Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfqeBl16kzhL"
      },
      "outputs": [],
      "source": [
        "import commentjson\n",
        "import datasets\n",
        "import math\n",
        "import logging\n",
        "import os\n",
        "import os.path as osp\n",
        "import sys\n",
        "import warnings\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import setuptools\n",
        "import faulthandler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import time\n",
        "import pyximport\n",
        "import argparse\n",
        "\n",
        "import pickle\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import AllChem\n",
        "from multiprocessing import Pool\n",
        "# import argparse\n",
        "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
        "\n",
        "\n",
        "from collections.abc import Mapping, Sequence\n",
        "from dataclasses import dataclass, field\n",
        "from datasets import load_dataset,DatasetDict\n",
        "from itertools import chain\n",
        "from typing import Optional,Tuple, List\n",
        "from sklearn.metrics import (roc_auc_score,f1_score,confusion_matrix,r2_score)\n",
        "from tqdm import tqdm\n",
        "from ogb.utils import smiles2graph\n",
        "from rdkit import Chem\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    CONFIG_MAPPING,\n",
        "    MODEL_FOR_MASKED_LM_MAPPING,\n",
        "    AutoConfig,\n",
        "    AutoModelForMaskedLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    HfArgumentParser,\n",
        "    T5ForConditionalGeneration,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    is_torch_tpu_available,\n",
        "    set_seed,\n",
        ")\n",
        "from transformers.modeling_outputs import (\n",
        "    BaseModelOutput,\n",
        "    Seq2SeqLMOutput,\n",
        "    BaseModelOutputWithPastAndCrossAttentions\n",
        ")\n",
        "from transformers.models.t5.modeling_t5 import T5Stack\n",
        "from transformers.tokenization_utils_base import BatchEncoding\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "from transformers.utils import check_min_version, send_example_telemetry, logging\n",
        "from transformers.utils.versions import require_version\n",
        "from transformers import AutoTokenizer, PretrainedConfig\n",
        "\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "from torch_geometric.data import (Data, Batch, InMemoryDataset, download_url,\n",
        "                                  extract_gz)\n",
        "from torch_geometric.datasets.molecule_net import x_map,e_map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oChC4qHl_uw"
      },
      "outputs": [],
      "source": [
        "logger = logging.get_logger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlv6knX04FiY"
      },
      "source": [
        "### Mount Notebook to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arnoXC1VgRol",
        "outputId": "a91ab913-2b12-47f1-bc48-df3c8adb9f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep_G6p8_43ga",
        "outputId": "0824b663-b2ea-44d0-89c5-70af4e994d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ablated_prompt_downstream_task.json    chembl_pretraining.parquet  tox21.parquet\n",
            "augmented_prompt_downstream_task.json  hiv.parquet\t\t   toxcast.parquet\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/MyDrive/DL4H_Team_136/chembl_dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NbPHUTMbkD3"
      },
      "source": [
        "##  Data\n",
        "Data includes raw data (ChEMBL), source of the data, descriptive statistics and data processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzVUQS0CHry0"
      },
      "source": [
        "### Source of the Data\n",
        "\n",
        "The dataset is sourced from ChEMBL, a large-scale bioactivity database containing information about bioactive drug-like small molecules. It includes the chemical structures of molecules, their biological activities, calculated properties, and drug targets. The dataset was initially downloaded from http://bioinf.jku.at/research/lsc/chembl20/. The downloaded raw data includes the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtkqswCktpBk",
        "outputId": "c287d053-f787-4234-b942-197555226bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checksums.md5\t     ecfp6.pckl\t\t      labelsWeakHard.mtx\t  samples.pckl\n",
            "chembl20LSTM.pckl    folds0.pckl\t      labelsWeakHard.pckl\t  semi.pckl\n",
            "chembl20Smiles.pckl  labelsHard.pckl\t      labelsWeakHard.targetNames  static.pckl\n",
            "dfs8.pckl\t     labelsWeakHard.cmpNames  mol_cluster.csv\t\t  tox.pckl\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/MyDrive/DL4H_Team_136/chembl_raw\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NivzQfQY1M-H"
      },
      "source": [
        "### Data Processing\n",
        "\n",
        "1. The transformation process of the ChEMBL dataset:\n",
        "* Remove entries with missing data (None values).\n",
        "* Exclude molecules with two or fewer non-hydrogen atoms.\n",
        "* For compounds with multiple components, keep only the largest molecule.\n",
        "* Filter out molecules outside the desired molecular weight range (below 50 or above 900).\n",
        "\n",
        "2. Map ChEMBL IDs to STRING IDs, facilitating a bridge between ChEMBL's biochemical data and STRING's protein interaction data. The process involves:\n",
        "* Map Targets to Indices: Create a list from target annotation indices and write a mapping of each target to a corresponding index into a new file. This step organizes the data for easy reference.\n",
        "* Verify SMILES Strings: Open a file containing SMILES strings and another with molecular representations. By iterating over these, the script checks that each SMILES string correctly matches its molecular structure as represented by RDKit objects, ensuring the data's accuracy and consistency.\n",
        "\n",
        "3. Simplifies the ChEMBL dataset:\n",
        "* Create Connected Subsets: Generate ChEMBL-Dense-{10, 50, 100} datasets based on connectivity.\n",
        "* Filtering: Keep only well-connected drug and assay tasks.\n",
        "* Resulting Datasets: Obtain three refined datasets with specific connectivity levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ibjFoT20YDY"
      },
      "source": [
        "### Descriptive Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba5zNvsXx4H6"
      },
      "source": [
        "We chose to focus on a specific task within the dataset known as Tox21, which examines the potential of certain molecules to engage the antioxidant response element (ARE) signaling pathway. This pathway plays a vital role in mitigating oxidative stress, a factor involved in a wide range of diseases from cancer to neurodegeneration. The objective is to determine whether a given molecule acts as an agonist to the ARE signaling pathway."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description of Tox21 dataset:\n",
        "\n",
        "1. graph: Contains SMILES notations representing the molecular structures.\n",
        "2. text: Descriptive text providing context or instructions related to the molecule's biological interactions.\n",
        "3. label: Indicates whether the molecule acts as an agonist (Yes) or not (No) to the biological target described in the text.\n",
        "4. dataset_name: Names the dataset, 'tox21' in this case, which focuses on understanding chemical effects on human health.\n",
        "5. task_index: An identifier for the specific biological assay within the dataset.\n",
        "6. molecule_index: A unique identifier for each molecule in the dataset.\n",
        "7. split: Designates the subset (train, validation, test) to which the data point belongs, for use in model training and evaluation."
      ],
      "metadata": {
        "id": "Hgw_mvl8U4-v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT_YRYhk5BMO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "tox21 = pd.read_parquet('/content/drive/MyDrive/DL4H_Team_136/chembl_dataset/tox21.parquet', engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wwR9gU2p5If5",
        "outputId": "32986cdb-9ce0-4d74-d5b3-51348a93973b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  graph  \\\n",
              "0          CCOc1ccc2nc(S(N)(=O)=O)sc2c1   \n",
              "1             CCN1C(=O)NC(c2ccccc2)C1=O   \n",
              "2       CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C   \n",
              "3             CC(O)(P(=O)(O)O)P(=O)(O)O   \n",
              "4  CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C   \n",
              "\n",
              "                                                text label dataset_name  \\\n",
              "0  [Estrogen receptor alpha (ER aplha) is Nuclear...    No        tox21   \n",
              "1  [Estrogen receptor alpha (ER aplha) is Nuclear...    No        tox21   \n",
              "2  [Estrogen receptor alpha (ER aplha) is Nuclear...    No        tox21   \n",
              "3  [Estrogen receptor alpha (ER aplha) is Nuclear...    No        tox21   \n",
              "4  [Estrogen receptor alpha (ER aplha) is Nuclear...    No        tox21   \n",
              "\n",
              "  task_index molecule_index  split  \n",
              "0          0              0  train  \n",
              "1          0              1  train  \n",
              "2          0              3  train  \n",
              "3          0              4  train  \n",
              "4          0              5  train  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36571fa9-2978-4b69-8285-adf1d68c90cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>graph</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>task_index</th>\n",
              "      <th>molecule_index</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
              "      <td>[Estrogen receptor alpha (ER aplha) is Nuclear...</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
              "      <td>[Estrogen receptor alpha (ER aplha) is Nuclear...</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C</td>\n",
              "      <td>[Estrogen receptor alpha (ER aplha) is Nuclear...</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
              "      <td>[Estrogen receptor alpha (ER aplha) is Nuclear...</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C</td>\n",
              "      <td>[Estrogen receptor alpha (ER aplha) is Nuclear...</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36571fa9-2978-4b69-8285-adf1d68c90cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36571fa9-2978-4b69-8285-adf1d68c90cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36571fa9-2978-4b69-8285-adf1d68c90cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80cff035-4f2e-43ff-a3bd-efbc915466d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80cff035-4f2e-43ff-a3bd-efbc915466d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80cff035-4f2e-43ff-a3bd-efbc915466d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tox21",
              "summary": "{\n  \"name\": \"tox21\",\n  \"rows\": 77946,\n  \"fields\": [\n    {\n      \"column\": \"graph\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7831,\n        \"samples\": [\n          \"COc1cccc(C=O)c1\",\n          \"CCCSP(=O)(OCC)Oc1ccc(Br)cc1Cl\",\n          \"CC(C)(C)C(=O)C1C(=O)c2ccccc2C1=O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"tox21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"task_index\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"molecule_index\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7831,\n        \"samples\": [\n          \"1219\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "# Display the first five entries for reference\n",
        "tox21.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWSJlLEazG3e",
        "outputId": "49b83674-6af7-44a7-b59a-71ee5a8d8fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Observations: 77946\n",
            "Training Set Size: 63733\n",
            "Validation Set Size: 7144\n",
            "Test Set Size: 7069\n",
            "Label Distribution: label\n",
            "No     72084\n",
            "Yes     5862\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Calculate basic statistics\n",
        "total_observations = tox21.shape[0]\n",
        "train_split_size = tox21[tox21['split'] == 'train'].shape[0]\n",
        "validation_split_size = tox21[tox21['split'] == 'valid'].shape[0]  # if 'valid' is a split type\n",
        "test_split_size = tox21[tox21['split'] == 'test'].shape[0]         # if 'test' is a split type\n",
        "label_distribution = tox21['label'].value_counts()\n",
        "\n",
        "# Print the basic statistics\n",
        "print(f\"Total Observations: {total_observations}\")\n",
        "print(f\"Training Set Size: {train_split_size}\")\n",
        "print(f\"Validation Set Size: {validation_split_size}\")\n",
        "print(f\"Test Set Size: {test_split_size}\")\n",
        "print(\"Label Distribution:\", label_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "VsZkji_ezcDf",
        "outputId": "717e9752-47ca-4a74-e2cb-b0ea0ab0a4d4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Labels Distribution\n",
        "tox21.groupby('label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.title('Distribution of Labels in Tox21 Dataset')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "l82y6WWqzeJn",
        "outputId": "b9ccc902-ab2b-46bc-a326-df890b249724"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Split Distribution\n",
        "tox21.groupby('split').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.title('Distribution of Split in Tox21 Dataset')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtSUBWI8kGnv"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AI_JD-6j-mN"
      },
      "outputs": [],
      "source": [
        "tokenizer_kwargs = {\n",
        "        \"cache_dir\": None,\n",
        "        \"use_fast\": True,\n",
        "        \"revision\": 'main',\n",
        "        \"use_auth_token\": None,\n",
        "    }\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", **tokenizer_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH67wGUMocJv"
      },
      "source": [
        "### Data Collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3iS4UTWoi94"
      },
      "outputs": [],
      "source": [
        "def tokenize_function_gimlet(examples, tokenizer, text_column_name, padding, max_seq_length, rich_features, transform_in_collator):\n",
        "    # Remove empty lines\n",
        "    # examples[text_column_name] = [line for line in examples[text_column_name] if len(line) > 0 and not line.isspace()]\n",
        "    text = tokenizer(\n",
        "        examples[text_column_name] if isinstance(examples[text_column_name],str) else examples[text_column_name][0], # if examples[text_column_name] is list\n",
        "        padding=padding,\n",
        "        truncation=True,\n",
        "        max_length=max_seq_length,\n",
        "        # We use this option because DataCollatorForLanguageModeling (see below) is more efficient when it\n",
        "        # receives the `special_tokens_mask`.\n",
        "        return_special_tokens_mask=True,\n",
        "    )\n",
        "    labels = tokenizer(\n",
        "        str(examples['label']),\n",
        "        padding=padding,\n",
        "        truncation=True,\n",
        "        max_length=max_seq_length,\n",
        "        # We use this option because DataCollatorForLanguageModeling (see below) is more efficient when it\n",
        "        # receives the `special_tokens_mask`.\n",
        "        return_special_tokens_mask=True,\n",
        "    )\n",
        "\n",
        "\n",
        "    graph_data = examples['graph']\n",
        "\n",
        "    return {'graph': graph_data,\n",
        "            'input_ids': text.data['input_ids'],\n",
        "            'attention_mask': text.data['attention_mask'],\n",
        "            'special_tokens_mask': text.data['special_tokens_mask'],\n",
        "            'labels': labels.data['input_ids']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK9wXnI7Nn1h",
        "outputId": "3e66f7dd-1af7-4ab8-d020-ed15e1cbf110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cython extension is already loaded. To reload it, use:\n",
            "  %reload_ext cython\n"
          ]
        }
      ],
      "source": [
        "%load_ext cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LttvFZjpNqSx"
      },
      "outputs": [],
      "source": [
        "%%cython\n",
        "import cython\n",
        "from cython.parallel cimport prange, parallel\n",
        "cimport numpy\n",
        "import numpy\n",
        "\n",
        "def floyd_warshall(adjacency_matrix):\n",
        "\n",
        "    (nrows, ncols) = adjacency_matrix.shape\n",
        "    assert nrows == ncols\n",
        "    cdef unsigned int n = nrows\n",
        "\n",
        "    adj_mat_copy = adjacency_matrix.astype(long, order='C', casting='safe', copy=True)\n",
        "    assert adj_mat_copy.flags['C_CONTIGUOUS']\n",
        "    cdef numpy.ndarray[long, ndim=2, mode='c'] M = adj_mat_copy\n",
        "    cdef numpy.ndarray[long, ndim=2, mode='c'] path = -1 * numpy.ones([n, n], dtype=numpy.int64)\n",
        "\n",
        "    cdef unsigned int i, j, k\n",
        "    cdef long M_ij, M_ik, cost_ikkj\n",
        "    cdef long* M_ptr = &M[0,0]\n",
        "    cdef long* M_i_ptr\n",
        "    cdef long* M_k_ptr\n",
        "\n",
        "    # set unreachable nodes distance to 510\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                M[i][j] = 0\n",
        "            elif M[i][j] == 0:\n",
        "                M[i][j] = 510\n",
        "\n",
        "    # floyed algo\n",
        "    for k in range(n):\n",
        "        M_k_ptr = M_ptr + n*k\n",
        "        for i in range(n):\n",
        "            M_i_ptr = M_ptr + n*i\n",
        "            M_ik = M_i_ptr[k]\n",
        "            for j in range(n):\n",
        "                cost_ikkj = M_ik + M_k_ptr[j]\n",
        "                M_ij = M_i_ptr[j]\n",
        "                if M_ij > cost_ikkj:\n",
        "                    M_i_ptr[j] = cost_ikkj\n",
        "                    path[i][j] = k\n",
        "\n",
        "    # set unreachable path to 510\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if M[i][j] >= 510:\n",
        "                path[i][j] = 510\n",
        "                M[i][j] = 510\n",
        "\n",
        "    return M, path\n",
        "\n",
        "\n",
        "def get_all_edges(path, i, j):\n",
        "    cdef int k = path[i][j]\n",
        "    if k == -1:\n",
        "        return []\n",
        "    else:\n",
        "        return get_all_edges(path, i, k) + [k] + get_all_edges(path, k, j)\n",
        "\n",
        "\n",
        "def gen_edge_input(max_dist, path, edge_feat):\n",
        "\n",
        "    (nrows, ncols) = path.shape\n",
        "    assert nrows == ncols\n",
        "    cdef unsigned int n = nrows\n",
        "    cdef unsigned int max_dist_copy = max_dist\n",
        "\n",
        "    path_copy = path.astype(long, order='C', casting='safe', copy=True)\n",
        "    edge_feat_copy = edge_feat.astype(long, order='C', casting='safe', copy=True)\n",
        "    assert path_copy.flags['C_CONTIGUOUS']\n",
        "    assert edge_feat_copy.flags['C_CONTIGUOUS']\n",
        "\n",
        "    cdef numpy.ndarray[long, ndim=4, mode='c'] edge_fea_all = -1 * numpy.ones([n, n, max_dist_copy, edge_feat.shape[-1]], dtype=numpy.int64)\n",
        "    cdef unsigned int i, j, k, num_path, cur\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                continue\n",
        "            if path_copy[i][j] == 510:\n",
        "                continue\n",
        "            path = [i] + get_all_edges(path_copy, i, j) + [j]\n",
        "            num_path = len(path) - 1\n",
        "            for k in range(num_path):\n",
        "                edge_fea_all[i, j, k, :] = edge_feat_copy[path[k], path[k+1], :]\n",
        "\n",
        "    return edge_fea_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k9uVJ_WNunw"
      },
      "outputs": [],
      "source": [
        "def convert_to_single_emb(x, offset: int = 512):\n",
        "    feature_num = x.shape[1] if len(x.shape) > 1 else 1\n",
        "    feature_offset = (1 + np.arange(0, feature_num * offset, offset)).astype(\"long\")\n",
        "    x = x + feature_offset\n",
        "    return x\n",
        "\n",
        "def graphormer_data_transform_tensor(item,rich_features=False):\n",
        "    if 'node_feat' in item and 'edge_feat' in item:\n",
        "        edge_attr, edge_index, x = item['edge_feat'].long(), item['edge_index'].long(), item['node_feat'].long()\n",
        "    elif hasattr(item, 'x') and hasattr(item, 'edge_attr'):\n",
        "        edge_attr, edge_index, x = item.edge_attr.long(), item.edge_index.long(), item.x.long()\n",
        "    else:\n",
        "        raise ValueError('item does not have expected keys or properties')\n",
        "\n",
        "    if not rich_features:\n",
        "        x = x[:,0:2]\n",
        "        edge_attr = edge_attr[:,0:2]\n",
        "\n",
        "\n",
        "    N = x.size(0)\n",
        "    x = convert_to_single_emb(x)\n",
        "\n",
        "    # node adj matrix [N, N] bool\n",
        "    adj = torch.zeros([N, N], dtype=torch.bool)\n",
        "    adj[edge_index[0, :], edge_index[1, :]] = True\n",
        "\n",
        "    # edge feature here\n",
        "    if len(edge_attr.size()) == 1:\n",
        "        edge_attr = edge_attr[:, None]\n",
        "    attn_edge_type = torch.zeros([N, N, edge_attr.size(-1)], dtype=torch.long)\n",
        "    attn_edge_type[edge_index[0, :], edge_index[1, :]] = (\n",
        "        convert_to_single_emb(edge_attr) + 1\n",
        "    )\n",
        "\n",
        "    shortest_path_result, path = floyd_warshall(adj.numpy())\n",
        "    max_dist = np.amax(shortest_path_result)\n",
        "    edge_input = gen_edge_input(max_dist, path, attn_edge_type.numpy())\n",
        "    spatial_pos = torch.from_numpy((shortest_path_result)).long()\n",
        "    attn_bias = torch.zeros([N + 1, N + 1], dtype=torch.float)  # with graph token\n",
        "\n",
        "    # combine\n",
        "    item.x = x\n",
        "    item.attn_bias = attn_bias\n",
        "    item.attn_edge_type = attn_edge_type\n",
        "    item.spatial_pos = spatial_pos\n",
        "    item.in_degree = adj.long().sum(dim=1).view(-1)\n",
        "    item.out_degree = item.in_degree  # for undirected graph\n",
        "    item.edge_input = torch.from_numpy(edge_input).long()\n",
        "\n",
        "    return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWcm5DC_pw9z"
      },
      "outputs": [],
      "source": [
        "def pad_1d_unsqueeze(x, padlen):\n",
        "    x = x + 1  # pad id = 0\n",
        "    xlen = x.size(0)\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen], dtype=x.dtype)\n",
        "        new_x[:xlen] = x\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_2d_unsqueeze(x, padlen):\n",
        "    x = x + 1  # pad id = 0\n",
        "    xlen, xdim = x.size()\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen, xdim], dtype=x.dtype)\n",
        "        new_x[:xlen, :] = x\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_attn_bias_unsqueeze(x, padlen):\n",
        "    xlen = x.size(0)\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen, padlen], dtype=x.dtype).fill_(float(\"-inf\"))\n",
        "        new_x[:xlen, :xlen] = x\n",
        "        new_x[xlen:, :xlen] = 0\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_edge_type_unsqueeze(x, padlen):\n",
        "    xlen = x.size(0)\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen, padlen, x.size(-1)], dtype=x.dtype)\n",
        "        new_x[:xlen, :xlen, :] = x\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_spatial_pos_unsqueeze(x, padlen):\n",
        "    x = x + 1\n",
        "    xlen = x.size(0)\n",
        "    if xlen < padlen:\n",
        "        new_x = x.new_zeros([padlen, padlen], dtype=x.dtype)\n",
        "        new_x[:xlen, :xlen] = x\n",
        "        x = new_x\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "\n",
        "def pad_3d_unsqueeze(x, padlen1, padlen2, padlen3):\n",
        "\n",
        "    x = x + 1\n",
        "    xlen1, xlen2, xlen3, xlen4 = x.size()\n",
        "    if xlen1 < padlen1 or xlen2 < padlen2 or xlen3 < padlen3:\n",
        "        # new_x = x.new_zeros([padlen1, padlen2, padlen3, xlen4], dtype=x.dtype)\n",
        "        # new_x[:xlen1, :xlen2, :xlen3, :] = x\n",
        "        # x = new_x\n",
        "        x = torch.nn.functional.pad(\n",
        "            x,\n",
        "            pad=(0,0, 0, padlen3 - xlen3,0, padlen2 - xlen2,0, padlen1 - xlen1, ),\n",
        "            mode='constant',\n",
        "            value=0\n",
        "        )\n",
        "\n",
        "    return x.unsqueeze(0)\n",
        "\n",
        "def pad_3d_sequences(xs, padlen1, padlen2, padlen3):\n",
        "    result=torch.zeros([len(xs),padlen1,padlen2,padlen3,xs[0].shape[-1]], dtype=xs[0].dtype)\n",
        "    for i,x in enumerate(xs):\n",
        "        result[i,:x.shape[0], :x.shape[1], :x.shape[2], :]=x+1\n",
        "    return result\n",
        "\n",
        "\n",
        "def pad(encoded_inputs,\n",
        "        pad_token_id,\n",
        "        pad_token_type_id,\n",
        "        max_length: Optional = None,\n",
        "        pad_to_multiple_of: Optional = None,\n",
        "        return_attention_mask: Optional = None,\n",
        "        padding_side='right',\n",
        "        ):\n",
        "    if return_attention_mask is None:\n",
        "        return_attention_mask = \"attention_mask\" in encoded_inputs\n",
        "\n",
        "    required_input = encoded_inputs[list(encoded_inputs.keys())[0]]\n",
        "\n",
        "\n",
        "    if max_length is not None and pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
        "        max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
        "\n",
        "    needs_to_be_padded =  len(required_input) != max_length\n",
        "\n",
        "    # Initialize attention mask if not present.\n",
        "    if return_attention_mask and \"attention_mask\" not in encoded_inputs:\n",
        "        encoded_inputs[\"attention_mask\"] = [1] * len(required_input)\n",
        "\n",
        "    if needs_to_be_padded:\n",
        "        difference = max_length - len(required_input)\n",
        "\n",
        "        if padding_side == \"right\":\n",
        "            if return_attention_mask:\n",
        "                encoded_inputs[\"attention_mask\"] = encoded_inputs[\"attention_mask\"] + [0] * difference\n",
        "            if \"token_type_ids\" in encoded_inputs:\n",
        "                encoded_inputs[\"token_type_ids\"] = (\n",
        "                        encoded_inputs[\"token_type_ids\"] + [pad_token_type_id] * difference\n",
        "                )\n",
        "            if \"special_tokens_mask\" in encoded_inputs:\n",
        "                encoded_inputs[\"special_tokens_mask\"] = encoded_inputs[\"special_tokens_mask\"] + [1] * difference\n",
        "            if \"answer_mask\" in encoded_inputs:\n",
        "                encoded_inputs[\"answer_mask\"] = encoded_inputs[\"answer_mask\"] + [0] * difference\n",
        "            if \"input_ids\" in encoded_inputs:\n",
        "                encoded_inputs['input_ids'] = encoded_inputs['input_ids'] + [pad_token_id] * difference\n",
        "            if \"labels\" in encoded_inputs:\n",
        "                encoded_inputs['labels'] = encoded_inputs['labels'] + [-100] * difference #-100 can makesure that generation loss will not consider padded position\n",
        "            if 'decoder_attention_mask' in encoded_inputs:\n",
        "                encoded_inputs['decoder_attention_mask'] = encoded_inputs['decoder_attention_mask']+[0]*difference\n",
        "\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid padding strategy:\" + str(padding_side))\n",
        "\n",
        "    return encoded_inputs\n",
        "\n",
        "def padding(encoded_inputs,\n",
        "        pad_token_id,\n",
        "        pad_token_type_id,\n",
        "        max_length: Optional = None,\n",
        "        pad_to_multiple_of: Optional = None,\n",
        "        return_attention_mask: Optional = None):\n",
        "    if isinstance(encoded_inputs, (list, tuple)) and isinstance(encoded_inputs[0], Mapping):\n",
        "        encoded_inputs = {key: [example[key] for example in encoded_inputs] for key in encoded_inputs[0].keys()}\n",
        "\n",
        "\n",
        "    required_input = encoded_inputs[list(encoded_inputs.keys())[0]]\n",
        "    if required_input and not isinstance(required_input[0], (list, tuple)):\n",
        "        encoded_inputs = pad(\n",
        "            encoded_inputs,\n",
        "            pad_token_id,\n",
        "            pad_token_type_id,\n",
        "            max_length=max_length,\n",
        "            pad_to_multiple_of=pad_to_multiple_of,\n",
        "            return_attention_mask=return_attention_mask,\n",
        "        )\n",
        "        return BatchEncoding(encoded_inputs, tensor_type='pt')\n",
        "\n",
        "    batch_size = len(required_input)\n",
        "    max_length = max(len(inputs) for inputs in required_input)\n",
        "    # padding_strategy = PaddingStrategy.MAX_LENGTH\n",
        "\n",
        "\n",
        "    batch_outputs = {}\n",
        "    for i in range(batch_size):\n",
        "        inputs = dict((k, v[i]) for k, v in encoded_inputs.items())\n",
        "        outputs = pad(\n",
        "            inputs,\n",
        "            pad_token_id,\n",
        "            pad_token_type_id,\n",
        "            max_length=max_length,\n",
        "            pad_to_multiple_of=pad_to_multiple_of,\n",
        "            return_attention_mask=return_attention_mask,\n",
        "        )\n",
        "\n",
        "        for key, value in outputs.items():\n",
        "            if key not in batch_outputs:\n",
        "                batch_outputs[key] = []\n",
        "            batch_outputs[key].append(value)\n",
        "    return BatchEncoding(batch_outputs, tensor_type='pt')\n",
        "\n",
        "\n",
        "def collator_graph_data(items, max_node=512, multi_hop_max_dist=20, spatial_pos_max=20,transform_in_collator=False,include_y=False,rich_features=False):\n",
        "    items_new=[]\n",
        "    ys=[]\n",
        "\n",
        "    for item in items:\n",
        "\n",
        "        if transform_in_collator:\n",
        "            if isinstance(item,str):\n",
        "                item = smiles2graph(item)\n",
        "\n",
        "        if include_y:\n",
        "            ys.append(item.y)\n",
        "        item_new = Data()\n",
        "        if isinstance(item,Data):\n",
        "            for key in item.keys:\n",
        "                item_new[key]=torch.tensor(item[key]) if (not isinstance(item[key],torch.Tensor))  else item[key]\n",
        "        else:\n",
        "            for key in item.keys():\n",
        "                item_new[key]=torch.tensor(item[key]) if (not isinstance(item[key],torch.Tensor))  else item[key]\n",
        "\n",
        "        if transform_in_collator:\n",
        "            # try:\n",
        "            item_new = graphormer_data_transform_tensor(item_new,rich_features)\n",
        "            # except:\n",
        "            #     print('graph data error')\n",
        "            #     print(item)\n",
        "            #     continue\n",
        "\n",
        "        items_new.append(item_new)\n",
        "\n",
        "\n",
        "\n",
        "    items=items_new\n",
        "    items = [item for item in items if item is not None and item['x'].size(0) <= max_node]\n",
        "    items = [\n",
        "        (\n",
        "            # item.idx,\n",
        "            item.attn_bias,\n",
        "            item.attn_edge_type,\n",
        "            item.spatial_pos,\n",
        "            item.in_degree,\n",
        "            item.out_degree,\n",
        "            item.x,\n",
        "            item.edge_input[:, :, :multi_hop_max_dist, :],\n",
        "            # item.y,\n",
        "        )\n",
        "        for item in items\n",
        "    ]\n",
        "    (\n",
        "        # idxs,\n",
        "        attn_biases,\n",
        "        attn_edge_types,\n",
        "        spatial_poses,\n",
        "        in_degrees,\n",
        "        out_degrees,\n",
        "        xs,\n",
        "        edge_inputs,\n",
        "        # ys,\n",
        "    ) = zip(*items)\n",
        "\n",
        "    for idx, _ in enumerate(attn_biases):\n",
        "        attn_biases[idx][1:, 1:][spatial_poses[idx] >= spatial_pos_max] = float(\"-inf\")\n",
        "\n",
        "    max_node_num = max(i.size(0) for i in xs)\n",
        "    max_dist = max(i.size(-2) for i in edge_inputs)\n",
        "\n",
        "    # y = torch.cat(ys)\n",
        "    x = torch.cat([pad_2d_unsqueeze(i, max_node_num) for i in xs])\n",
        "\n",
        "    # edge_input_padded=[pad_3d_unsqueeze(i, max_node_num, max_node_num, max_dist) for i in edge_inputs]\n",
        "    # edge_input_ori = torch.cat(edge_input_padded\n",
        "    # )\n",
        "    edge_input = pad_3d_sequences(edge_inputs,max_node_num, max_node_num, max_dist)\n",
        "    # assert (edge_input_ori-edge_input).abs().sum()==0\n",
        "\n",
        "    attn_bias = torch.cat(\n",
        "        [pad_attn_bias_unsqueeze(i, max_node_num + 1) for i in attn_biases]\n",
        "    )\n",
        "\n",
        "    attn_edge_type = torch.cat(\n",
        "        [pad_edge_type_unsqueeze(i, max_node_num) for i in attn_edge_types]\n",
        "    )\n",
        "\n",
        "    spatial_pos = torch.cat(\n",
        "        [pad_spatial_pos_unsqueeze(i, max_node_num) for i in spatial_poses]\n",
        "    )\n",
        "\n",
        "    in_degree = torch.cat([pad_1d_unsqueeze(i, max_node_num) for i in in_degrees])\n",
        "\n",
        "\n",
        "    if include_y:\n",
        "        y = torch.cat(ys)\n",
        "        return Data(\n",
        "            # idx=torch.LongTensor(idxs),\n",
        "            attn_bias=attn_bias,\n",
        "            attn_edge_type=attn_edge_type,\n",
        "            spatial_pos=spatial_pos,\n",
        "            in_degree=in_degree,\n",
        "            out_degree=in_degree,  # for undirected graph\n",
        "            x=x,\n",
        "            edge_input=edge_input,\n",
        "            y=y,\n",
        "        )\n",
        "    else:\n",
        "        return Data(\n",
        "            # idx=torch.LongTensor(idxs),\n",
        "            attn_bias=attn_bias,\n",
        "            attn_edge_type=attn_edge_type,\n",
        "            spatial_pos=spatial_pos,\n",
        "            in_degree=in_degree,\n",
        "            out_degree=in_degree,  # for undirected graph\n",
        "            x=x,\n",
        "            edge_input=edge_input,\n",
        "            # y=y,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRQIA__2pzN5"
      },
      "outputs": [],
      "source": [
        "class CollatorForGIMLETLanguageModeling(DataCollatorForLanguageModeling):\n",
        "\n",
        "    def __init__(self,**kwargs):\n",
        "        self.transform_in_collator= kwargs.pop('transform_in_collator')\n",
        "        self.rich_features = kwargs.pop('rich_features')\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def __post_init__(self):\n",
        "\n",
        "        if self.tf_experimental_compile:\n",
        "            import tensorflow as tf\n",
        "\n",
        "            self.tf_mask_tokens = tf.function(self.tf_mask_tokens, jit_compile=True)\n",
        "\n",
        "\n",
        "\n",
        "    def torch_call(self, examples):\n",
        "\n",
        "        #turn list to torch tensor\n",
        "        graph_batch=[]\n",
        "        text_batch=[]\n",
        "        labels_batch=[]\n",
        "        for example_data in examples:\n",
        "            # print(example_data)\n",
        "            graph_data=example_data['graph']\n",
        "            graph_batch.append(graph_data)\n",
        "            text_batch.append({'input_ids': example_data['input_ids'],\n",
        "                    'attention_mask': example_data['attention_mask'],\n",
        "                               })\n",
        "            if 'decoder_attention_mask' in example_data:\n",
        "                labels_batch.append({'labels':example_data['labels'],'decoder_attention_mask':example_data['decoder_attention_mask']})\n",
        "            else:\n",
        "                labels_batch.append({'labels':example_data['labels']})\n",
        "\n",
        "        graph_batch = collator_graph_data(graph_batch,transform_in_collator=self.transform_in_collator,rich_features=self.rich_features)\n",
        "\n",
        "        text_batch = padding(text_batch, self.tokenizer.pad_token_id,self.tokenizer.pad_token_type_id,  pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "        labels_batch = padding(labels_batch, self.tokenizer.pad_token_id, self.tokenizer.pad_token_type_id,\n",
        "                             pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "\n",
        "        batch={'graph': graph_batch,\n",
        "            'input_ids': text_batch.data['input_ids'],\n",
        "            'attention_mask': text_batch.data['attention_mask'],\n",
        "               'labels':labels_batch.data['labels']}\n",
        "        if 'decoder_attention_mask' in labels_batch.data:\n",
        "            batch['decoder_attention_mask'] = labels_batch.data['decoder_attention_mask']\n",
        "\n",
        "        return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UK1hPzakJnf"
      },
      "outputs": [],
      "source": [
        "data_collator = CollatorForGIMLETLanguageModeling(\n",
        "      tokenizer=tokenizer,\n",
        "      transform_in_collator=True,\n",
        "      rich_features=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXPhd0wgoCTG"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU_jN_rMoEEj"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "def load_training_dataset(data_args, training_args, dataset, few_shot = None):\n",
        "  if data_args.train_file=='haitengzhao/molecule_property_instruction' or data_args.validation_file=='haitengzhao/molecule_property_instruction':\n",
        "    raw_datasets={}\n",
        "    dataset_full=load_dataset(\"haitengzhao/molecule_property_instruction\")\n",
        "    # raw_datasets['train']=dataset_full['chembl_pretraining']\n",
        "    # raw_datasets['validation']=dataset_full['chembl_zero_shot']\n",
        "    raw_datasets['train']=dataset_full[dataset].filter(lambda x: x[\"split\"] == \"train\")\n",
        "    raw_datasets['validation']=dataset_full[dataset].filter(lambda x: x[\"split\"] == \"validation\")\n",
        "    raw_datasets['test']=dataset_full[dataset].filter(lambda x: x[\"split\"] == \"test\")\n",
        "    raw_datasets=DatasetDict(raw_datasets)\n",
        "  else:\n",
        "      # dataset_full = pd.read_parquet(data_args.train_file, engine='pyarrow')\n",
        "      dataset_full = load_dataset(\"parquet\",data_files=data_args.train_file)[\"train\"]\n",
        "      raw_datasets={}\n",
        "      raw_datasets['train']=dataset_full.filter(lambda x: x[\"split\"] == \"train\")\n",
        "      raw_datasets['validation']=dataset_full.filter(lambda x: x[\"split\"] == \"validation\")\n",
        "      raw_datasets['test']=dataset_full.filter(lambda x: x[\"split\"] == \"test\")\n",
        "      raw_datasets=DatasetDict(raw_datasets)\n",
        "\n",
        "  if few_shot is not None:\n",
        "    counter = defaultdict(list)\n",
        "    for i, row in enumerate(raw_datasets[\"train\"]):\n",
        "      graph = row[\"graph\"]\n",
        "      if len(counter[graph]) < few_shot:\n",
        "        counter[graph].append(i)\n",
        "    raw_datasets['train'] = raw_datasets['train'].filter(lambda x, i: i in counter[x[\"graph\"]], with_indices=True)\n",
        "\n",
        "\n",
        "  column_names = raw_datasets[\"train\"].column_names\n",
        "  text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
        "\n",
        "  if data_args.max_seq_length is None:\n",
        "    max_seq_length = tokenizer.model_max_length\n",
        "    if max_seq_length > 1024:\n",
        "      logger.warning(f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"\n",
        "                \"Picking 1024 instead. You can change that default value by passing --max_seq_length xxx.\"\n",
        "            )\n",
        "      max_seq_length = 1024\n",
        "  else:\n",
        "      if data_args.max_seq_length > tokenizer.model_max_length:\n",
        "        logger.warning(\n",
        "                f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the\"\n",
        "                f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"\n",
        "            )\n",
        "      max_seq_length = min(data_args.max_seq_length, tokenizer.model_max_length)\n",
        "\n",
        "\n",
        "  padding = \"max_length\" if data_args.pad_to_max_length else False\n",
        "\n",
        "  if data_args.max_train_samples is not None:\n",
        "    max_train_samples = min(len(raw_datasets['train']), data_args.max_train_samples)\n",
        "    raw_datasets['train'] = raw_datasets['train'].shuffle().select(range(max_train_samples))\n",
        "  if data_args.max_eval_samples is not None:\n",
        "    max_eval_samples = min(len(raw_datasets['validation']), data_args.max_eval_samples)\n",
        "    raw_datasets['validation'] = raw_datasets['validation'].shuffle().select(range(max_eval_samples))\n",
        "\n",
        "  tokenize_function=lambda x: tokenize_function_gimlet(examples=x,\n",
        "                                                       tokenizer=tokenizer,\n",
        "                                                       text_column_name=text_column_name,\n",
        "                                                       padding=padding,\n",
        "                                                       max_seq_length=max_seq_length,\n",
        "                                                       rich_features=False,\n",
        "                                                       transform_in_collator=True)\n",
        "  with training_args.main_process_first(desc=\"dataset map tokenization\"):\n",
        "    tokenized_datasets = raw_datasets.map(\n",
        "      tokenize_function,\n",
        "      batched=False,\n",
        "      num_proc=data_args.preprocessing_num_workers,\n",
        "      remove_columns=[text_column_name],\n",
        "      load_from_cache_file=not data_args.overwrite_cache,\n",
        "      desc=\"Running tokenizer on dataset line_by_line\")\n",
        "    # print(tokenized_datasets['train'][0])\n",
        "\n",
        "    if \"train\" not in tokenized_datasets:\n",
        "      raise ValueError(\"--do_train requires a train dataset\")\n",
        "    if \"validation\" not in tokenized_datasets:\n",
        "      raise ValueError(\"--do_eval requires a validation dataset\")\n",
        "    if \"test\" not in tokenized_datasets:\n",
        "      raise ValueError(\"--do_eval requires a test dataset\")\n",
        "\n",
        "    return tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"], tokenized_datasets[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gcpIK1B3dKv"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ens69x3t-R"
      },
      "source": [
        "### Citation\n",
        "\n",
        "@article{zhao2024gimlet, title={Gimlet: A unified graph-text model for instruction-based molecule zero-shot learning}, author={Zhao, Haiteng and Liu, Shengchao and Chang, Ma and Xu, Hannan and Fu, Jie and Deng, Zhihong and Kong, Lingpeng and Liu, Qi}, journal={Advances in Neural Information Processing Systems}, volume={36}, year={2024} }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipR75T_E3xVH"
      },
      "source": [
        "### Original Paper Github Repo\n",
        "\n",
        "https://github.com/zhao-ht/GIMLET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3muyDPFPbozY"
      },
      "source": [
        "###   Model Descriptions\n",
        "  * Model architecture\n",
        "  The GIMLET model use [T5 Small](https://huggingface.co/docs/transformers/en/model_doc/t5) language model as backbone, which is a encoder-decoder based transformer architecture.\n",
        "  It modified transformer attention modeule to encode both molecule graph and instruction token in hidden state h. The modified attention function as following:\n",
        "\n",
        "  A<sub>ij</sub> = (hW<sup>Q</sup>) (hW<sup>K</sup>) / dk + b(i, j), A = softmax(A), Attn(H) = AHW<sup>V</sup>W<sup>Q</sup>\n",
        "\n",
        "\n",
        " * Training objectives:\n",
        "   * Loss Function: Like typical language model, GIMLET(T5 based model) use cross-entropy loss\n",
        "   * Optimizer: GIMLET(T5 based model) use Adam optimizer\n",
        "\n",
        "* Others: The model is using instruction based pretrain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0X8DSkrrZwR"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj_eiGWGmCA1"
      },
      "outputs": [],
      "source": [
        "class FairseqDropout(nn.Module):\n",
        "    def __init__(self, p, module_name=None):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.module_name = module_name\n",
        "        self.apply_during_inference = False\n",
        "\n",
        "    def forward(self, x, inplace: bool = False):\n",
        "        if self.p > 0 and (self.training or self.apply_during_inference):\n",
        "            return F.dropout(x, p=self.p, training=True, inplace=inplace)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def make_generation_fast_(\n",
        "        self,\n",
        "        name: str,\n",
        "        retain_dropout: bool = False,\n",
        "        retain_dropout_modules: Optional[List[str]] = None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        if retain_dropout:\n",
        "            if retain_dropout_modules is not None and self.module_name is None:\n",
        "                logger.warning(\n",
        "                    \"Cannot enable dropout during inference for module {} \"\n",
        "                    \"because module_name was not set\".format(name)\n",
        "                )\n",
        "            elif (\n",
        "                retain_dropout_modules is None  # if None, apply to all modules\n",
        "                or self.module_name in retain_dropout_modules\n",
        "            ):\n",
        "                logger.info(\n",
        "                    \"Enabling dropout during inference for module: {}\".format(name)\n",
        "                )\n",
        "                self.apply_during_inference = True\n",
        "            else:\n",
        "                logger.info(\"Disabling dropout for module: {}\".format(name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg8bwBwxmHpJ"
      },
      "outputs": [],
      "source": [
        "def quant_noise(module, p, block_size):\n",
        "    \"\"\"\n",
        "    Wraps modules and applies quantization noise to the weights for\n",
        "    subsequent quantization with Iterative Product Quantization as\n",
        "    described in \"Training with Quantization Noise for Extreme Model Compression\"\n",
        "\n",
        "    Args:\n",
        "        - module: nn.Module\n",
        "        - p: amount of Quantization Noise\n",
        "        - block_size: size of the blocks for subsequent quantization with iPQ\n",
        "\n",
        "    Remarks:\n",
        "        - Module weights must have the right sizes wrt the block size\n",
        "        - Only Linear, Embedding and Conv2d modules are supported for the moment\n",
        "        - For more detail on how to quantize by blocks with convolutional weights,\n",
        "          see \"And the Bit Goes Down: Revisiting the Quantization of Neural Networks\"\n",
        "        - We implement the simplest form of noise here as stated in the paper\n",
        "          which consists in randomly dropping blocks\n",
        "    \"\"\"\n",
        "\n",
        "    # if no quantization noise, don't register hook\n",
        "    if p <= 0:\n",
        "        return module\n",
        "\n",
        "    # supported modules\n",
        "    assert isinstance(module, (nn.Linear, nn.Embedding, nn.Conv2d))\n",
        "\n",
        "    # test whether module.weight has the right sizes wrt block_size\n",
        "    is_conv = module.weight.ndim == 4\n",
        "\n",
        "    # 2D matrix\n",
        "    if not is_conv:\n",
        "        assert (\n",
        "            module.weight.size(1) % block_size == 0\n",
        "        ), \"Input features must be a multiple of block sizes\"\n",
        "\n",
        "    # 4D matrix\n",
        "    else:\n",
        "        # 1x1 convolutions\n",
        "        if module.kernel_size == (1, 1):\n",
        "            assert (\n",
        "                module.in_channels % block_size == 0\n",
        "            ), \"Input channels must be a multiple of block sizes\"\n",
        "        # regular convolutions\n",
        "        else:\n",
        "            k = module.kernel_size[0] * module.kernel_size[1]\n",
        "            assert k % block_size == 0, \"Kernel size must be a multiple of block size\"\n",
        "\n",
        "    def _forward_pre_hook(mod, input):\n",
        "        # no noise for evaluation\n",
        "        if mod.training:\n",
        "            if not is_conv:\n",
        "                # gather weight and sizes\n",
        "                weight = mod.weight\n",
        "                in_features = weight.size(1)\n",
        "                out_features = weight.size(0)\n",
        "\n",
        "                # split weight matrix into blocks and randomly drop selected blocks\n",
        "                mask = torch.zeros(\n",
        "                    in_features // block_size * out_features, device=weight.device\n",
        "                )\n",
        "                mask.bernoulli_(p)\n",
        "                mask = mask.repeat_interleave(block_size, -1).view(-1, in_features)\n",
        "\n",
        "            else:\n",
        "                # gather weight and sizes\n",
        "                weight = mod.weight\n",
        "                in_channels = mod.in_channels\n",
        "                out_channels = mod.out_channels\n",
        "\n",
        "                # split weight matrix into blocks and randomly drop selected blocks\n",
        "                if mod.kernel_size == (1, 1):\n",
        "                    mask = torch.zeros(\n",
        "                        int(in_channels // block_size * out_channels),\n",
        "                        device=weight.device,\n",
        "                    )\n",
        "                    mask.bernoulli_(p)\n",
        "                    mask = mask.repeat_interleave(block_size, -1).view(-1, in_channels)\n",
        "                else:\n",
        "                    mask = torch.zeros(\n",
        "                        weight.size(0), weight.size(1), device=weight.device\n",
        "                    )\n",
        "                    mask.bernoulli_(p)\n",
        "                    mask = (\n",
        "                        mask.unsqueeze(2)\n",
        "                        .unsqueeze(3)\n",
        "                        .repeat(1, 1, mod.kernel_size[0], mod.kernel_size[1])\n",
        "                    )\n",
        "\n",
        "            # scale weights and apply mask\n",
        "            mask = mask.to(\n",
        "                torch.bool\n",
        "            )  # x.bool() is not currently supported in TorchScript\n",
        "            s = 1 / (1 - p)\n",
        "            mod.weight.data = s * weight.masked_fill(mask, 0)\n",
        "\n",
        "    module.register_forward_pre_hook(_forward_pre_hook)\n",
        "    return module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DwHDiC9mQOx"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "    \"\"\"Multi-headed attention.\n",
        "\n",
        "    See \"Attention Is All You Need\" for more details.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim,\n",
        "        num_heads,\n",
        "        kdim=None,\n",
        "        vdim=None,\n",
        "        dropout=0.0,\n",
        "        bias=True,\n",
        "        self_attention=False,\n",
        "        q_noise=0.0,\n",
        "        qn_block_size=8,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.kdim = kdim if kdim is not None else embed_dim\n",
        "        self.vdim = vdim if vdim is not None else embed_dim\n",
        "        self.qkv_same_dim = self.kdim == embed_dim and self.vdim == embed_dim\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_module = FairseqDropout(\n",
        "            dropout, module_name=self.__class__.__name__\n",
        "        )\n",
        "\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        # assert (\n",
        "        #     self.head_dim * num_heads == self.embed_dim\n",
        "        # ), \"embed_dim must be divisible by num_heads\"\n",
        "        self.scaling = self.head_dim ** -0.5\n",
        "\n",
        "        self.self_attention = self_attention\n",
        "\n",
        "        assert self.self_attention, \"Only support self attention\"\n",
        "\n",
        "        assert not self.self_attention or self.qkv_same_dim, (\n",
        "            \"Self-attention requires query, key and \" \"value to be of the same size\"\n",
        "        )\n",
        "\n",
        "        self.k_proj = quant_noise(\n",
        "            nn.Linear(self.kdim, embed_dim, bias=bias), q_noise, qn_block_size\n",
        "        )\n",
        "        self.v_proj = quant_noise(\n",
        "            nn.Linear(self.vdim, embed_dim, bias=bias), q_noise, qn_block_size\n",
        "        )\n",
        "        self.q_proj = quant_noise(\n",
        "            nn.Linear(embed_dim, embed_dim, bias=bias), q_noise, qn_block_size\n",
        "        )\n",
        "\n",
        "        self.out_proj = quant_noise(\n",
        "            nn.Linear(embed_dim, embed_dim, bias=bias), q_noise, qn_block_size\n",
        "        )\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "        self.onnx_trace = False\n",
        "\n",
        "    def prepare_for_onnx_export_(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.qkv_same_dim:\n",
        "            # Empirically observed the convergence to be much better with\n",
        "            # the scaled initialization\n",
        "            nn.init.xavier_uniform_(self.k_proj.weight, gain=1 / math.sqrt(2))\n",
        "            nn.init.xavier_uniform_(self.v_proj.weight, gain=1 / math.sqrt(2))\n",
        "            nn.init.xavier_uniform_(self.q_proj.weight, gain=1 / math.sqrt(2))\n",
        "        else:\n",
        "            nn.init.xavier_uniform_(self.k_proj.weight)\n",
        "            nn.init.xavier_uniform_(self.v_proj.weight)\n",
        "            nn.init.xavier_uniform_(self.q_proj.weight)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.out_proj.weight)\n",
        "        if self.out_proj.bias is not None:\n",
        "            nn.init.constant_(self.out_proj.bias, 0.0)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        query,\n",
        "        key: Optional[Tensor],\n",
        "        value: Optional[Tensor],\n",
        "        attn_bias: Optional[Tensor],\n",
        "        key_padding_mask: Optional[Tensor] = None,\n",
        "        need_weights: bool = True,\n",
        "        attn_mask: Optional[Tensor] = None,\n",
        "        before_softmax: bool = False,\n",
        "        need_head_weights: bool = False,\n",
        "    ) -> Tuple[Tensor, Optional[Tensor]]:\n",
        "        \"\"\"Input shape: Time x Batch x Channel\n",
        "\n",
        "        Args:\n",
        "            key_padding_mask (ByteTensor, optional): mask to exclude\n",
        "                keys that are pads, of shape `(batch, src_len)`, where\n",
        "                padding elements are indicated by 1s.\n",
        "            need_weights (bool, optional): return the attention weights,\n",
        "                averaged over heads (default: False).\n",
        "            attn_mask (ByteTensor, optional): typically used to\n",
        "                implement causal attention, where the mask prevents the\n",
        "                attention from looking forward in time (default: None).\n",
        "            before_softmax (bool, optional): return the raw attention\n",
        "                weights and values before the attention softmax.\n",
        "            need_head_weights (bool, optional): return the attention\n",
        "                weights for each head. Implies *need_weights*. Default:\n",
        "                return the average attention weights over all heads.\n",
        "        \"\"\"\n",
        "        if need_head_weights:\n",
        "            need_weights = True\n",
        "\n",
        "        tgt_len, bsz, embed_dim = query.size()\n",
        "        src_len = tgt_len\n",
        "        assert embed_dim == self.embed_dim, f\"query dim {embed_dim} != {self.embed_dim}\"\n",
        "        assert list(query.size()) == [tgt_len, bsz, embed_dim]\n",
        "        if key is not None:\n",
        "            src_len, key_bsz, _ = key.size()\n",
        "            if not torch.jit.is_scripting():\n",
        "                assert key_bsz == bsz\n",
        "                assert value is not None\n",
        "                assert src_len, bsz == value.shape[:2]\n",
        "\n",
        "        q = self.q_proj(query)\n",
        "        k = self.k_proj(query)\n",
        "        v = self.v_proj(query)\n",
        "        q *= self.scaling\n",
        "\n",
        "        q = (\n",
        "            q.contiguous()\n",
        "            .view(tgt_len, bsz * self.num_heads, self.head_dim)\n",
        "            .transpose(0, 1)\n",
        "        )\n",
        "        if k is not None:\n",
        "            k = (\n",
        "                k.contiguous()\n",
        "                .view(-1, bsz * self.num_heads, self.head_dim)\n",
        "                .transpose(0, 1)\n",
        "            )\n",
        "        if v is not None:\n",
        "            v = (\n",
        "                v.contiguous()\n",
        "                .view(-1, bsz * self.num_heads, self.head_dim)\n",
        "                .transpose(0, 1)\n",
        "            )\n",
        "\n",
        "        assert k is not None\n",
        "        assert k.size(1) == src_len\n",
        "\n",
        "        # This is part of a workaround to get around fork/join parallelism\n",
        "        # not supporting Optional types.\n",
        "        if key_padding_mask is not None and key_padding_mask.dim() == 0:\n",
        "            key_padding_mask = None\n",
        "\n",
        "        if key_padding_mask is not None:\n",
        "            assert key_padding_mask.size(0) == bsz\n",
        "            assert key_padding_mask.size(1) == src_len\n",
        "        attn_weights = torch.bmm(q, k.transpose(1, 2))\n",
        "        attn_weights = self.apply_sparse_mask(attn_weights, tgt_len, src_len, bsz)\n",
        "\n",
        "        assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
        "\n",
        "        if attn_bias is not None:\n",
        "            attn_weights += attn_bias.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attn_mask = attn_mask.unsqueeze(0)\n",
        "            attn_weights += attn_mask\n",
        "\n",
        "        if key_padding_mask is not None:\n",
        "            # don't attend to padding symbols\n",
        "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "            attn_weights = attn_weights.masked_fill(\n",
        "                key_padding_mask.unsqueeze(1).unsqueeze(2).to(torch.bool),\n",
        "                float(\"-inf\"),\n",
        "            )\n",
        "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        if before_softmax:\n",
        "            return attn_weights, v\n",
        "\n",
        "        attn_weights_float = F.softmax(attn_weights.float(), dim=-1)\n",
        "        attn_weights = attn_weights_float.type_as(attn_weights)\n",
        "        attn_probs = self.dropout_module(attn_weights)\n",
        "\n",
        "        assert v is not None\n",
        "        attn = torch.bmm(attn_probs, v)\n",
        "        assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n",
        "\n",
        "        attn = attn.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n",
        "        attn = self.out_proj(attn)\n",
        "\n",
        "        attn_weights: Optional[Tensor] = None\n",
        "        if need_weights:\n",
        "            attn_weights = attn_weights_float.view(\n",
        "                bsz, self.num_heads, tgt_len, src_len\n",
        "            ).transpose(1, 0)\n",
        "            if not need_head_weights:\n",
        "                # average attention weights over heads\n",
        "                attn_weights = attn_weights.mean(dim=0)\n",
        "\n",
        "        return attn, attn_weights\n",
        "\n",
        "    def apply_sparse_mask(self, attn_weights, tgt_len: int, src_len: int, bsz: int):\n",
        "        return attn_weights\n",
        "\n",
        "    def upgrade_state_dict_named(self, state_dict, name):\n",
        "        prefix = name + \".\" if name != \"\" else \"\"\n",
        "        items_to_add = {}\n",
        "        keys_to_remove = []\n",
        "        for k in state_dict.keys():\n",
        "            if k.endswith(prefix + \"in_proj_weight\"):\n",
        "                # in_proj_weight used to be q + k + v with same dimensions\n",
        "                dim = int(state_dict[k].shape[0] / 3)\n",
        "                items_to_add[prefix + \"q_proj.weight\"] = state_dict[k][:dim]\n",
        "                items_to_add[prefix + \"k_proj.weight\"] = state_dict[k][dim : 2 * dim]\n",
        "                items_to_add[prefix + \"v_proj.weight\"] = state_dict[k][2 * dim :]\n",
        "\n",
        "                keys_to_remove.append(k)\n",
        "\n",
        "                k_bias = prefix + \"in_proj_bias\"\n",
        "                if k_bias in state_dict.keys():\n",
        "                    dim = int(state_dict[k].shape[0] / 3)\n",
        "                    items_to_add[prefix + \"q_proj.bias\"] = state_dict[k_bias][:dim]\n",
        "                    items_to_add[prefix + \"k_proj.bias\"] = state_dict[k_bias][\n",
        "                        dim : 2 * dim\n",
        "                    ]\n",
        "                    items_to_add[prefix + \"v_proj.bias\"] = state_dict[k_bias][2 * dim :]\n",
        "\n",
        "                    keys_to_remove.append(prefix + \"in_proj_bias\")\n",
        "\n",
        "        for k in keys_to_remove:\n",
        "            del state_dict[k]\n",
        "\n",
        "        for key, value in items_to_add.items():\n",
        "            state_dict[key] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUtvRG4BmyEV"
      },
      "outputs": [],
      "source": [
        "def init_params(module, n_layers):\n",
        "    if isinstance(module, nn.Linear):\n",
        "        module.weight.data.normal_(mean=0.0, std=0.02 / math.sqrt(n_layers))\n",
        "        if module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "    if isinstance(module, nn.Embedding):\n",
        "        module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "\n",
        "\n",
        "class GraphNodeFeature(nn.Module):\n",
        "    \"\"\"\n",
        "    Compute node features for each node in the graph.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, num_heads, num_atoms, num_in_degree, num_out_degree, hidden_dim, n_layers\n",
        "    ):\n",
        "        super(GraphNodeFeature, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.num_atoms = num_atoms\n",
        "\n",
        "        # 1 for graph token\n",
        "        self.atom_encoder = nn.Embedding(num_atoms + 1, hidden_dim, padding_idx=0)\n",
        "        self.in_degree_encoder = nn.Embedding(num_in_degree, hidden_dim, padding_idx=0)\n",
        "        self.out_degree_encoder = nn.Embedding(\n",
        "            num_out_degree, hidden_dim, padding_idx=0\n",
        "        )\n",
        "\n",
        "        self.graph_token = nn.Embedding(1, hidden_dim)\n",
        "\n",
        "        self.apply(lambda module: init_params(module, n_layers=n_layers))\n",
        "\n",
        "    def forward(self, batched_data):\n",
        "        x, in_degree, out_degree = (\n",
        "            batched_data[\"x\"],\n",
        "            batched_data[\"in_degree\"],\n",
        "            batched_data[\"out_degree\"],\n",
        "        )\n",
        "        n_graph, n_node = x.size()[:2]\n",
        "\n",
        "        # node feauture + graph token\n",
        "        node_feature = self.atom_encoder(x).sum(dim=-2)  # [n_graph, n_node, n_hidden]\n",
        "\n",
        "        # if self.flag and perturb is not None:\n",
        "        #     node_feature += perturb\n",
        "\n",
        "        node_feature = (\n",
        "            node_feature\n",
        "            + self.in_degree_encoder(in_degree)\n",
        "            + self.out_degree_encoder(out_degree)\n",
        "        )\n",
        "\n",
        "        graph_token_feature = self.graph_token.weight.unsqueeze(0).repeat(n_graph, 1, 1)\n",
        "\n",
        "        graph_node_feature = torch.cat([graph_token_feature, node_feature], dim=1)\n",
        "\n",
        "        return graph_node_feature\n",
        "\n",
        "\n",
        "class GraphAttnBias(nn.Module):\n",
        "    \"\"\"\n",
        "    Compute attention bias for each head.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_heads,\n",
        "        num_atoms,\n",
        "        num_edges,\n",
        "        num_spatial,\n",
        "        num_edge_dis,\n",
        "        hidden_dim,\n",
        "        edge_type,\n",
        "        multi_hop_max_dist,\n",
        "        n_layers,\n",
        "    ):\n",
        "        super(GraphAttnBias, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.multi_hop_max_dist = multi_hop_max_dist\n",
        "\n",
        "        self.edge_encoder = nn.Embedding(num_edges + 1, num_heads, padding_idx=0)\n",
        "        self.edge_type = edge_type\n",
        "        if self.edge_type == \"multi_hop\":\n",
        "            self.edge_dis_encoder = nn.Embedding(\n",
        "                num_edge_dis * num_heads * num_heads, 1\n",
        "            )\n",
        "        self.spatial_pos_encoder = nn.Embedding(num_spatial, num_heads, padding_idx=0)\n",
        "\n",
        "        self.graph_token_virtual_distance = nn.Embedding(1, num_heads)\n",
        "\n",
        "        self.apply(lambda module: init_params(module, n_layers=n_layers))\n",
        "\n",
        "    def forward(self, batched_data):\n",
        "        attn_bias, spatial_pos, x = (\n",
        "            batched_data[\"attn_bias\"],\n",
        "            batched_data[\"spatial_pos\"],\n",
        "            batched_data[\"x\"],\n",
        "        )\n",
        "        # in_degree, out_degree = batched_data.in_degree, batched_data.in_degree\n",
        "        edge_input, attn_edge_type = (\n",
        "            batched_data[\"edge_input\"],\n",
        "            batched_data[\"attn_edge_type\"],\n",
        "        )\n",
        "\n",
        "        n_graph, n_node = x.size()[:2]\n",
        "        graph_attn_bias = attn_bias.clone()\n",
        "        graph_attn_bias = graph_attn_bias.unsqueeze(1).repeat(\n",
        "            1, self.num_heads, 1, 1\n",
        "        )  # [n_graph, n_head, n_node+1, n_node+1]\n",
        "\n",
        "        # spatial pos\n",
        "        # [n_graph, n_node, n_node, n_head] -> [n_graph, n_head, n_node, n_node]\n",
        "        spatial_pos_bias = self.spatial_pos_encoder(spatial_pos).permute(0, 3, 1, 2)\n",
        "        graph_attn_bias[:, :, 1:, 1:] = graph_attn_bias[:, :, 1:, 1:] + spatial_pos_bias\n",
        "\n",
        "        # reset spatial pos here\n",
        "        t = self.graph_token_virtual_distance.weight.view(1, self.num_heads, 1)\n",
        "        graph_attn_bias[:, :, 1:, 0] = graph_attn_bias[:, :, 1:, 0] + t\n",
        "        graph_attn_bias[:, :, 0, :] = graph_attn_bias[:, :, 0, :] + t\n",
        "\n",
        "        # edge feature\n",
        "        if self.edge_type == \"multi_hop\":\n",
        "            spatial_pos_ = spatial_pos.clone()\n",
        "\n",
        "            spatial_pos_[spatial_pos_ == 0] = 1  # set pad to 1\n",
        "\n",
        "            # set 1 to 1, x > 1 to x - 1\n",
        "            spatial_pos_ = torch.where(spatial_pos_ > 1, spatial_pos_ - 1, spatial_pos_)\n",
        "            if self.multi_hop_max_dist > 0:\n",
        "                spatial_pos_ = spatial_pos_.clamp(0, self.multi_hop_max_dist)\n",
        "                edge_input = edge_input[:, :, :, : self.multi_hop_max_dist, :]\n",
        "            # [n_graph, n_node, n_node, max_dist, n_head]\n",
        "\n",
        "            edge_input = self.edge_encoder(edge_input).mean(-2)\n",
        "\n",
        "            max_dist = edge_input.size(-2)\n",
        "            # edge_input is shape [*,*,*,0,*] when graph has no edge; -1 while raise error\n",
        "            if edge_input.shape[3]>0:\n",
        "                edge_input_flat = edge_input.permute(3, 0, 1, 2, 4).reshape(\n",
        "                    max_dist, -1, self.num_heads\n",
        "                )\n",
        "            else:\n",
        "                edge_input_flat = edge_input.permute(3, 0, 1, 2, 4).reshape(\n",
        "                    max_dist, 0, self.num_heads\n",
        "                )\n",
        "            edge_input_flat = torch.bmm(\n",
        "                edge_input_flat,\n",
        "                self.edge_dis_encoder.weight.reshape(\n",
        "                    -1, self.num_heads, self.num_heads\n",
        "                )[:max_dist, :, :],\n",
        "            )\n",
        "            edge_input = edge_input_flat.reshape(\n",
        "                max_dist, n_graph, n_node, n_node, self.num_heads\n",
        "            ).permute(1, 2, 3, 0, 4)\n",
        "            edge_input = (\n",
        "                edge_input.sum(-2) / (spatial_pos_.float().unsqueeze(-1))\n",
        "            ).permute(0, 3, 1, 2)\n",
        "        else:\n",
        "            # [n_graph, n_node, n_node, n_head] -> [n_graph, n_head, n_node, n_node]\n",
        "            edge_input = self.edge_encoder(attn_edge_type).mean(-2).permute(0, 3, 1, 2)\n",
        "\n",
        "        graph_attn_bias[:, :, 1:, 1:] = graph_attn_bias[:, :, 1:, 1:] + edge_input\n",
        "        graph_attn_bias = graph_attn_bias + attn_bias.unsqueeze(1)  # reset\n",
        "\n",
        "        return graph_attn_bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQD5KttQm9pm"
      },
      "outputs": [],
      "source": [
        "def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):\n",
        "    if torch.jit.is_scripting() or torch.jit.is_tracing():\n",
        "        export = True\n",
        "    # if not export and torch.cuda.is_available() and has_fused_layernorm:\n",
        "        # return FusedLayerNorm(normalized_shape, eps, elementwise_affine)\n",
        "    return torch.nn.LayerNorm(normalized_shape, eps, elementwise_affine)\n",
        "\n",
        "def init_graphormer_params(module):\n",
        "    \"\"\"\n",
        "    Initialize the weights specific to the Graphormer Model.\n",
        "    \"\"\"\n",
        "\n",
        "    def normal_(data):\n",
        "        # with FSDP, module params will be on CUDA, so we cast them back to CPU\n",
        "        # so that the RNG is consistent with and without FSDP\n",
        "        data.copy_(data.cpu().normal_(mean=0.0, std=0.02).to(data.device))\n",
        "\n",
        "    if isinstance(module, nn.Linear):\n",
        "        normal_(module.weight.data)\n",
        "        if module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "    if isinstance(module, nn.Embedding):\n",
        "        normal_(module.weight.data)\n",
        "        if module.padding_idx is not None:\n",
        "            module.weight.data[module.padding_idx].zero_()\n",
        "    if isinstance(module, MultiheadAttention):\n",
        "        normal_(module.q_proj.weight.data)\n",
        "        normal_(module.k_proj.weight.data)\n",
        "        normal_(module.v_proj.weight.data)\n",
        "\n",
        "class GraphEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_atoms: int,\n",
        "        num_in_degree: int,\n",
        "        num_out_degree: int,\n",
        "        num_edges: int,\n",
        "        num_spatial: int,\n",
        "        num_edge_dis: int,\n",
        "        edge_type: str,\n",
        "        multi_hop_max_dist: int,\n",
        "        num_encoder_layers: int = 12,\n",
        "        embedding_dim: int = 768,\n",
        "        num_attention_heads: int = 32,\n",
        "        dropout: float = 0.1,\n",
        "        layerdrop: float = 0.0,\n",
        "        encoder_normalize_before: bool = False,\n",
        "        apply_graphormer_init: bool = False,\n",
        "        embed_scale: float = None,\n",
        "        export: bool = False,\n",
        "        traceable: bool = False,\n",
        "        q_noise: float = 0.0,\n",
        "        qn_block_size: int = 8,\n",
        "    ) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        self.dropout_module = FairseqDropout(\n",
        "            dropout, module_name=self.__class__.__name__\n",
        "        )\n",
        "        self.layerdrop = layerdrop\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.apply_graphormer_init = apply_graphormer_init\n",
        "        self.traceable = traceable\n",
        "\n",
        "        self.graph_node_feature = GraphNodeFeature(\n",
        "            num_heads=num_attention_heads,\n",
        "            num_atoms=num_atoms,\n",
        "            num_in_degree=num_in_degree,\n",
        "            num_out_degree=num_out_degree,\n",
        "            hidden_dim=embedding_dim,\n",
        "            n_layers=num_encoder_layers,\n",
        "        )\n",
        "\n",
        "        self.graph_attn_bias = GraphAttnBias(\n",
        "            num_heads=num_attention_heads,\n",
        "            num_atoms=num_atoms,\n",
        "            num_edges=num_edges,\n",
        "            num_spatial=num_spatial,\n",
        "            num_edge_dis=num_edge_dis,\n",
        "            edge_type=edge_type,\n",
        "            multi_hop_max_dist=multi_hop_max_dist,\n",
        "            hidden_dim=embedding_dim,\n",
        "            n_layers=num_encoder_layers,\n",
        "        )\n",
        "\n",
        "        self.embed_scale = embed_scale\n",
        "\n",
        "        if q_noise > 0:\n",
        "            self.quant_noise = quant_noise(\n",
        "                nn.Linear(self.embedding_dim, self.embedding_dim, bias=False),\n",
        "                q_noise,\n",
        "                qn_block_size,\n",
        "            )\n",
        "        else:\n",
        "            self.quant_noise = None\n",
        "\n",
        "        if encoder_normalize_before:\n",
        "            self.emb_layer_norm = LayerNorm(self.embedding_dim, export=export)\n",
        "        else:\n",
        "            self.emb_layer_norm = None\n",
        "\n",
        "        # Apply initialization of model params after building the model\n",
        "        if self.apply_graphormer_init:\n",
        "            self.apply(init_graphormer_params)\n",
        "\n",
        "\n",
        "    def embedding_graph(self,batched_data):\n",
        "        data_x = batched_data[\"x\"]\n",
        "        n_graph, n_node = data_x.size()[:2]\n",
        "        padding_mask = (data_x[:, :, 0]).eq(0)  # B x T x 1\n",
        "        padding_mask_cls = torch.zeros(\n",
        "            n_graph, 1, device=padding_mask.device, dtype=padding_mask.dtype\n",
        "        )\n",
        "        padding_mask = torch.cat((padding_mask_cls, padding_mask), dim=1)\n",
        "        # B x (T+1) x 1\n",
        "\n",
        "        # if token_embeddings is not None:\n",
        "        #     x = token_embeddings\n",
        "        # else:\n",
        "        x = self.graph_node_feature(batched_data)\n",
        "\n",
        "        # if perturb is not None:\n",
        "        #     #ic(torch.mean(torch.abs(x[:, 1, :])))\n",
        "        #     #ic(torch.mean(torch.abs(perturb)))\n",
        "        #     x[:, 1:, :] += perturb\n",
        "\n",
        "        # x: B x T x C\n",
        "\n",
        "        attn_bias = self.graph_attn_bias(batched_data)\n",
        "\n",
        "        if self.embed_scale is not None:\n",
        "            x = x * self.embed_scale\n",
        "\n",
        "        if self.quant_noise is not None:\n",
        "            x = self.quant_noise(x)\n",
        "\n",
        "        if self.emb_layer_norm is not None:\n",
        "            x = self.emb_layer_norm(x)\n",
        "\n",
        "        x = self.dropout_module(x)\n",
        "\n",
        "        # account for padding while computing the representation\n",
        "\n",
        "        # B x T x C -> T x B x C\n",
        "        x = x.transpose(0, 1)\n",
        "        return x,attn_bias,padding_mask\n",
        "\n",
        "    def forward(self,batched_data):\n",
        "        return self.embedding_graph(batched_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxkvNX9wnL8m"
      },
      "outputs": [],
      "source": [
        "class GIMLETEncoderStack(T5Stack):\n",
        "    def __init__(self, config, graph_args,embed_tokens=None):\n",
        "        super().__init__(config,embed_tokens=embed_tokens)\n",
        "\n",
        "        if graph_args.encoder_embed_dim>0 and graph_args.encoder_embed_dim!=self.config.d_model:\n",
        "            raise ValueError('Warning! Inconsistent graph encoder_embed_dim and transformer d_model for Unimodel')\n",
        "        graph_args.encoder_embed_dim=self.config.d_model\n",
        "        if graph_args.encoder_attention_heads>0 and graph_args.encoder_attention_heads!=self.config.num_heads:\n",
        "            raise ValueError('Warning! Inconsistent graph encoder_attention_heads and transformer num_heads for Unimodel')\n",
        "        graph_args.encoder_attention_heads=self.config.num_heads\n",
        "        if graph_args.encoder_layers>0 and graph_args.encoder_layers!=self.config.num_layers:\n",
        "            raise ValueError('Warning! Inconsistent graph encoder_layers and transformer num_layers for Unimodel')\n",
        "        graph_args.encoder_layers = self.config.num_layers\n",
        "\n",
        "        self.graph_encoder = GraphEncoder(\n",
        "        num_atoms=graph_args.num_atoms,\n",
        "        num_in_degree=graph_args.num_in_degree,\n",
        "        num_out_degree=graph_args.num_out_degree,\n",
        "        num_edges=graph_args.num_edges,\n",
        "        num_spatial=graph_args.num_spatial,\n",
        "        num_edge_dis=graph_args.num_edge_dis,\n",
        "        edge_type=graph_args.edge_type,\n",
        "        multi_hop_max_dist=graph_args.multi_hop_max_dist,\n",
        "        # >\n",
        "        num_encoder_layers=graph_args.encoder_layers,\n",
        "        embedding_dim=graph_args.encoder_embed_dim,\n",
        "        num_attention_heads=graph_args.encoder_attention_heads,\n",
        "        dropout=graph_args.dropout,\n",
        "        encoder_normalize_before=graph_args.encoder_normalize_before,\n",
        "        apply_graphormer_init=graph_args.apply_graphormer_init,)\n",
        "\n",
        "        self.graph_encoder.args=graph_args\n",
        "        self.position_embedding_graph=nn.Embedding(1, self.block[1].layer[0].SelfAttention.n_heads)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        graph=None,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        head_mask=None,\n",
        "        cross_attn_head_mask=None,\n",
        "        past_key_values=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        graph=graph.to(input_ids.device)\n",
        "        attention_mask_graph=graph['attn_bias'][:,0,:]\n",
        "\n",
        "\n",
        "        hidden_state_graph, attn_bias_graph, padding_mask_graph = self.graph_encoder(graph)\n",
        "\n",
        "        attention_bias_graph_unimodel = attn_bias_graph.masked_fill(\n",
        "            padding_mask_graph.unsqueeze(1).unsqueeze(2).to(torch.bool),\n",
        "            float(\"-inf\"))\n",
        "\n",
        "\n",
        "        # Model parallel\n",
        "        if self.model_parallel:\n",
        "            torch.cuda.set_device(self.first_device)\n",
        "            self.embed_tokens = self.embed_tokens.to(self.first_device)\n",
        "\n",
        "\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            err_msg_prefix = \"decoder_\" if self.is_decoder else \"\"\n",
        "            raise ValueError(\n",
        "                f\"You cannot specify both {err_msg_prefix}input_ids and {err_msg_prefix}inputs_embeds at the same time\"\n",
        "            )\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "            input_ids = input_ids.view(-1, input_shape[-1])\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            err_msg_prefix = \"decoder_\" if self.is_decoder else \"\"\n",
        "            raise ValueError(f\"You have to specify either {err_msg_prefix}input_ids or {err_msg_prefix}inputs_embeds\")\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            assert self.embed_tokens is not None, \"You have to initialize the model with valid token embeddings\"\n",
        "            inputs_embeds = self.embed_tokens(input_ids)\n",
        "\n",
        "        batch_size, seq_length = input_shape\n",
        "\n",
        "        # required mask seq length can be calculated via length of past\n",
        "        mask_seq_length = past_key_values[0][0].shape[2] + seq_length if past_key_values is not None else seq_length\n",
        "\n",
        "        if use_cache is True:\n",
        "            assert self.is_decoder, f\"`use_cache` can only be set to `True` if {self} is used as a decoder\"\n",
        "\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(batch_size, mask_seq_length, device=inputs_embeds.device)\n",
        "        if self.is_decoder and encoder_attention_mask is None and encoder_hidden_states is not None:\n",
        "            encoder_seq_length = encoder_hidden_states.shape[1]\n",
        "            encoder_attention_mask = torch.ones(\n",
        "                batch_size, encoder_seq_length, device=inputs_embeds.device, dtype=torch.long\n",
        "            )\n",
        "\n",
        "        # initialize past_key_values with `None` if past does not exist\n",
        "        if past_key_values is None:\n",
        "            past_key_values = [None] * len(self.block)\n",
        "\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        extended_attention_mask = self.get_extended_attention_mask(attention_mask, input_shape)\n",
        "\n",
        "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
        "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "        if self.is_decoder and encoder_hidden_states is not None:\n",
        "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
        "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
        "            if encoder_attention_mask is None:\n",
        "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=inputs_embeds.device)\n",
        "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
        "        else:\n",
        "            encoder_extended_attention_mask = None\n",
        "\n",
        "        # Prepare head mask if needed\n",
        "        head_mask = self.get_head_mask(head_mask, self.config.num_layers)\n",
        "        cross_attn_head_mask = self.get_head_mask(cross_attn_head_mask, self.config.num_layers)\n",
        "        present_key_value_states = () if use_cache else None\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "        all_cross_attentions = () if (output_attentions and self.is_decoder) else None\n",
        "        position_bias = None\n",
        "        encoder_decoder_position_bias = None\n",
        "\n",
        "        hidden_states = self.dropout(inputs_embeds)\n",
        "\n",
        "        # construct position_bias for T5, where graph tokens are all treated as a special distance to each text token\n",
        "        position_bias=self.block[0].layer[0].SelfAttention.compute_bias(hidden_states.shape[1], hidden_states.shape[1], device=hidden_states.device)\n",
        "        position_embedding_graph_spaned=self.position_embedding_graph(\n",
        "            torch.zeros(1,hidden_states.shape[1],hidden_state_graph.shape[0]).long().to(self.position_embedding_graph.weight.device))\\\n",
        "            .transpose(3,1)\n",
        "        position_embedding_graph_spaned_2=self.position_embedding_graph(\n",
        "            torch.zeros(1,hidden_state_graph.shape[0],hidden_states.shape[1]+hidden_state_graph.shape[0]).long().to(self.position_embedding_graph.weight.device))\\\n",
        "            .transpose(3,1)\n",
        "        position_bias_merged=torch.cat([position_embedding_graph_spaned,position_bias],2)\n",
        "        position_bias_merged = torch.cat([position_embedding_graph_spaned_2, position_bias_merged], 3)\n",
        "\n",
        "\n",
        "        position_bias_merged = position_bias_merged.repeat(attention_bias_graph_unimodel.shape[0], 1, 1, 1) #attention_bias_graph_unimodel.shape[0] is batch size\n",
        "        position_bias_merged[:, :, 0:attention_bias_graph_unimodel.shape[2],\n",
        "                            0:attention_bias_graph_unimodel.shape[3]] = attention_bias_graph_unimodel\n",
        "        if self.graph_encoder.args.maskt2g:\n",
        "            position_bias_merged[:,:,0:attention_bias_graph_unimodel.shape[2],attention_bias_graph_unimodel.shape[3]:]=float(\"-inf\")\n",
        "\n",
        "        for i, (layer_module, past_key_value) in enumerate(zip(self.block, past_key_values)):\n",
        "\n",
        "            #Because hidden_state_graph size is length,batch,embedding_dim, need transpose before input to T5\n",
        "            # transpose to be consistant with the non-unimodel\n",
        "            # hidden_state_graph=hidden_state_graph.transpose(0,1)\n",
        "\n",
        "            layer_head_mask = head_mask[i]\n",
        "            cross_attn_layer_head_mask = cross_attn_head_mask[i]\n",
        "            # Model parallel\n",
        "            if self.model_parallel:\n",
        "                torch.cuda.set_device(hidden_states.device)\n",
        "                # Ensure that attention_mask is always on the same device as hidden_states\n",
        "                if attention_mask is not None:\n",
        "                    attention_mask = attention_mask.to(hidden_states.device)\n",
        "                if position_bias is not None:\n",
        "                    position_bias = position_bias.to(hidden_states.device)\n",
        "                if encoder_hidden_states is not None:\n",
        "                    encoder_hidden_states = encoder_hidden_states.to(hidden_states.device)\n",
        "                if encoder_extended_attention_mask is not None:\n",
        "                    encoder_extended_attention_mask = encoder_extended_attention_mask.to(hidden_states.device)\n",
        "                if encoder_decoder_position_bias is not None:\n",
        "                    encoder_decoder_position_bias = encoder_decoder_position_bias.to(hidden_states.device)\n",
        "                if layer_head_mask is not None:\n",
        "                    layer_head_mask = layer_head_mask.to(hidden_states.device)\n",
        "                if cross_attn_layer_head_mask is not None:\n",
        "                    cross_attn_layer_head_mask = cross_attn_layer_head_mask.to(hidden_states.device)\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "                if use_cache:\n",
        "                    logger.warning(\n",
        "                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
        "                    )\n",
        "                    use_cache = False\n",
        "\n",
        "                def create_custom_forward(module):\n",
        "                    def custom_forward(*inputs):\n",
        "                        return tuple(module(*inputs, use_cache, output_attentions))\n",
        "\n",
        "                    return custom_forward\n",
        "\n",
        "                layer_outputs = checkpoint(\n",
        "                    create_custom_forward(layer_module),\n",
        "                    hidden_states,\n",
        "                    extended_attention_mask,\n",
        "                    position_bias_merged,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_extended_attention_mask,\n",
        "                    encoder_decoder_position_bias,\n",
        "                    layer_head_mask,\n",
        "                    cross_attn_layer_head_mask,\n",
        "                    None,  # past_key_value is always None with gradient checkpointing\n",
        "                )\n",
        "            else:\n",
        "                # transpose [length,batch,dim] to [batch,length,dim]\n",
        "                # if not self.graph_encoder.args.unimodel:\n",
        "                #     hidden_states_graph_mapped = (self.graph_projector(hidden_state_graph)).transpose(0, 1)\n",
        "                # else:\n",
        "                hidden_states_graph_mapped = hidden_state_graph.transpose(0, 1)\n",
        "\n",
        "                hidden_states_merged = torch.cat([hidden_states_graph_mapped, hidden_states], 1)\n",
        "                attention_mask_merged = torch.cat(\n",
        "                    [attention_mask_graph.unsqueeze(1).unsqueeze(1), extended_attention_mask], 3)\n",
        "\n",
        "\n",
        "\n",
        "                layer_outputs = layer_module(\n",
        "                    hidden_states_merged,\n",
        "                    # attention_mask=attention_mask_merged,\n",
        "                    position_bias=position_bias_merged + attention_mask_merged,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    encoder_attention_mask=encoder_extended_attention_mask,\n",
        "                    encoder_decoder_position_bias=encoder_decoder_position_bias,\n",
        "                    layer_head_mask=layer_head_mask,\n",
        "                    cross_attn_layer_head_mask=cross_attn_layer_head_mask,\n",
        "                    past_key_value=past_key_value,\n",
        "                    use_cache=use_cache,\n",
        "                    output_attentions=output_attentions,\n",
        "                )\n",
        "\n",
        "            # layer_outputs is a tuple with:\n",
        "            # hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\n",
        "            if use_cache is False:\n",
        "                layer_outputs = layer_outputs[:1] + (None,) + layer_outputs[1:]\n",
        "\n",
        "            hidden_states_merged, present_key_value_state = layer_outputs[:2]\n",
        "\n",
        "            hidden_states = hidden_states_merged[:, hidden_states_graph_mapped.shape[1]:, :]\n",
        "            # transpose again for consistance\n",
        "            hidden_state_graph=(hidden_states_merged[:, 0:hidden_states_graph_mapped.shape[1], :]).transpose(0, 1)\n",
        "\n",
        "            assert hidden_states.shape[1] == extended_attention_mask.shape[3]\n",
        "\n",
        "            # We share the position biases between the layers - the first layer store them\n",
        "            # layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\n",
        "            # (cross-attention position bias), (cross-attention weights)\n",
        "            position_bias = layer_outputs[2]\n",
        "            if self.is_decoder and encoder_hidden_states is not None:\n",
        "                encoder_decoder_position_bias = layer_outputs[4 if output_attentions else 3]\n",
        "            # append next layer key value states\n",
        "            if use_cache:\n",
        "                present_key_value_states = present_key_value_states + (present_key_value_state,)\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[3],)\n",
        "                if self.is_decoder:\n",
        "                    all_cross_attentions = all_cross_attentions + (layer_outputs[5],)\n",
        "\n",
        "            # Model Parallel: If it's the last layer for that device, put things on the next device\n",
        "            if self.model_parallel:\n",
        "                for k, v in self.device_map.items():\n",
        "                    if i == v[-1] and \"cuda:\" + str(k) != self.last_device:\n",
        "                        hidden_states = hidden_states.to(\"cuda:\" + str(k + 1))\n",
        "\n",
        "\n",
        "        hidden_states = self.final_layer_norm(hidden_states)\n",
        "\n",
        "        #for debug\n",
        "        # hidden_states = self.final_layer_norm(hidden_state_graph.transpose(0,1))\n",
        "\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "\n",
        "        # Add last layer\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v\n",
        "                for v in [\n",
        "                    hidden_states,\n",
        "                    present_key_value_states,\n",
        "                    all_hidden_states,\n",
        "                    all_attentions,\n",
        "                    all_cross_attentions,\n",
        "                ]\n",
        "                if v is not None\n",
        "            )\n",
        "        return BaseModelOutputWithPastAndCrossAttentions(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=present_key_value_states,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_attentions,\n",
        "            cross_attentions=all_cross_attentions,\n",
        "        )\n",
        "\n",
        "    def forward_graph_only(\n",
        "        self,\n",
        "        graph=None,\n",
        "        # input_ids=None,\n",
        "        # attention_mask=None,\n",
        "        # encoder_hidden_states=None,\n",
        "        # encoder_attention_mask=None,\n",
        "        # inputs_embeds=None,\n",
        "        head_mask=None,\n",
        "        cross_attn_head_mask=None,\n",
        "        past_key_values=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        graph=graph.to(self.device)\n",
        "        attention_mask_graph=graph['attn_bias'][:,0,:]\n",
        "\n",
        "\n",
        "        hidden_state_graph, attn_bias_graph, padding_mask_graph = self.graph_encoder(graph)\n",
        "\n",
        "        attention_bias_graph_unimodel = attn_bias_graph.masked_fill(\n",
        "            padding_mask_graph.unsqueeze(1).unsqueeze(2).to(torch.bool),\n",
        "            float(\"-inf\"))\n",
        "\n",
        "\n",
        "        # Model parallel\n",
        "        if self.model_parallel:\n",
        "            torch.cuda.set_device(self.first_device)\n",
        "            self.embed_tokens = self.embed_tokens.to(self.first_device)\n",
        "\n",
        "\n",
        "\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "\n",
        "        if use_cache is True:\n",
        "            assert self.is_decoder, f\"`use_cache` can only be set to `True` if {self} is used as a decoder\"\n",
        "\n",
        "\n",
        "        # initialize past_key_values with `None` if past does not exist\n",
        "        if past_key_values is None:\n",
        "            past_key_values = [None] * len(self.block)\n",
        "\n",
        "\n",
        "        # Prepare head mask if needed\n",
        "        head_mask = self.get_head_mask(head_mask, self.config.num_layers)\n",
        "        cross_attn_head_mask = self.get_head_mask(cross_attn_head_mask, self.config.num_layers)\n",
        "        present_key_value_states = () if use_cache else None\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "        all_cross_attentions = () if (output_attentions and self.is_decoder) else None\n",
        "        position_bias = None\n",
        "        encoder_decoder_position_bias = None\n",
        "\n",
        "\n",
        "\n",
        "        position_bias_merged=attention_bias_graph_unimodel\n",
        "\n",
        "        for i, (layer_module, past_key_value) in enumerate(zip(self.block, past_key_values)):\n",
        "\n",
        "            if self.model_parallel:\n",
        "                torch.cuda.set_device(hidden_states.device)\n",
        "                # Ensure that attention_mask is always on the same device as hidden_states\n",
        "                if attention_mask is not None:\n",
        "                    attention_mask = attention_mask.to(hidden_states.device)\n",
        "                if position_bias is not None:\n",
        "                    position_bias = position_bias.to(hidden_states.device)\n",
        "\n",
        "                if encoder_decoder_position_bias is not None:\n",
        "                    encoder_decoder_position_bias = encoder_decoder_position_bias.to(hidden_states.device)\n",
        "\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "                if use_cache:\n",
        "                    logger.warning(\n",
        "                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
        "                    )\n",
        "                    use_cache = False\n",
        "\n",
        "                def create_custom_forward(module):\n",
        "                    def custom_forward(*inputs):\n",
        "                        return tuple(module(*inputs, use_cache, output_attentions))\n",
        "\n",
        "                    return custom_forward\n",
        "\n",
        "                layer_outputs = checkpoint(\n",
        "                    create_custom_forward(layer_module),\n",
        "                    hidden_states_merged,\n",
        "                    position_bias_merged + attention_mask_merged,\n",
        "                    encoder_decoder_position_bias,\n",
        "                    None,  # past_key_value is always None with gradient checkpointing\n",
        "                )\n",
        "            else:\n",
        "\n",
        "                hidden_states_graph_mapped = hidden_state_graph.transpose(0, 1)\n",
        "\n",
        "                hidden_states_merged = hidden_states_graph_mapped\n",
        "                attention_mask_merged = attention_mask_graph.unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "                layer_outputs = layer_module(\n",
        "                    hidden_states_merged,\n",
        "                    # attention_mask=attention_mask_merged,\n",
        "                    position_bias=position_bias_merged + attention_mask_merged,\n",
        "                    # encoder_hidden_states=encoder_hidden_states,\n",
        "                    # encoder_attention_mask=encoder_extended_attention_mask,\n",
        "                    encoder_decoder_position_bias=encoder_decoder_position_bias,\n",
        "                    # layer_head_mask=layer_head_mask,\n",
        "                    # cross_attn_layer_head_mask=cross_attn_layer_head_mask,\n",
        "                    past_key_value=past_key_value,\n",
        "                    use_cache=use_cache,\n",
        "                    output_attentions=output_attentions,\n",
        "                )\n",
        "\n",
        "            # layer_outputs is a tuple with:\n",
        "            # hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\n",
        "            if use_cache is False:\n",
        "                layer_outputs = layer_outputs[:1] + (None,) + layer_outputs[1:]\n",
        "\n",
        "            hidden_states_merged, present_key_value_state = layer_outputs[:2]\n",
        "\n",
        "            hidden_states = hidden_states_merged\n",
        "            # transpose again for consistance\n",
        "            hidden_state_graph=hidden_states_merged.transpose(0, 1)\n",
        "\n",
        "            # assert hidden_states.shape[1] == extended_attention_mask.shape[3]\n",
        "\n",
        "            # We share the position biases between the layers - the first layer store them\n",
        "            # layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\n",
        "            # (cross-attention position bias), (cross-attention weights)\n",
        "            position_bias = layer_outputs[2]\n",
        "            # if self.is_decoder and encoder_hidden_states is not None:\n",
        "            #     encoder_decoder_position_bias = layer_outputs[4 if output_attentions else 3]\n",
        "            # append next layer key value states\n",
        "            if use_cache:\n",
        "                present_key_value_states = present_key_value_states + (present_key_value_state,)\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[3],)\n",
        "                if self.is_decoder:\n",
        "                    all_cross_attentions = all_cross_attentions + (layer_outputs[5],)\n",
        "\n",
        "            # Model Parallel: If it's the last layer for that device, put things on the next device\n",
        "            if self.model_parallel:\n",
        "                for k, v in self.device_map.items():\n",
        "                    if i == v[-1] and \"cuda:\" + str(k) != self.last_device:\n",
        "                        hidden_states = hidden_states.to(\"cuda:\" + str(k + 1))\n",
        "\n",
        "\n",
        "\n",
        "        hidden_states = self.final_layer_norm(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "\n",
        "        # Add last layer\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                    hidden_states,\n",
        "                    present_key_value_states,\n",
        "                    all_hidden_states,\n",
        "                    all_attentions,\n",
        "                    all_cross_attentions,\n",
        "                    attention_mask_merged\n",
        "            )\n",
        "        return dict(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=present_key_value_states,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_attentions,\n",
        "            cross_attentions=all_cross_attentions,\n",
        "            attention_mask_merged=attention_mask_merged\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0zBKovAnRfr"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "__HEAD_MASK_WARNING_MSG = \"\"\"\n",
        "The input argument `head_mask` was split into two arguments `head_mask` and `decoder_head_mask`. Currently,\n",
        "`decoder_head_mask` is set to copy `head_mask`, but this feature is deprecated and will be removed in future versions.\n",
        "If you do not want to use any `decoder_head_mask` now, please set `decoder_head_mask = torch.ones(num_layers,\n",
        "num_heads)`.\n",
        "\"\"\"\n",
        "\n",
        "class GraphT5TransformerForConditionalGeneration(T5ForConditionalGeneration):\n",
        "    _keys_to_ignore_on_load_missing = [\n",
        "        r\"encoder.embed_tokens.weight\",\n",
        "        r\"decoder.embed_tokens.weight\",\n",
        "        r\"lm_head.weight\",\n",
        "    ]\n",
        "    _keys_to_ignore_on_load_unexpected = [\n",
        "        r\"decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight\",\n",
        "    ]\n",
        "\n",
        "    def __init__(self, config,graph_args=None):\n",
        "\n",
        "        #for debug\n",
        "        # config.dropout_rate=0.0\n",
        "\n",
        "        super().__init__(config)\n",
        "\n",
        "        encoder_config = copy.deepcopy(config)\n",
        "        encoder_config.is_decoder = False\n",
        "        encoder_config.use_cache = False\n",
        "        encoder_config.is_encoder_decoder = False\n",
        "\n",
        "        if graph_args is None:\n",
        "            assert hasattr(config,'graph_args')\n",
        "            graph_args= PretrainedConfig.from_dict(config.graph_args)\n",
        "        else:\n",
        "            config.graph_args = vars(graph_args)\n",
        "\n",
        "        self.config.loss_reduction_method = getattr(graph_args,'loss_reduction_method')\n",
        "        self.encoder = GIMLETEncoderStack(encoder_config,graph_args, self.shared)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        graph=None,\n",
        "        input_ids = None,\n",
        "        attention_mask = None,\n",
        "        decoder_input_ids = None,\n",
        "        decoder_attention_mask = None,\n",
        "        head_mask = None,\n",
        "        decoder_head_mask = None,\n",
        "        cross_attn_head_mask = None,\n",
        "        encoder_outputs = None,\n",
        "        past_key_values = None,\n",
        "        inputs_embeds = None,\n",
        "        decoder_inputs_embeds = None,\n",
        "        labels = None,\n",
        "        use_cache = None,\n",
        "        output_attentions = None,\n",
        "        output_hidden_states = None,\n",
        "        return_dict = None,\n",
        "    ) :\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[-100, 0, ...,\n",
        "            config.vocab_size - 1]`. All labels set to `-100` are ignored (masked), the loss is only computed for\n",
        "            labels in `[0, ..., config.vocab_size]`\n",
        "\n",
        "        Returns:\n",
        "\n",
        "        Examples:\n",
        "\n",
        "        ```python\n",
        "        >>> from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "        >>> tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "        >>> model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "        >>> # training\n",
        "        >>> input_ids = tokenizer(\"The <extra_id_0> walks in <extra_id_1> park\", return_tensors=\"pt\").input_ids\n",
        "        >>> labels = tokenizer(\"<extra_id_0> cute dog <extra_id_1> the <extra_id_2>\", return_tensors=\"pt\").input_ids\n",
        "        >>> outputs = model(input_ids=input_ids, labels=labels)\n",
        "        >>> loss = outputs.loss\n",
        "        >>> logits = outputs.logits\n",
        "\n",
        "        >>> # inference\n",
        "        >>> input_ids = tokenizer(\n",
        "        ...     \"summarize: studies have shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
        "        ... ).input_ids  # Batch size 1\n",
        "        >>> outputs = model.generate(input_ids)\n",
        "        >>> print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "        >>> # studies have shown that owning a dog is good for you.\n",
        "        ```\"\"\"\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        # FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask\n",
        "        if head_mask is not None and decoder_head_mask is None:\n",
        "            if self.config.num_layers == self.config.num_decoder_layers:\n",
        "                warnings.warn(__HEAD_MASK_WARNING_MSG, FutureWarning)\n",
        "                decoder_head_mask = head_mask\n",
        "\n",
        "        # Encode if needed (training, first prediction pass)\n",
        "        if encoder_outputs is None:\n",
        "            # Convert encoder inputs in embeddings if needed\n",
        "            encoder_outputs = self.encoder(\n",
        "                graph=graph,\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                head_mask=head_mask,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=output_hidden_states,\n",
        "                return_dict=return_dict,\n",
        "            )\n",
        "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
        "            encoder_outputs = BaseModelOutput(\n",
        "                last_hidden_state=encoder_outputs[0],\n",
        "                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
        "                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
        "            )\n",
        "\n",
        "        hidden_states = encoder_outputs[0]\n",
        "\n",
        "        if self.model_parallel:\n",
        "            torch.cuda.set_device(self.decoder.first_device)\n",
        "\n",
        "        if labels is not None and decoder_input_ids is None and decoder_inputs_embeds is None:\n",
        "            # get decoder inputs from shifting lm labels to the right\n",
        "            decoder_input_ids = self._shift_right(labels)\n",
        "\n",
        "        # Set device for model parallelism\n",
        "        if self.model_parallel:\n",
        "            torch.cuda.set_device(self.decoder.first_device)\n",
        "            hidden_states = hidden_states.to(self.decoder.first_device)\n",
        "            if decoder_input_ids is not None:\n",
        "                decoder_input_ids = decoder_input_ids.to(self.decoder.first_device)\n",
        "            if attention_mask is not None:\n",
        "                attention_mask = attention_mask.to(self.decoder.first_device)\n",
        "            if decoder_attention_mask is not None:\n",
        "                decoder_attention_mask = decoder_attention_mask.to(self.decoder.first_device)\n",
        "\n",
        "        # Decode\n",
        "        decoder_outputs = self.decoder(\n",
        "            input_ids=decoder_input_ids,\n",
        "            attention_mask=decoder_attention_mask,\n",
        "            inputs_embeds=decoder_inputs_embeds,\n",
        "            past_key_values=past_key_values,\n",
        "            encoder_hidden_states=hidden_states,\n",
        "            encoder_attention_mask=attention_mask,\n",
        "            head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        sequence_output = decoder_outputs[0]\n",
        "\n",
        "        # Set device for model parallelism\n",
        "        if self.model_parallel:\n",
        "            torch.cuda.set_device(self.encoder.first_device)\n",
        "            self.lm_head = self.lm_head.to(self.encoder.first_device)\n",
        "            sequence_output = sequence_output.to(self.lm_head.weight.device)\n",
        "\n",
        "        if self.config.tie_word_embeddings:\n",
        "            # Rescale output before projecting on vocab\n",
        "            # See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\n",
        "            sequence_output = sequence_output * (self.model_dim**-0.5)\n",
        "\n",
        "        lm_logits = self.lm_head(sequence_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.loss_reduction_method=='sentence':\n",
        "                loss_fct = CrossEntropyLoss(ignore_index=-100,reduction='none')\n",
        "                loss_perout = loss_fct(lm_logits.transpose(-1,-2), labels)\n",
        "                cnt=(labels!=-100).sum(-1)\n",
        "                cnt[cnt == 0] = 1 #avoid nan for reduction\n",
        "                loss=(loss_perout.sum(-1) / cnt).mean()\n",
        "                if loss>50:\n",
        "                    print(loss_perout)\n",
        "                    print(loss)\n",
        "            elif self.config.loss_reduction_method=='token':\n",
        "                loss_fct = CrossEntropyLoss(ignore_index=-100)\n",
        "                loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
        "            else:\n",
        "                raise ValueError('Not supported loss reduction method yet')\n",
        "            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (lm_logits,) + decoder_outputs[1:] + encoder_outputs\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return Seq2SeqLMOutput(\n",
        "            loss=loss,\n",
        "            logits=lm_logits,\n",
        "            past_key_values=decoder_outputs.past_key_values,\n",
        "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
        "            decoder_attentions=decoder_outputs.attentions,\n",
        "            cross_attentions=decoder_outputs.cross_attentions,\n",
        "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
        "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
        "            encoder_attentions=encoder_outputs.attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORD3ctD8qjxo"
      },
      "outputs": [],
      "source": [
        "def get_model(args,graph_args,tokenizer):\n",
        "  if args.model_name_or_path=='haitengzhao/gimlet':\n",
        "    model = GraphT5TransformerForConditionalGeneration.from_pretrained(args.model_name_or_path)\n",
        "  else: #load from local file:\n",
        "    config_kwargs = {\"cache_dir\": None, \"revision\": 'main', \"use_auth_token\":  None}\n",
        "    config = AutoConfig.from_pretrained(\"t5-small\", **config_kwargs)\n",
        "    config.vocab_size=len(tokenizer)\n",
        "    graph_args.transformer_backbone = \"gimlet\"\n",
        "    config.graph_args = vars(graph_args)  #use the user-provided graph args\n",
        "    model = GraphT5TransformerForConditionalGeneration.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "        config=config,\n",
        "        cache_dir=None,\n",
        "        revision='main',\n",
        "        use_auth_token=None,\n",
        "        ignore_mismatched_sizes=True)\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzW7jWxwrlII"
      },
      "source": [
        "### Model Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O57TI_9IrMS9"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class GIMLETConfig:\n",
        "    num_classes: int = field(\n",
        "        default=-1,\n",
        "        metadata={\"help\": \"number of classes or regression targets\"},\n",
        "    )\n",
        "\n",
        "    max_nodes: int = field(\n",
        "        default=128,\n",
        "        metadata={\"help\": \"max nodes per graph\"},\n",
        "    )\n",
        "\n",
        "\n",
        "    num_atoms: int = field(\n",
        "        default=512 * 9,\n",
        "        metadata={\"help\": \"number of atom types in the graph\"},\n",
        "    )\n",
        "\n",
        "    num_edges: int = field(\n",
        "        default=512 * 3,\n",
        "        metadata={\"help\": \"number of edge types in the graph\"},\n",
        "    )\n",
        "\n",
        "    num_in_degree: int = field(\n",
        "        default=512,\n",
        "        metadata={\"help\": \"number of in degree types in the graph\"},\n",
        "    )\n",
        "\n",
        "    num_out_degree: int = field(\n",
        "        default=512,\n",
        "        metadata={\"help\": \"number of out degree types in the graph\"},\n",
        "    )\n",
        "\n",
        "    num_spatial: int = field(\n",
        "        default=512,\n",
        "        metadata={\"help\": \"number of spatial types in the graph\"},\n",
        "    )\n",
        "\n",
        "    num_edge_dis: int = field(\n",
        "        default=128,\n",
        "        metadata={\"help\": \"number of edge dis types in the graph\"},\n",
        "    )\n",
        "\n",
        "    multi_hop_max_dist: int = field(\n",
        "        default=5,\n",
        "        metadata={\"help\": \"max distance of multi-hop edges\"},\n",
        "    )\n",
        "\n",
        "    spatial_pos_max: int = field(\n",
        "        default=1024,\n",
        "        metadata={\"help\": \"max distance of multi-hop edges\"},\n",
        "    )\n",
        "\n",
        "    edge_type: str = field(\n",
        "        default=\"multi_hop\",\n",
        "        metadata={\"help\": \"edge type in the graph\"},\n",
        "    )\n",
        "\n",
        "    dropout: float = field(default=0.0)\n",
        "\n",
        "    encoder_embed_dim: int = field(\n",
        "        default=0,\n",
        "    )\n",
        "\n",
        "    encoder_attention_heads: int = field(\n",
        "        default=0,\n",
        "    )\n",
        "\n",
        "    encoder_layers: int = field(\n",
        "        default=0,\n",
        "    )\n",
        "\n",
        "    encoder_normalize_before: bool = field(\n",
        "        default=False,\n",
        "    )\n",
        "    apply_graphormer_init: bool = field(\n",
        "        default=True,\n",
        "    )\n",
        "\n",
        "    graphonly_problem_type: str = field(default='')\n",
        "\n",
        "    graphonly_readout: str= field(default='mean')\n",
        "\n",
        "    maskt2g: bool = field(default=True)\n",
        "\n",
        "    loss_reduction_method: str = field(default='sentence')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I64ZKwJvBAR"
      },
      "outputs": [],
      "source": [
        "MODEL_CONFIG_CLASSES = list(MODEL_FOR_MASKED_LM_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
        "def load_graph_args(args,left):\n",
        "    assert args.transformer_backbone in ['gimlet']\n",
        "    parsernew = HfArgumentParser(GIMLETConfig)\n",
        "    graph_args = parsernew.parse_args(left)\n",
        "    return args,graph_args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJGG8zurnf_u"
      },
      "source": [
        "### Model Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLBM6b1YryiC"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
        "    \"\"\"\n",
        "\n",
        "    model_name_or_path: Optional[str] = field(\n",
        "        default=\"t5-small\",\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"The model checkpoint for weights initialization. Don't set if you want to train a model from scratch.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    config_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
        "    )\n",
        "    cache_dir: Optional[str] = field(\n",
        "        default=\"cache_dir\",\n",
        "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
        "    )\n",
        "\n",
        "    transformer_backbone: str = field(default='gimlet')\n",
        "\n",
        "    attention_fasion: str= field(default='sequential')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlPnXM5EnqDX"
      },
      "source": [
        "### Data Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32WCHYgVr1au"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "    dataset_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
        "    )\n",
        "    dataset_config_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
        "    )\n",
        "    train_file: Optional[str] = field(default=\"haitengzhao/molecule_property_instruction\", metadata={\"help\": \"The input training data file (a text file).\"})\n",
        "    validation_file: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"},\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
        "    )\n",
        "    validation_split_percentage: Optional[int] = field(\n",
        "        default=5,\n",
        "        metadata={\n",
        "            \"help\": \"The percentage of the train set used as validation set in case there's no validation split\"\n",
        "        },\n",
        "    )\n",
        "    max_seq_length: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "                \"than this will be truncated.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    preprocessing_num_workers: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
        "    )\n",
        "    mlm_probability: float = field(\n",
        "        default=0.15, metadata={\"help\": \"Ratio of tokens to mask for masked language modeling loss\"}\n",
        "    )\n",
        "    pad_to_max_length: bool = field(\n",
        "        default=False,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"Whether to pad all samples to `max_seq_length`. \"\n",
        "                \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    max_train_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
        "                \"value if set.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    max_eval_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
        "                \"value if set.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    rich_features: Optional[bool] = field(default=False)\n",
        "    transform_in_collator: Optional[bool] = field(default=True)\n",
        "    wrap_dataset: Optional[bool] = field(default=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpI1meEfkXwU"
      },
      "source": [
        "## Training\n",
        "\n",
        "### Hyperparams\n",
        "* Batch size 128\n",
        "* Learning rate 5e-5\n",
        "* Number of finetune epoch 2\n",
        "* Adam beta1 0.9, beta2 0.999\n",
        "\n",
        "### Computational requirements\n",
        "\n",
        "It needs 40GB GPU to train at batch size 128 and ~7min to train on epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYpZGzbEsIA5"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "def train_model(model, tokenizer, data_collator, model_args, data_args, training_args, graph_args, train_dataset, eval_dataset):\n",
        "    log_level = training_args.get_process_log_level()\n",
        "    logger.setLevel(log_level)\n",
        "    datasets.utils.logging.set_verbosity(log_level)\n",
        "    transformers.utils.logging.set_verbosity(log_level)\n",
        "    transformers.utils.logging.enable_default_handler()\n",
        "    transformers.utils.logging.enable_explicit_format()\n",
        "\n",
        "\n",
        "    # Set seed before initializing model.\n",
        "    set_seed(training_args.seed)\n",
        "\n",
        "    def preprocess_logits_for_metrics(logits, labels):\n",
        "      if isinstance(logits, tuple):\n",
        "        logits = logits[0]\n",
        "        return logits.argmax(dim=-1)\n",
        "\n",
        "    # Initialize our Trainer\n",
        "    # train_dataset, eval_dataset = load_training_dataset(data_args, training_args, dataset=\"tox21\", few_shot = 2)\n",
        "    training_args.remove_unused_columns=False\n",
        "    training_args.per_device_train_batch_size = 128\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        # compute_metrics=compute_metrics if training_args.do_eval and not is_torch_tpu_available() else None,\n",
        "        preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
        "        if training_args.do_eval and not is_torch_tpu_available()\n",
        "        else None)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    last_checkpoint = None\n",
        "    if training_args.do_train:\n",
        "        checkpoint = None\n",
        "        if training_args.resume_from_checkpoint is not None:\n",
        "            checkpoint = training_args.resume_from_checkpoint\n",
        "        elif last_checkpoint is not None:\n",
        "            checkpoint = last_checkpoint\n",
        "        print('last_checkpoint: {}'.format(last_checkpoint))\n",
        "        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
        "        trainer.save_model()  # Saves the tokenizer too for easy upload\n",
        "        metrics = train_result.metrics\n",
        "\n",
        "        max_train_samples = (\n",
        "            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
        "        )\n",
        "        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
        "\n",
        "        trainer.log_metrics(\"train\", metrics)\n",
        "        trainer.save_metrics(\"train\", metrics)\n",
        "        trainer.save_state()\n",
        "\n",
        "    kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"fill-mask\"}\n",
        "    if data_args.dataset_name is not None:\n",
        "        kwargs[\"dataset_tags\"] = data_args.dataset_name\n",
        "        if data_args.dataset_config_name is not None:\n",
        "            kwargs[\"dataset_args\"] = data_args.dataset_config_name\n",
        "            kwargs[\"dataset\"] = f\"{data_args.dataset_name} {data_args.dataset_config_name}\"\n",
        "        else:\n",
        "            kwargs[\"dataset\"] = data_args.dataset_name\n",
        "\n",
        "    trainer.create_model_card(**kwargs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDP-zrJYZ-rU"
      },
      "outputs": [],
      "source": [
        "label_ignore = [-100]\n",
        "raw_label = {1: 'Yes', 0: 'No', 'invalid': label_ignore}\n",
        "label_y = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(raw_label[1])) # Not include CLS or other tokens\n",
        "label_n = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(raw_label[0]))\n",
        "# input a list so that they can be concatenated in collator\n",
        "label_dict = {1: label_y, 0: label_n, 'invalid': label_ignore}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQHpfCcaIZRd"
      },
      "outputs": [],
      "source": [
        "faulthandler.enable()\n",
        "\n",
        "check_min_version(\"4.24.0.dev0\")\n",
        "require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/language-modeling/requirements.txt\")\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gQT2-ZpSMq7"
      },
      "outputs": [],
      "source": [
        "do_train=False\n",
        "few_shot = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss7BYOmivLdX",
        "outputId": "850e7dd5-ea90-4f65-9681-f36b39fcf07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
        "model_name_or_path = f\"drive/MyDrive/DL4H_Team_136/gimlet_tox21_{few_shot}shot\"\n",
        "if do_train:\n",
        "  model_name_or_path = \"haitengzhao/gimlet\"\n",
        "model_args, data_args, training_args = parser.parse_dict({\"model_name_or_path\": model_name_or_path,\"output_dir\": \"ckpts/gimlet_tox21_4shot\", \"do_train\": do_train, \"num_train_epochs\": 2, \"overwrite_output_dir\": False, \"train_file\": \"/content/drive/MyDrive/chembl_dataset/tox21.parquet\"})\n",
        "model_args,graph_args=load_graph_args(model_args,\"\")\n",
        "model=get_model(model_args, graph_args, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuC2dtd075J_"
      },
      "outputs": [],
      "source": [
        "train_dataset, eval_dataset, test_dataset = load_training_dataset(data_args, training_args, dataset=\"tox21\", few_shot = few_shot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv8A30MmyUT5"
      },
      "outputs": [],
      "source": [
        "# main()\n",
        "if do_train:\n",
        "  train_model(model, tokenizer, data_collator,model_args, data_args, training_args,graph_args, train_dataset, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8sl6KxLFTmN"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYOD1lOOoVES"
      },
      "source": [
        "## Evaluation\n",
        "### Metrics descriptions\n",
        "Both train and test data split contains, molecule graph representation, prompt and binary label.\n",
        "\n",
        "We use roc_auc_score(https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) metrices to evaluation the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "z2cxg0k_oe1R",
        "outputId": "5ba4927b-32d8-4f28-e49e-2c3675ebb7dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               graph label dataset_name  \\\n",
              "0  NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)([O-])OP(...    No        tox21   \n",
              "1                    Cl/C=C\\C[N+]12CN3CN(CN(C3)C1)C2    No        tox21   \n",
              "2        CN[C@@H]1C[C@@H](c2ccc(Cl)c(Cl)c2)c2ccccc21    No        tox21   \n",
              "3  CCOc1ccc(N=Nc2ccc(C=Cc3ccc(N=Nc4ccc(OCC)cc4)cc...    No        tox21   \n",
              "4  O=C(Nc1ccc2c(O)c(N=Nc3ccc(N=Nc4ccc(S(=O)(=O)[O...    No        tox21   \n",
              "\n",
              "  task_index molecule_index split  \\\n",
              "0          0             10  test   \n",
              "1          0             14  test   \n",
              "2          0             23  test   \n",
              "3          0             52  test   \n",
              "4          0             54  test   \n",
              "\n",
              "                                           input_ids  \\\n",
              "0  [7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...   \n",
              "1  [7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...   \n",
              "2  [7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...   \n",
              "3  [7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...   \n",
              "4  [7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...   \n",
              "\n",
              "                                      attention_mask  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "\n",
              "                                 special_tokens_mask    labels  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [465, 1]  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [465, 1]  \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [465, 1]  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [465, 1]  \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [465, 1]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2dd6e41-db25-417e-9c93-7b67fb66faa7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>graph</th>\n",
              "      <th>label</th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>task_index</th>\n",
              "      <th>molecule_index</th>\n",
              "      <th>split</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>special_tokens_mask</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)([O-])OP(...</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>test</td>\n",
              "      <td>[7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[465, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cl/C=C\\C[N+]12CN3CN(CN(C3)C1)C2</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>test</td>\n",
              "      <td>[7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[465, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CN[C@@H]1C[C@@H](c2ccc(Cl)c(Cl)c2)c2ccccc21</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>test</td>\n",
              "      <td>[7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[465, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCOc1ccc(N=Nc2ccc(C=Cc3ccc(N=Nc4ccc(OCC)cc4)cc...</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>test</td>\n",
              "      <td>[7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[465, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O=C(Nc1ccc2c(O)c(N=Nc3ccc(N=Nc4ccc(S(=O)(=O)[O...</td>\n",
              "      <td>No</td>\n",
              "      <td>tox21</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>test</td>\n",
              "      <td>[7545, 3822, 35, 15102, 491, 6977, 41, 3316, 3...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[465, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2dd6e41-db25-417e-9c93-7b67fb66faa7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2dd6e41-db25-417e-9c93-7b67fb66faa7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2dd6e41-db25-417e-9c93-7b67fb66faa7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98ec6d85-dbb4-453b-9e16-2c73be3b0d63\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98ec6d85-dbb4-453b-9e16-2c73be3b0d63')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98ec6d85-dbb4-453b-9e16-2c73be3b0d63 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"test_dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"graph\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Cl/C=C\\\\C[N+]12CN3CN(CN(C3)C1)C2\",\n          \"O=C(Nc1ccc2c(O)c(N=Nc3ccc(N=Nc4ccc(S(=O)(=O)[O-])cc4)cc3)c(S(=O)(=O)[O-])cc2c1)c1ccccc1\",\n          \"CN[C@@H]1C[C@@H](c2ccc(Cl)c(Cl)c2)c2ccccc21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"tox21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"task_index\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"molecule_index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"special_tokens_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "test_dataset.to_pandas().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bYr8tbWjpKn"
      },
      "outputs": [],
      "source": [
        "def eval_result(model, data_loader,label_dict,tokenizer):\n",
        "  model.eval()\n",
        "  y_true, y_scores = [], []\n",
        "\n",
        "  id_y=label_dict[1][0]\n",
        "  id_n=label_dict[0][0]\n",
        "  id_invalid=label_dict['invalid'][0]\n",
        "\n",
        "  for step, batch in enumerate(data_loader):\n",
        "    # print(batch)\n",
        "    for key in batch.keys():\n",
        "      batch[key] = batch[key].to(model.device)\n",
        "    with torch.no_grad():\n",
        "      labels=batch[\"labels\"]\n",
        "      if labels.shape[1]>1: # Yes <s>\n",
        "        assert all((labels[:,1]==tokenizer.eos_token_id) + (labels[:,1]==id_invalid))\n",
        "        labels=labels[:,0].unsqueeze(1)\n",
        "        del batch[\"labels\"]\n",
        "\n",
        "      batch[\"max_length\"] = 3 # <PAD> CLASS <EOS>\n",
        "      output = model.generate(**batch, output_scores=True, return_dict_in_generate=True)\n",
        "      logits=output.scores[0].unsqueeze(1) #logits of CLASS\n",
        "\n",
        "      index = labels != id_invalid #mask both text not answer and invalid labels; shape: [batch,answer length]\n",
        "\n",
        "      assert logits[index].ndim==2 # selected answer shape:[n_valid_sample,n_vocabulary]\n",
        "\n",
        "      pred = (logits[index][:, id_y] - logits[index][:, id_n]).view([-1,1])\n",
        "      true = labels[index].view(pred.shape)\n",
        "      true[true == id_y] = 1\n",
        "      true[true == id_n] = 0\n",
        "      true[true == id_invalid] = -100\n",
        "      y_true.append(true)\n",
        "      y_scores.append(pred)\n",
        "\n",
        "  y_true = torch.cat(y_true, dim=0).cpu().numpy()\n",
        "  y_scores = torch.cat(y_scores, dim=0).cpu().numpy()\n",
        "\n",
        "  roc_list = []\n",
        "  for i in range(y_true.shape[1]):\n",
        "    # AUC is only defined when there is at least one positive data.\n",
        "    if np.sum(y_true[:, i] == 1) > 0 and np.sum(y_true[:, i] == 0) > 0:\n",
        "      is_valid = y_true[:, i]  >= 0\n",
        "      roc_list.append(roc_auc_score(y_true[is_valid, i], y_scores[is_valid, i]))\n",
        "    else:\n",
        "      print('{} is invalid'.format(i))\n",
        "\n",
        "  if len(roc_list) < y_true.shape[1]:\n",
        "    print(len(roc_list))\n",
        "    print('Some target is missing!')\n",
        "    print('Missing ratio: %f' % (1 - float(len(roc_list)) / y_true.shape[1]))\n",
        "\n",
        "  if len(roc_list)==0:\n",
        "    return {'score':0},0, y_true, y_scores\n",
        "  else:\n",
        "    return {'score':sum(roc_list) / len(roc_list)}, 0, y_true, y_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6bCcZNuxmz"
      },
      "source": [
        "# Results\n",
        "In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
        "\n",
        "Please test and report results for all experiments that you run with:\n",
        "\n",
        "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
        "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z45xt0c0XjvT"
      },
      "outputs": [],
      "source": [
        "def load_test_dataset(dataset, step=50):\n",
        "  model_args, data_args, training_args = parser.parse_dict({\"model_name_or_path\": model_name_or_path,\"output_dir\": \"ckpts/gimlet_tox21_4shot\", \"do_train\": do_train, \"num_train_epochs\": 2, \"overwrite_output_dir\": False, \"train_file\": f\"/content/drive/MyDrive/chembl_dataset/{dataset}.parquet\"})\n",
        "  _, _, test_dataset = load_training_dataset(data_args, training_args, dataset=dataset, few_shot = few_shot)\n",
        "  subrange = list(range(0, len(test_dataset), step))\n",
        "  test_dataset_subset = torch.utils.data.Subset(test_dataset, subrange)\n",
        "  test_loader = DataLoader(test_dataset_subset, batch_size=10,shuffle=False, num_workers=1,collate_fn=data_collator)\n",
        "  return test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkF7F90XXxyA"
      },
      "outputs": [],
      "source": [
        "def load_and_evaluate_model(few_shot, test_loader):\n",
        "  if few_shot == 0:\n",
        "    model_name_or_path = f\"haitengzhao/gimlet\"\n",
        "  else:\n",
        "    model_name_or_path = f\"drive/MyDrive/DL4H_Team_136/gimlet_tox21_{few_shot}shot\"\n",
        "  model_args, data_args, training_args = parser.parse_dict({\"model_name_or_path\": model_name_or_path,\"output_dir\": \"ckpts/gimlet_tox21_4shot\", \"do_train\": do_train, \"num_train_epochs\": 2, \"overwrite_output_dir\": False, \"train_file\": \"/content/drive/MyDrive/chembl_dataset/tox21.parquet\"})\n",
        "  model_args,graph_args=load_graph_args(model_args,\"\")\n",
        "  model=get_model(model_args, graph_args, tokenizer)\n",
        "  roc_auc, _, _, _ = eval_result(model, test_loader,label_dict,tokenizer)\n",
        "  if few_shot == 0:\n",
        "    print(f\"zero shot model ruc_auc score: {roc_auc}\")\n",
        "  else:\n",
        "    print(f\"few shot: {few_shot} ruc_auc score: {roc_auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG88H5tUPXIV"
      },
      "source": [
        "### Original Dataset Eval on Paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAaj_9lVMJc1"
      },
      "source": [
        "#### hiv dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "31da256a6eba45cc8470e481c33a70d6",
            "78e7466ad3664cd990ce9b59e358b592",
            "36794df33ea1448d87554644d71f2fc4",
            "9bd153b895a140e298f199a64e9615a5",
            "34899f80fe9640d2b04131d0218c5f8c",
            "78f689adee16442e8b959751f9e25046",
            "52d0584b16ba43c6adcb897539acbc9b",
            "814d6a9f9aa6421cbb05150660ee617d",
            "aa1072d9fc094813a414ebd25499a2b3",
            "b693678feaaf4ce5be738cdbc6f92083",
            "a52109d410b9431e9263d1baf0a35ad7"
          ]
        },
        "id": "Q2-DmBuyIWh5",
        "outputId": "8946e99e-cb95-4c44-dab4-2d60ba5bf7f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on dataset line_by_line:   0%|          | 0/4113 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31da256a6eba45cc8470e481c33a70d6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "test_loader = load_test_dataset(\"hiv\", step=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fraesvBIb5r",
        "outputId": "f57f6bb2-370d-4f59-f060-fd51aad6be68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zero shot model ruc_auc score: {'score': 0.5412464512640259}\n"
          ]
        }
      ],
      "source": [
        "# currently using 2% of test data, use 20% test data ruc score is 0.568\n",
        "load_and_evaluate_model(few_shot=0, test_loader=test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrVRm2VXMMhd"
      },
      "source": [
        "#### tox21 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duWNUU4lLNet",
        "outputId": "3b1bc6ab-7fbe-4976-a906-3b0128719869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "test_loader = load_test_dataset(\"tox21\", step=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBEsYS2eLW3A",
        "outputId": "b8a9c57b-80d8-420e-b26e-395756fcc2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zero shot model ruc_auc score: {'score': 0.5669673837612769}\n"
          ]
        }
      ],
      "source": [
        "# currently using 2% of test data, use 20% test data ruc score is 0.595\n",
        "load_and_evaluate_model(few_shot=0, test_loader=test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ta9egwgPQis"
      },
      "source": [
        "#### toxcast dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgyMO35IMSom",
        "outputId": "a45908d0-5a7b-445c-ec5f-28a1a82a0424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "test_loader = load_test_dataset(\"toxcast\", step=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUGu0DKiMXII",
        "outputId": "5e6b6e5c-438d-4000-f7cf-512489c3d275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zero shot model ruc_auc score: {'score': 0.4984683932052353}\n"
          ]
        }
      ],
      "source": [
        "# currently using 2% of test data, use 20% test data ruc score is 0.535\n",
        "load_and_evaluate_model(few_shot=0, test_loader=test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUbN8r0gYnM5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exP3t7uWZBVW"
      },
      "source": [
        "### Few shot vs Zero shot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOmZirFQPhRG",
        "outputId": "20731dfe-1ff8-45f1-9308-dffc2101b218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "test_loader = load_test_dataset(\"tox21\", step=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuiaZOrKih0i",
        "outputId": "0444006e-6120-4be6-f57f-c523849e2e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zero shot model ruc_auc score: {'score': 0.5669673837612769}\n"
          ]
        }
      ],
      "source": [
        "load_and_evaluate_model(few_shot=0, test_loader=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7nITqExqduM",
        "outputId": "2c682d8c-d681-4feb-c8ef-c3779a915da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "few shot: 4 ruc_auc score: {'score': 0.8327550312283136}\n"
          ]
        }
      ],
      "source": [
        "load_and_evaluate_model(few_shot=4, test_loader=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IgOLSpPqeuG",
        "outputId": "d936d450-4773-4e75-8885-1e3ebb61160d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "few shot: 8 ruc_auc score: {'score': 0.8952116585704373}\n"
          ]
        }
      ],
      "source": [
        "load_and_evaluate_model(few_shot=8,test_loader=test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tsY0XF1skwE"
      },
      "source": [
        "### Prompt Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptfrx_VWpOGz"
      },
      "outputs": [],
      "source": [
        "def merge_augment_prompt_with_test_set(dataset):\n",
        "  with open(\"/content/drive/MyDrive/DL4H_Team_136/chembl_dataset/augmented_prompt_downstream_task.json\", \"r\") as f:\n",
        "    augment_test_daset = commentjson.load(f)\n",
        "    augment_test_df = {\n",
        "      \"task_index\": [],\n",
        "      \"augment\": [],\n",
        "      \"prompt\": [],\n",
        "      \"input_ids\": [],\n",
        "      \"attention_mask\": []\n",
        "    }\n",
        "    for task_index, augment in augment_test_daset[dataset].items():\n",
        "      for aug, prompts in augment.items():\n",
        "        for prompt in prompts:\n",
        "          augment_test_df[\"task_index\"].append(task_index)\n",
        "          augment_test_df[\"augment\"].append(aug)\n",
        "          augment_test_df[\"prompt\"].append(prompt)\n",
        "          prompt_token=tokenizer(prompt,return_special_tokens_mask=True)\n",
        "          augment_test_df[\"input_ids\"].append([item for item in prompt_token.data['input_ids']])\n",
        "          augment_test_df[\"attention_mask\"].append(prompt_token.data['attention_mask'])\n",
        "    augment_test_df = pd.DataFrame.from_dict(augment_test_df)\n",
        "    test_dataset_df = test_dataset.to_pandas()\n",
        "    result_df = pd.merge(test_dataset_df, augment_test_df, on='task_index', how='inner')\n",
        "    # print(result_df.head())\n",
        "    result_df = result_df.drop([\"input_ids_x\",\"attention_mask_x\"], axis=1).rename(columns={\"input_ids_y\": \"input_ids\", \"attention_mask_y\": \"attention_mask\"})\n",
        "    return datasets.Dataset.from_pandas(result_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlmd4ERZvWyB"
      },
      "outputs": [],
      "source": [
        "augment_test_dataset = merge_augment_prompt_with_test_set(\"tox21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "32ac15a966b44e8ab28a1fc6e56eebc7",
            "be23b2d74055424e9d2371076f2ef6e8",
            "9e35251e81e4410e9a5e987f6cfc2ba5",
            "f6f618f4028f4a03bf1a779eb318298f",
            "9a2c561a24ab491ba537ddb78ea72b6f",
            "dc2a2dfe2bb2494b904d26d614322f30",
            "6fd9244165f74b548dcfe1876aabc24a",
            "d67c6040b2b840ed8ab78c0e84620478",
            "20f606de59d947c88fcbceb34b6d3222",
            "e225a55ec9f64f02bd0aa4945b072d8a",
            "53e60239b50b48c6896a5651401caab0"
          ]
        },
        "id": "Y4xx4bep0-R9",
        "outputId": "29e2849d-7413-4e5b-a236-16f64a28659d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/103425 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32ac15a966b44e8ab28a1fc6e56eebc7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "orig_test_dataset = augment_test_dataset.filter(lambda x: x[\"augment\"] == \"origin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lbwqYYQ2kWn"
      },
      "outputs": [],
      "source": [
        "def eval_augment_test_set(augment):\n",
        "  dataset = augment_test_dataset.filter(lambda x: x[\"augment\"] == augment)\n",
        "  subrange = list(range(0, len(dataset), 50))\n",
        "  dataset_subset = torch.utils.data.Subset(dataset, subrange)\n",
        "  data_loader = DataLoader(dataset_subset, batch_size=10,shuffle=False, num_workers=1,collate_fn=data_collator)\n",
        "  roc_auc, _, _, _ = eval_result(model, data_loader,label_dict,tokenizer)\n",
        "  print(f\"model ruc_auc score: {roc_auc} on {augment} prompt set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGMKp_QsvlgI",
        "outputId": "9d1c7927-41c4-43cb-8945-a0c618c0433d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "few_shot = 4\n",
        "model_name_or_path = f\"drive/MyDrive/DL4H_Team_136/gimlet_tox21_{few_shot}shot\"\n",
        "model_args, data_args, training_args = parser.parse_dict({\"model_name_or_path\": model_name_or_path,\"output_dir\": \"ckpts/gimlet_tox21_4shot\", \"do_train\": do_train, \"num_train_epochs\": 2, \"overwrite_output_dir\": False, \"train_file\": \"/content/drive/MyDrive/chembl_dataset/tox21.parquet\"})\n",
        "model_args,graph_args=load_graph_args(model_args,\"\")\n",
        "model=get_model(model_args, graph_args, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "e2563afc7e8a420c8d66fa9576320359",
            "f9ca63f8105741d0b28e22db088ffcf3",
            "a0b756f1344f4f4bad4993d872646a65",
            "3f4c240bfd7a4392ad252e27695334f6",
            "97710809bef24406b8b22a8a1d0994e9",
            "b9fb196ca21d4510887f0b44874c73ad",
            "6442f4b30d11430e93106b4d71454ec7",
            "8f87b377e69e4631bd67d5ab435af2e2",
            "05fb07a2cf2e40e19a748ddd9466c8ab",
            "d67713ffec6640cd81f1923077e9c61a",
            "788a826771d5474aacbadbcd6e082a49"
          ]
        },
        "id": "rghuGeqdhko9",
        "outputId": "fabec4a7-4a83-400a-aa59-98a1fc04b658"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/103425 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2563afc7e8a420c8d66fa9576320359"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model ruc_auc score: {'score': 0.7428696796840719} on origin prompt set\n"
          ]
        }
      ],
      "source": [
        "eval_augment_test_set(\"origin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "c0a947372b6f4992ba939e250b334b3a",
            "17d0fd13e9bb4d5ba3e2f2e8d7403fda",
            "58f2b80a60b94401a4541bb84c06374a",
            "5e6ce1fdc4c94b91baaa934a05cec756",
            "76bcb65946004f44862d0f1d3d8883c9",
            "999a2178326a442794547c507fa8a63e",
            "74a2ea4ee8ea4bffb3a17744fc2cbfa8",
            "85dca619e364411e90ff12c22e9cf171",
            "1f7b575716a748b7b7dbbc1c4a47c6ee",
            "07b37ff7bbbd4a9eb5127f1c56d581ba",
            "4d9e8e8c4c0a450c8435801bd63a8cd2"
          ]
        },
        "id": "EQD4mTrzhoZq",
        "outputId": "d8fcce6a-7f7f-45ff-ec81-4ab6cf098e09"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/103425 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0a947372b6f4992ba939e250b334b3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model ruc_auc score: {'score': 0.7334043753525982} on rewrite prompt set\n"
          ]
        }
      ],
      "source": [
        "eval_augment_test_set(\"rewrite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "3aabe650555646388fc1edcb6d4ca0be",
            "ddc8b8b7025142379cbe02a4ea131d1f",
            "aa36e70da0c647cb8394072af91284f8",
            "b21789b292094aedabcea7ed6bec626b",
            "999d84fc098547f58152087740383494",
            "12689a03a3964859bc9f0691230deccf",
            "29c9878c060342c2ac2389e4e8f57f4b",
            "aa5e5a8d551f453e9e374ad473a85241",
            "1e8f83494f2548f1b3906bad3e8c3038",
            "b3744df93f19426480b278def2b6fba2",
            "e989c1ef6e2c4ff3be0bb864bd116e4c"
          ]
        },
        "id": "JC08O5IX25D_",
        "outputId": "b45bfef9-13ec-4386-87a5-e1b6d1515541"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/103425 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3aabe650555646388fc1edcb6d4ca0be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model ruc_auc score: {'score': 0.7586033974800978} on expand prompt set\n"
          ]
        }
      ],
      "source": [
        "eval_augment_test_set(\"expand\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "582379e4abe34703b7a7b63bff563060",
            "1cf756a02b574abea8e3c9fe1f073c52",
            "3c12535b3ad54a269b9ce431eaedc0e5",
            "3bbde523470a4c1b8f57fb6c9ac19230",
            "e75af559f91e47ed805fd39ef18b05da",
            "905ae9d373484d10a7c4ab563c1a54a6",
            "922661d0acd649fa9f4785cf342f820e",
            "1feda1a343a14463bade6620462581b2",
            "6f3192935cd24e438b7ee3d3c104eb9c",
            "f2cdfe4aff9c41a5852aa535255fe614",
            "d5b3d010272b4a108d1494fec2166437"
          ]
        },
        "id": "9ZSSdvCP2-1d",
        "outputId": "a091f79b-498c-450b-c0b0-333dd35a50b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/103425 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "582379e4abe34703b7a7b63bff563060"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model ruc_auc score: {'score': 0.73421926910299} on detail prompt set\n"
          ]
        }
      ],
      "source": [
        "eval_augment_test_set(\"detail\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "22ebeb2718644a5f96ca23f2ebc2e33b",
            "76b25667c70b4fbf8409c0e8a2dee34a",
            "20d392f8cfae4690a0f95609278d759d",
            "acbd423057954062a5203951698230b9",
            "f02ae78f2d774fb0bbf1ea2fa28eb93c",
            "5454244f06ff4d56a486a5fbe774d189",
            "c0c18971f9464a6bb811aa917217b3ab",
            "3cbb7f16c37b4f6781d3799457afd7d1",
            "a88758b866624b49a03a943afb8caf5c",
            "55a031c3dc644f20b267f51f769708e0",
            "07a560aa84e94e4f8c35fb561a340df5"
          ]
        },
        "id": "qvEVyW1S3CH0",
        "outputId": "d6f68afb-ba53-451f-b250-541c4b075bc1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/103425 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22ebeb2718644a5f96ca23f2ebc2e33b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model ruc_auc score: {'score': 0.7107127186109196} on shorten prompt set\n"
          ]
        }
      ],
      "source": [
        "eval_augment_test_set(\"shorten\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0gB6Z_1yN6y"
      },
      "source": [
        "### Molecule Name Ablation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CC0ECs2yJTm"
      },
      "outputs": [],
      "source": [
        "def merge_ablated_prompt_with_test_set(dataset):\n",
        "  with open(\"/content/drive/MyDrive/DL4H_Team_136/chembl_dataset/ablated_prompt_downstream_task.json\", \"r\") as f:\n",
        "    ablated_test_daset = commentjson.load(f)\n",
        "    ablated_test_df = {\n",
        "      \"task_index\": [],\n",
        "      \"prompt\": [],\n",
        "      \"input_ids\": [],\n",
        "      \"attention_mask\": []\n",
        "    }\n",
        "    for task_index, molecule in ablated_test_daset[dataset].items():\n",
        "      for name in molecule[\"name\"]:\n",
        "        ablated_test_df[\"task_index\"].append(task_index)\n",
        "        ablated_test_df[\"prompt\"].append(name)\n",
        "        prompt_token=tokenizer(name,return_special_tokens_mask=True)\n",
        "        ablated_test_df[\"input_ids\"].append([item for item in prompt_token.data['input_ids']])\n",
        "        ablated_test_df[\"attention_mask\"].append(prompt_token.data['attention_mask'])\n",
        "    ablated_test_df = pd.DataFrame.from_dict(ablated_test_df)\n",
        "    test_dataset_df = test_dataset.to_pandas()\n",
        "    result_df = pd.merge(test_dataset_df, ablated_test_df, on='task_index', how='inner')\n",
        "    result_df = result_df.drop([\"input_ids_x\",\"attention_mask_x\"], axis=1).rename(columns={\"input_ids_y\": \"input_ids\", \"attention_mask_y\": \"attention_mask\"})\n",
        "    # print(result_df)\n",
        "    return datasets.Dataset.from_pandas(result_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V6afW3ZyUyg"
      },
      "outputs": [],
      "source": [
        "ablated_test_dataset = merge_ablated_prompt_with_test_set(\"tox21\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmycDhX-ybaw"
      },
      "outputs": [],
      "source": [
        "def eval_ablated_test_set():\n",
        "  subrange = list(range(0, len(ablated_test_dataset), 50))\n",
        "  dataset_subset = torch.utils.data.Subset(ablated_test_dataset, subrange)\n",
        "  data_loader = DataLoader(dataset_subset, batch_size=10,shuffle=False, num_workers=1,collate_fn=data_collator)\n",
        "  roc_auc, _, _, _ = eval_result(model, data_loader,label_dict,tokenizer)\n",
        "  print(f\"model ruc_auc score: {roc_auc} on molecule name only prompt set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8QcMDG2y6zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d572769-3ae6-4400-d907-91a99ed752a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model ruc_auc score: {'score': 0.6881464301385319} on molecule name only prompt set\n"
          ]
        }
      ],
      "source": [
        "eval_ablated_test_set()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original Paper Experiment Result\n",
        "\n",
        "\n",
        "Here is the table of result for zero-shot model against 3 dataset: hiv, tox21 and toxcast. Compare to other models (KVPLM, MoMu, Galactica-125M, Galactica-1.3B).\n",
        "\n",
        "|                | hiv    | tox21  | toxcast |\n",
        "|----------------|--------|--------|---------|\n",
        "| KVPLM          | **0.6120** | 0.4917 | 0.5096  |\n",
        "| MoMu           | 0.5026 | 0.5757 | 0.5238  |\n",
        "| Galactica-125M | 0.3671 | 0.4964 | 0.5106  |\n",
        "| Galactica-1.3B | 0.3385 | 0.4946 | 0.5123  |\n",
        "| *GIMLET(proposed model)*       | 0.568  | **0.595**  | **0.535**   |\n"
      ],
      "metadata": {
        "id": "Fmshu8N5DbV7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muqjxfqNunOM"
      },
      "source": [
        "### Zero shot vs Few shot Result\n",
        "From the below chart we can see, pretrain + few shot model performs much better than pretrain zero shot model. The improvement from 4 shot to 8 shot is not as much."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Xd4UFDnMtJdf",
        "outputId": "537a7291-ea19-41a2-81c6-cf3bc1a00fc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'AUC ROC Score')"
            ]
          },
          "metadata": {},
          "execution_count": 238
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "zeroshot_fewshot_auc_roc = {'Zero Shot': 0.567, '4 Shot': 0.833, '8 Shot': 0.895}\n",
        "x = list(zeroshot_fewshot_auc_roc.keys())\n",
        "y = list(zeroshot_fewshot_auc_roc.values())\n",
        "plt.bar(x, y)\n",
        "plt.xlabel('zero shot vs few shot')\n",
        "plt.ylabel('AUC ROC Score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxnv1q6ku9OG"
      },
      "source": [
        "### Prompt Augmentations Result\n",
        "\n",
        "Compare origin prompts, different prompt augmentations have very little impact of model performance. Out of them, make prompt shorter did hurt model performance a bit. It could because model not able to get enough information from prompt when it got shorter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjKwjYCtu9cr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "0ae7b257-dca6-4409-aae4-4163c33227ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'AUC ROC Score')"
            ]
          },
          "metadata": {},
          "execution_count": 239
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt_augmentation_auc_roc = {'origin': 0.74, 'rewrite': 0.73, 'expand': 0.75, 'detail': 0.73, 'shorten': 0.71}\n",
        "x = list(prompt_augmentation_auc_roc.keys())\n",
        "y = list(prompt_augmentation_auc_roc.values())\n",
        "plt.bar(x, y)\n",
        "plt.xlabel('Different Prompt Augmentations')\n",
        "plt.ylabel('AUC ROC Score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4lQV7ljzoJq"
      },
      "source": [
        "### Prompt vs Molecule name only Ablation Result\n",
        "\n",
        "In this ablation study we compare impact of using the original dataset prompt vs only mentioning molecule name in the prompt on correctly predicting task. Original prompt typically contains some introduction when ask a question while molecule name only prompt ask the same question while only provide molecule name.\n",
        "\n",
        "For example,\n",
        "\n",
        "* original prompt: \"APR_HepG2_CellCycleArrest_24hr, is one of 10 assay component(s) measured or calculated from the APR_HepG2_24hr assay. It is designed to make measurements of cell phenotype, a form of morphology reporter, as detected with fluorescence intensity signals by HCS Fluorescent Imaging technology.Data from the assay component APR_HepG2_CellCycleArrest_24hr was analyzed into 2 assay endpoints. \\nThis assay endpoint, APR_HepG2_CellCycleArrest_24h_dn, was analyzed in the negative fitting direction relative to DMSO as the negative control and baseline of activity. \\nUsing a type of morphology reporter, measures of all nuclear dna for loss-of-signal activity can be used to understand the signaling at the pathway-level as they relate to the gene . \\nFurthermore, this assay endpoint can be referred to as a primary readout, because this assay has produced multiple assay endpoints where this one serves a signaling function. \\nTo generalize the intended target to other relatable targets, this assay endpoint is annotated to the \\\"cell cycle\\\" intended target family, where the subfamily is \\\"proliferation\\\". Is this molecule effective to this assay?\"\n",
        "\n",
        "* molecule name only prompt: \"The assay name is APR_HepG2_CellCycleArrest_24hr. Is this molecule effective to this assay?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5oxUEKc0FQQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "3e34bebc-5570-4fc9-8041-cad84b4f740c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'AUC ROC Score')"
            ]
          },
          "metadata": {},
          "execution_count": 240
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGJklEQVR4nO3deVxWZf7/8fcNsoogioISyrhjLiimoZWWFFk6WmNZY2GojOOSJmlmOVJZg2miLaaTC/Y1TVusnNEspcxUGrfcEkVN01RwTUQLFK7fH/28xzsW7xtR7PR6Ph7348G5znWu8zk3933z5pxzn2MzxhgBAABYhFtFFwAAAFCeCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSKlV0AddaYWGhDh8+rCpVqshms1V0OQAAwAnGGJ05c0a1a9eWm1vp+2b+cOHm8OHDCgsLq+gyAABAGRw8eFA33HBDqX3+cOGmSpUqkn59cvz9/Su4GgAA4IycnByFhYXZ/46X5g8Xbi4eivL39yfcAADwO+PMKSWcUAwAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACylUkUXYDXhTy+p6BKA69b+8fdWdAkA/gDYcwMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACyFcAMAACzlugg3U6dOVXh4uLy9vdWuXTutW7euxL6dOnWSzWYr8rj33nuvYcUAAOB6VeHhZuHChUpMTFRSUpI2bdqkli1bKjY2VkePHi22/6JFi3TkyBH7Y/v27XJ3d9cDDzxwjSsHAADXowoPNykpKUpISFB8fLyaNm2q6dOny9fXV7Nnzy62f7Vq1RQSEmJ/LF++XL6+voQbAAAgqYLDTX5+vjZu3KiYmBh7m5ubm2JiYpSenu7UGLNmzdJDDz2kypUrFzs/Ly9POTk5Dg8AAGBdFRpujh8/roKCAgUHBzu0BwcHKysr67LLr1u3Ttu3b1f//v1L7JOcnKyAgAD7Iyws7IrrBgAA168KPyx1JWbNmqXmzZurbdu2JfYZPXq0Tp8+bX8cPHjwGlYIAACutUoVufKgoCC5u7srOzvboT07O1shISGlLnv27FktWLBAL7zwQqn9vLy85OXldcW1AgCA34cK3XPj6empqKgopaWl2dsKCwuVlpam6OjoUpd9//33lZeXp0ceeeRqlwkAAH5HKnTPjSQlJiaqT58+atOmjdq2baspU6bo7Nmzio+PlyTFxcUpNDRUycnJDsvNmjVLPXr0UPXq1SuibAAAcJ2q8HDTq1cvHTt2TGPHjlVWVpYiIyO1bNky+0nGBw4ckJub4w6mXbt2afXq1fr8888romQAAHAdsxljTEUXcS3l5OQoICBAp0+flr+/f7mPH/70knIfE7CK/eO5kjiAsnHl7/fv+ttSAAAAv0W4AQAAllLh59wAwO8Nh5+B0lX0IWj23AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEup8HAzdepUhYeHy9vbW+3atdO6detK7f/TTz9p8ODBqlWrlry8vNSoUSMtXbr0GlULAACud5UqcuULFy5UYmKipk+frnbt2mnKlCmKjY3Vrl27VLNmzSL98/Pzdeedd6pmzZr64IMPFBoaqh9++EFVq1a99sUDAIDrUoWGm5SUFCUkJCg+Pl6SNH36dC1ZskSzZ8/W008/XaT/7NmzdfLkSa1du1YeHh6SpPDw8FLXkZeXp7y8PPt0Tk5O+W0AAAC47lTYYan8/Hxt3LhRMTEx/yvGzU0xMTFKT08vdpnFixcrOjpagwcPVnBwsJo1a6Z//vOfKigoKHE9ycnJCggIsD/CwsLKfVsAAMD1o8LCzfHjx1VQUKDg4GCH9uDgYGVlZRW7zPfff68PPvhABQUFWrp0qf7xj39o0qRJevHFF0tcz+jRo3X69Gn74+DBg+W6HQAA4PpSoYelXFVYWKiaNWvqrbfekru7u6KionTo0CFNnDhRSUlJxS7j5eUlLy+va1wpAACoKBUWboKCguTu7q7s7GyH9uzsbIWEhBS7TK1ateTh4SF3d3d7W0REhLKyspSfny9PT8+rWjMAALj+VdhhKU9PT0VFRSktLc3eVlhYqLS0NEVHRxe7TIcOHbRnzx4VFhba2zIzM1WrVi2CDQAAkFTB17lJTEzUjBkz9PbbbysjI0MDBw7U2bNn7d+eiouL0+jRo+39Bw4cqJMnT2rYsGHKzMzUkiVL9M9//lODBw+uqE0AAADXmQo956ZXr146duyYxo4dq6ysLEVGRmrZsmX2k4wPHDggN7f/5a+wsDB99tlnGj58uFq0aKHQ0FANGzZMo0aNqqhNAAAA15kKP6F4yJAhGjJkSLHzVq5cWaQtOjpa33zzzVWuCgAA/F5V+O0XAAAAyhPhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWMp1EW6mTp2q8PBweXt7q127dlq3bl2JfefMmSObzebw8Pb2vobVAgCA61mFh5uFCxcqMTFRSUlJ2rRpk1q2bKnY2FgdPXq0xGX8/f115MgR++OHH364hhUDAIDrWYWHm5SUFCUkJCg+Pl5NmzbV9OnT5evrq9mzZ5e4jM1mU0hIiP0RHBx8DSsGAADXswoNN/n5+dq4caNiYmLsbW5uboqJiVF6enqJy+Xm5qpu3boKCwtT9+7d9d1335XYNy8vTzk5OQ4PAABgXRUabo4fP66CgoIie16Cg4OVlZVV7DKNGzfW7Nmz9cknn+idd95RYWGh2rdvrx9//LHY/snJyQoICLA/wsLCyn07AADA9aNM4eann37SzJkzNXr0aJ08eVKStGnTJh06dKhciytOdHS04uLiFBkZqY4dO2rRokWqUaOG/vWvfxXbf/To0Tp9+rT9cfDgwateIwAAqDiVXF1g69atiomJUUBAgPbv36+EhARVq1ZNixYt0oEDB/R///d/To8VFBQkd3d3ZWdnO7RnZ2crJCTEqTE8PDzUqlUr7dmzp9j5Xl5e8vLycromAADw++bynpvExEQ99thj2r17t8NXsO+55x6tWrXKpbE8PT0VFRWltLQ0e1thYaHS0tIUHR3t1BgFBQXatm2batWq5dK6AQCANbm852b9+vXFHgIKDQ0t8TyZ0iQmJqpPnz5q06aN2rZtqylTpujs2bOKj4+XJMXFxSk0NFTJycmSpBdeeEE333yzGjRooJ9++kkTJ07UDz/8oP79+7u8bgAAYD0uhxsvL69iv3GUmZmpGjVquFxAr169dOzYMY0dO1ZZWVmKjIzUsmXL7CcZHzhwQG5u/9vBdOrUKSUkJCgrK0uBgYGKiorS2rVr1bRpU5fXDQAArMdmjDGuLNC/f3+dOHFC7733nqpVq6atW7fK3d1dPXr00G233aYpU6ZcpVLLR05OjgICAnT69Gn5+/uX+/jhTy8p9zEBq9g//t6KLqFc8D4HSnc13uuu/P12+ZybSZMmKTc3VzVr1tTPP/+sjh07qkGDBqpSpYpeeumlMhcNAABQHlw+LBUQEKDly5drzZo12rJli3Jzc9W6dWuHC/EBAABUFJfCzfnz5+Xj46PNmzerQ4cO6tChw9WqCwAAoExcOizl4eGhOnXqqKCg4GrVAwAAcEVcPufm2Wef1TPPPGO/MjEAAMD1xOVzbt544w3t2bNHtWvXVt26dVW5cmWH+Zs2bSq34gAAAFzlcrjp0aPHVSgDAACgfLgcbpKSkq5GHQAAAOXC5XBz0caNG5WRkSFJuvHGG9WqVatyKwoAAKCsXA43R48e1UMPPaSVK1eqatWqkqSffvpJt99+uxYsWFCmWzAAAACUF5e/LfX444/rzJkz+u6773Ty5EmdPHlS27dvV05OjoYOHXo1agQAAHCay3tuli1bphUrVigiIsLe1rRpU02dOlV33XVXuRYHAADgKpf33BQWFsrDw6NIu4eHhwoLC8ulKAAAgLJyOdzccccdGjZsmA4fPmxvO3TokIYPH67OnTuXa3EAAACucjncvPHGG8rJyVF4eLjq16+v+vXr609/+pNycnL0+uuvX40aAQAAnObyOTdhYWHatGmTVqxYoZ07d0qSIiIiuCs4AAC4LpTpOjc2m0133nmn7rzzzvKuBwAA4Iq4fFhq6NCheu2114q0v/HGG3riiSfKoyYAAIAyczncfPjhh+rQoUOR9vbt2+uDDz4ol6IAAADKyuVwc+LECQUEBBRp9/f31/Hjx8ulKAAAgLJyOdw0aNBAy5YtK9L+6aefql69euVSFAAAQFm5fEJxYmKihgwZomPHjumOO+6QJKWlpWnSpEmaMmVKedcHAADgEpfDTd++fZWXl6eXXnpJ48aNkySFh4dr2rRpiouLK/cCAQAAXFGmr4IPHDhQAwcO1LFjx+Tj4yM/P7/yrgsAAKBMXD7n5lI1atTQxo0b9emnn+rUqVPlVRMAAECZOb3n5uWXX1Zubq79UJQxRl26dNHnn38uSapZs6bS0tJ04403Xp1KAQAAnOD0npuFCxeqWbNm9ukPPvhAq1at0tdff63jx4+rTZs2ev75569KkQAAAM5yOtzs27dPLVq0sE8vXbpUPXv2VIcOHVStWjWNGTNG6enpV6VIAAAAZzkdbi5cuCAvLy/7dHp6utq3b2+frl27NhfxAwAAFc7pcFO/fn2tWrVKknTgwAFlZmbqtttus8//8ccfVb169fKvEAAAwAVOn1A8ePBgDRkyRF9//bW++eYbRUdHq2nTpvb5X3zxhVq1anVVigQAAHCW0+EmISFB7u7u+ve//63bbrtNSUlJDvMPHz6svn37lnuBAAAArnDpIn59+/YtMcC8+eab5VIQAADAlbiii/gBAABcbwg3AADAUgg3AADAUgg3AADAUpwONwUFBdq6dat+/vnnIvPOnTunrVu3qrCwsExFTJ06VeHh4fL29la7du20bt06p5ZbsGCBbDabevToUab1AgAA63E63MydO1d9+/aVp6dnkXmenp7q27ev5s+f73IBCxcuVGJiopKSkrRp0ya1bNlSsbGxOnr0aKnL7d+/XyNGjNCtt97q8joBAIB1OR1uZs2apREjRsjd3b3IvEqVKumpp57SW2+95XIBKSkpSkhIUHx8vJo2barp06fL19dXs2fPLnGZgoIC9e7dW88//7zq1atX6vh5eXnKyclxeAAAAOtyOtzs2rVLN998c4nzb7rpJmVkZLi08vz8fG3cuFExMTH/K8jNTTExMaXehPOFF15QzZo11a9fv8uuIzk5WQEBAfZHWFiYSzUCAIDfF6fDzdmzZ0vd63HmzBmdO3fOpZUfP35cBQUFCg4OdmgPDg5WVlZWscusXr1as2bN0owZM5xax+jRo3X69Gn74+DBgy7VCAAAfl+cvkJxw4YNtXbtWrVo0aLY+atXr1bDhg3LrbDinDlzRo8++qhmzJihoKAgp5bx8vJyuJs5AACwNqfDzV//+leNGTNG7du3LxJwtmzZorFjx+qpp55yaeVBQUFyd3dXdna2Q3t2drZCQkKK9N+7d6/279+vbt262dsufkOrUqVK2rVrl+rXr+9SDQAAwFqcDjfDhw/Xp59+qqioKMXExKhJkyaSpJ07d2rFihXq0KGDhg8f7tLKPT09FRUVpbS0NPvXuQsLC5WWlqYhQ4YU6d+kSRNt27bNoW3MmDE6c+aMXn31Vc6nAQAAzocbDw8Pff7555o8ebLmz5+vVatWyRijRo0a6aWXXtITTzwhDw8PlwtITExUnz591KZNG7Vt21ZTpkzR2bNnFR8fL0mKi4tTaGiokpOT5e3trWbNmjksX7VqVUkq0g4AAP6YXLoruIeHh5566imXDz+VplevXjp27JjGjh2rrKwsRUZGatmyZfaTjA8cOCA3Ny6kDAAAnONSuJGkn3/+WcuXL1dmZqYkqXHjxoqJiZGPj0+ZixgyZEixh6EkaeXKlaUuO2fOnDKvFwAAWI9L4Wbx4sXq37+/jh8/7tAeFBSkWbNmOZzoCwAAUBGcPt6zdu1a9ezZU7fddpvWrFmjkydP6uTJk1q9erVuvfVW9ezZU998883VrBUAAOCynN5z8+KLLyo+Pl7/+te/HNrbt2+v9u3ba8CAAXrhhRe0dOnSci8SAADAWU7vufnmm29KPC9GkgYPHlzqLRMAAACuBafDzc8//yx/f/8S5wcEBOiXX34pl6IAAADKyulw07BhQ33xxRclzk9LS7vqt18AAAC4HKfDTXx8vEaMGFHsOTVLlizRU089pccee6w8awMAAHCZ0ycUDxs2TGvXrlXXrl3VuHFjRUREyBijjIwM7d69Wz169NATTzxxFUsFAAC4PKf33Li5uen999/Xu+++q8aNG2vnzp3atWuXmjRponnz5unDDz/kSsIAAKDCuXyF4l69eqlXr15XoxYAAIArVm67WjZt2qSuXbuW13AAAABl4lK4+eyzzzRixAg988wz+v777yVJO3fuVI8ePXTTTTepsLDwqhQJAADgLKcPS82aNUsJCQmqVq2aTp06pZkzZyolJUWPP/64evXqpe3btysiIuJq1goAAHBZTu+5efXVV/Xyyy/r+PHjeu+993T8+HG9+eab2rZtm6ZPn06wAQAA1wWnw83evXv1wAMPSJLuv/9+VapUSRMnTtQNN9xw1YoDAABwlUu3X/D19ZUk2Ww2eXl5qVatWletMAAAgLJw6avgM2fOlJ+fnyTpwoULmjNnjoKCghz6DB06tPyqAwAAcJHT4aZOnTqaMWOGfTokJERz58516GOz2Qg3AACgQjkdbvbv338VywAAACgf3C8BAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYitPh5vDhwxoxYoRycnKKzDt9+rRGjhyp7Ozsci0OAADAVU6Hm5SUFOXk5Mjf37/IvICAAJ05c0YpKSnlWhwAAICrnA43y5YtU1xcXInz4+Li9J///KdcigIAACgrp8PNvn37VKdOnRLn33DDDVzoDwAAVDinw42Pj0+p4WX//v3y8fEpj5oAAADKzOlw065duyL3krrU//3f/6lt27blUhQAAEBZOX1vqREjRujOO+9UQECARo4cqeDgYElSdna2JkyYoDlz5ujzzz+/aoUCAAA4w+lwc/vtt2vq1KkaNmyYJk+eLH9/f9lsNp0+fVoeHh56/fXXdccdd1zNWgEAAC7L6XAjSQMGDFDXrl313nvvac+ePTLGqFGjRurZs6duuOGGq1UjAACA01wKN5IUGhqq4cOHX41aAAAArpjT4ea1114rtj0gIECNGjVSdHR0uRUFAABQVk6Hm8mTJxfb/tNPP+n06dNq3769Fi9erGrVqpVbcQAAAK5y6SJ+xT1OnTqlPXv2qLCwUGPGjClTEVOnTlV4eLi8vb3Vrl07rVu3rsS+ixYtUps2bVS1alVVrlxZkZGRpX5FHQAA/LGUy13B69Wrp/Hjx5fpq+ALFy5UYmKikpKStGnTJrVs2VKxsbE6evRosf2rVaumZ599Vunp6dq6davi4+MVHx+vzz777Eo3AwAAWEC5hBtJqlOnjrKyslxeLiUlRQkJCYqPj1fTpk01ffp0+fr6avbs2cX279Spk+677z5FRESofv36GjZsmFq0aKHVq1df6SYAAAALKLdws23bNtWtW9elZfLz87Vx40bFxMT8ryA3N8XExCg9Pf2yyxtjlJaWpl27dum2224rtk9eXp5ycnIcHgAAwLqcPqG4pFBw+vRpbdy4UU8++aT69Onj0sqPHz+ugoIC+9WOLwoODtbOnTtLXO706dMKDQ1VXl6e3N3d9eabb+rOO+8stm9ycrKef/55l+oCAAC/X06Hm6pVq8pmsxU7z2azqX///nr66afLrbDSVKlSRZs3b1Zubq7S0tKUmJioevXqqVOnTkX6jh49WomJifbpnJwchYWFXZM6AQDAted0uPnyyy+Lbff391fDhg3l5+fn8sqDgoLk7u6u7Oxsh/bs7GyFhISUuJybm5saNGggSYqMjFRGRoaSk5OLDTdeXl7y8vJyuTYAAPD75HS46dix42X7bN++Xc2aNXN65Z6enoqKilJaWpp69OghSSosLFRaWpqGDBni9DiFhYXKy8tzuj8AALAul2+/8FtnzpzRu+++q5kzZ2rjxo0qKChwafnExET16dNHbdq0Udu2bTVlyhSdPXtW8fHxkqS4uDiFhoYqOTlZ0q/n0LRp00b169dXXl6eli5dqrlz52ratGlXuikAAMACyhxuVq1apVmzZunDDz9U7dq1df/992vq1Kkuj9OrVy8dO3ZMY8eOVVZWliIjI7Vs2TL7ScYHDhyQm9v/vtR19uxZDRo0SD/++KN8fHzUpEkTvfPOO+rVq1dZNwUAAFiIzRhjnO2clZWlOXPmaNasWcrJydGDDz6o6dOna8uWLWratOnVrLPc5OTkKCAgQKdPn5a/v3+5jx/+9JJyHxOwiv3j763oEsoF73OgdFfjve7K32+nr3PTrVs3NW7cWFu3btWUKVN0+PBhvf7661dcLAAAQHly+rDUp59+qqFDh2rgwIFq2LDh1awJAACgzJzec7N69WqdOXNGUVFRateund544w0dP378atYGAADgMqfDzc0336wZM2boyJEjGjBggBYsWKDatWursLBQy5cv15kzZ65mnQAAAE5x+d5SlStXVt++fbV69Wpt27ZNTz75pMaPH6+aNWvqz3/+89WoEQAAwGlXdOPMxo0ba8KECfrxxx/17rvvlldNAAAAZVYudwV3d3dXjx49tHjx4vIYDgAAoMzKJdwAAABcLwg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUq6LcDN16lSFh4fL29tb7dq107p160rsO2PGDN16660KDAxUYGCgYmJiSu0PAAD+WCo83CxcuFCJiYlKSkrSpk2b1LJlS8XGxuro0aPF9l+5cqUefvhhffnll0pPT1dYWJjuuusuHTp06BpXDgAArkcVHm5SUlKUkJCg+Ph4NW3aVNOnT5evr69mz55dbP958+Zp0KBBioyMVJMmTTRz5kwVFhYqLS3tGlcOAACuRxUabvLz87Vx40bFxMTY29zc3BQTE6P09HSnxjh37pzOnz+vatWqFTs/Ly9POTk5Dg8AAGBdFRpujh8/roKCAgUHBzu0BwcHKysry6kxRo0apdq1azsEpEslJycrICDA/ggLC7viugEAwPWrwg9LXYnx48drwYIF+uijj+Tt7V1sn9GjR+v06dP2x8GDB69xlQAA4FqqVJErDwoKkru7u7Kzsx3as7OzFRISUuqyr7zyisaPH68VK1aoRYsWJfbz8vKSl5dXudQLAACufxW658bT01NRUVEOJwNfPDk4Ojq6xOUmTJigcePGadmyZWrTps21KBUAAPxOVOieG0lKTExUnz591KZNG7Vt21ZTpkzR2bNnFR8fL0mKi4tTaGiokpOTJUkvv/yyxo4dq/nz5ys8PNx+bo6fn5/8/PwqbDsAAMD1ocLDTa9evXTs2DGNHTtWWVlZioyM1LJly+wnGR84cEBubv/bwTRt2jTl5+erZ8+eDuMkJSXpueeeu5alAwCA61CFhxtJGjJkiIYMGVLsvJUrVzpM79+//+oXBAAAfrd+19+WAgAA+C3CDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsJQKDzdTp05VeHi4vL291a5dO61bt67Evt99953+8pe/KDw8XDabTVOmTLl2hQIAgN+FCg03CxcuVGJiopKSkrRp0ya1bNlSsbGxOnr0aLH9z507p3r16mn8+PEKCQm5xtUCAIDfgwoNNykpKUpISFB8fLyaNm2q6dOny9fXV7Nnzy62/0033aSJEyfqoYcekpeXl1PryMvLU05OjsMDAABYV4WFm/z8fG3cuFExMTH/K8bNTTExMUpPTy+39SQnJysgIMD+CAsLK7exAQDA9afCws3x48dVUFCg4OBgh/bg4GBlZWWV23pGjx6t06dP2x8HDx4st7EBAMD1p1JFF3C1eXl5OX0ICwAA/P5V2J6boKAgubu7Kzs726E9Ozubk4UBAECZVVi48fT0VFRUlNLS0uxthYWFSktLU3R0dEWVBQAAfucq9LBUYmKi+vTpozZt2qht27aaMmWKzp49q/j4eElSXFycQkNDlZycLOnXk5B37Nhh//nQoUPavHmz/Pz81KBBgwrbDgAAcP2o0HDTq1cvHTt2TGPHjlVWVpYiIyO1bNky+0nGBw4ckJvb/3YuHT58WK1atbJPv/LKK3rllVfUsWNHrVy58lqXDwAArkMVfkLxkCFDNGTIkGLn/TawhIeHyxhzDaoCAAC/VxV++wUAAIDyRLgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWcl2Em6lTpyo8PFze3t5q166d1q1bV2r/999/X02aNJG3t7eaN2+upUuXXqNKAQDA9a7Cw83ChQuVmJiopKQkbdq0SS1btlRsbKyOHj1abP+1a9fq4YcfVr9+/fTtt9+qR48e6tGjh7Zv336NKwcAANejCg83KSkpSkhIUHx8vJo2barp06fL19dXs2fPLrb/q6++qrvvvlsjR45URESExo0bp9atW+uNN964xpUDAIDrUaWKXHl+fr42btyo0aNH29vc3NwUExOj9PT0YpdJT09XYmKiQ1tsbKw+/vjjYvvn5eUpLy/PPn369GlJUk5OzhVWX7zCvHNXZVzACq7W++5a430OlO5qvNcvjmmMuWzfCg03x48fV0FBgYKDgx3ag4ODtXPnzmKXycrKKrZ/VlZWsf2Tk5P1/PPPF2kPCwsrY9UAyipgSkVXAOBauJrv9TNnziggIKDUPhUabq6F0aNHO+zpKSws1MmTJ1W9enXZbLYKrAxXW05OjsLCwnTw4EH5+/tXdDkArhLe638MxhidOXNGtWvXvmzfCg03QUFBcnd3V3Z2tkN7dna2QkJCil0mJCTEpf5eXl7y8vJyaKtatWrZi8bvjr+/Px94wB8A73Xru9wem4sq9IRiT09PRUVFKS0tzd5WWFiotLQ0RUdHF7tMdHS0Q39JWr58eYn9AQDAH0uFH5ZKTExUnz591KZNG7Vt21ZTpkzR2bNnFR8fL0mKi4tTaGiokpOTJUnDhg1Tx44dNWnSJN17771asGCBNmzYoLfeeqsiNwMAAFwnKjzc9OrVS8eOHdPYsWOVlZWlyMhILVu2zH7S8IEDB+Tm9r8dTO3bt9f8+fM1ZswYPfPMM2rYsKE+/vhjNWvWrKI2AdcpLy8vJSUlFTksCcBaeK/jt2zGme9UAQAA/E5U+EX8AAAAyhPhBgAAWArhBgAAWArhBlfsueeeU2RkpEvLdOrUSU888USF1wHgV1fjPXk5NputxFvnoHgrV66UzWbTTz/9VNGlXNcIN7hiI0aMKHLtoctZtGiRxo0bd5Uqshb+AACAayr8q+D4/TLGqKCgQH5+fvLz83Np2WrVql2lqspXQUGBbDabw+UIAADXNz6xYZeXl6ehQ4eqZs2a8vb21i233KL169fb51/cHfrpp58qKipKXl5eWr16dZHDQRcuXNDQoUNVtWpVVa9eXaNGjVKfPn3Uo0cPe5/f7gIPDw/XP//5T/Xt21dVqlRRnTp1ilyYcdSoUWrUqJF8fX1Vr149/eMf/9D58+ed3r6L9S9ZskQtWrSQt7e3br75Zm3fvt3eZ86cOapataoWL16spk2bysvLSwcOHNCpU6cUFxenwMBA+fr6qkuXLtq9e3eR5f7zn/+ocePG8vX1Vc+ePXXu3Dm9/fbbCg8PV2BgoIYOHaqCggKH7R43bpwefvhhVa5cWaGhoZo6darDfEm67777ZLPZ7NP44+rUqZMef/xxPfHEEwoMDFRwcLBmzJhhv/hplSpV1KBBA3366acOy3311Vdq27atvLy8VKtWLT399NO6cOFCievJy8vTiBEjFBoaqsqVK6tdu3ZauXKlQ581a9aoU6dO8vX1VWBgoGJjY3Xq1ClJv752p0yZ4tA/MjJSzz33XInrPHjwoB588EFVrVpV1apVU/fu3bV///4S+198T6elpalNmzby9fVV+/bttWvXLnufvXv3qnv37goODpafn59uuukmrVixwmGc8PBwvfjii4qLi5Ofn5/q1q2rxYsX69ixY+revbv8/PzUokULbdiwwWG51atX69Zbb5WPj4/CwsI0dOhQnT17tsR6JWnatGmqX7++PD091bhxY82dO9dhvs1m08yZM3XffffJ19dXDRs21OLFi4sd6+zZs/L399cHH3zg0P7xxx+rcuXKOnPmTKm1WBnhBnZPPfWUPvzwQ7399tvatGmTGjRooNjYWJ08edKh39NPP63x48crIyNDLVq0KDLOyy+/rHnz5ik1NVVr1qxRTk6OU4dVJk2apDZt2ujbb7/VoEGDNHDgQIcPqSpVqmjOnDnasWOHXn31Vc2YMUOTJ092eTtHjhypSZMmaf369apRo4a6devmEJLOnTunl19+WTNnztR3332nmjVr6rHHHtOGDRu0ePFipaenyxije+65p8hyr732mhYsWKBly5Zp5cqVuu+++7R06VItXbpUc+fO1b/+9a8iH0QTJ05Uy5Yt9e233+rpp5/WsGHDtHz5ckmyh8vU1FQdOXLEIWzij+vtt99WUFCQ1q1bp8cff1wDBw7UAw88oPbt22vTpk2666679Oijj+rcuXOSpEOHDumee+7RTTfdpC1btmjatGmaNWuWXnzxxRLXMWTIEKWnp2vBggXaunWrHnjgAd199932UL9582Z17txZTZs2VXp6ulavXq1u3bo5hHdXnD9/XrGxsapSpYq+/vprrVmzRn5+frr77ruVn59f6rLPPvusJk2apA0bNqhSpUrq27evfV5ubq7uuecepaWl6dtvv9Xdd9+tbt266cCBAw5jTJ48WR06dNC3336re++9V48++qji4uL0yCOPaNOmTapfv77i4uJ08dJwe/fu1d13362//OUv2rp1qxYuXKjVq1dryJAhJdb50UcfadiwYXryySe1fft2DRgwQPHx8fryyy8d+j3//PN68MEHtXXrVt1zzz3q3bt3kc9hSapcubIeeughpaamOrSnpqaqZ8+eqlKlSqnPm6UZwBiTm5trPDw8zLx58+xt+fn5pnbt2mbChAnGGGO+/PJLI8l8/PHHDssmJSWZli1b2qeDg4PNxIkT7dMXLlwwderUMd27d7e3dezY0QwbNsw+XbduXfPII4/YpwsLC03NmjXNtGnTSqx54sSJJioqqsQ6futi/QsWLLC3nThxwvj4+JiFCxcaY4xJTU01kszmzZvtfTIzM40ks2bNGnvb8ePHjY+Pj3nvvfccltuzZ4+9z4ABA4yvr685c+aMvS02NtYMGDDAYbvvvvtuhzp79eplunTpYp+WZD766KMStwt/LB07djS33HKLffrChQumcuXK5tFHH7W3HTlyxEgy6enpxhhjnnnmGdO4cWNTWFho7zN16lTj5+dnCgoK7ONefE/+8MMPxt3d3Rw6dMhh3Z07dzajR482xhjz8MMPmw4dOpRYZ926dc3kyZMd2lq2bGmSkpLs05e+tufOnVukxry8POPj42M+++yzYtdx8T29YsUKe9uSJUuMJPPzzz+XWNuNN95oXn/9dYdaL/38ufj8/eMf/7C3paenG0nmyJEjxhhj+vXrZ/72t785jPv1118bNze3Etfdvn17k5CQ4ND2wAMPmHvuucc+LcmMGTPGPp2bm2skmU8//dRhm0+dOmWMMea///2vcXd3N4cPHzbGGJOdnW0qVapkVq5cWeL2/xGw5waSfv0v5Pz58+rQoYO9zcPDQ23btlVGRoZD3zZt2pQ4zunTp5Wdna22bdva29zd3RUVFXXZGi7dC2Sz2RQSEqKjR4/a2xYuXKgOHTooJCREfn5+GjNmTJH/vpxx6U1Wq1WrpsaNGztso6enp0MtGRkZqlSpktq1a2dvq169epHlfH19Vb9+fft0cHCwwsPDHc5HCg4Odtim39Zzcfq3zzlwqUtfn+7u7qpevbqaN29ub7t4+5qLr7WMjAxFR0fLZrPZ+3To0EG5ubn68ccfi4y/bds2FRQUqFGjRvZz6vz8/PTVV19p7969kv6356a8bNmyRXv27FGVKlXs66tWrZp++eUX+zpLcunzUatWLUn/2/bc3FyNGDFCERERqlq1qvz8/JSRkVHks+PSMS4+f6U9p1u2bNGcOXMcnp/Y2FgVFhZq3759xdaZkZHh8Bkr/fp7+O37/dJaKleuLH9//yKfGxe1bdtWN954o95++21J0jvvvKO6devqtttuK7b/HwUnFMNllStXvirjenh4OEzbbDYVFhZKktLT09W7d289//zzio2NVUBAgBYsWKBJkyaVex0+Pj4OfwScVVz9pW0TUFaXe61dfP2W9bWWm5srd3d3bdy4Ue7u7g7zLoZ1Hx+fUsdwc3OzH8K5qLRz5HJzcxUVFaV58+YVmVejRo1S11Xato8YMULLly/XK6+8ogYNGsjHx0c9e/YscqiruDFKGzc3N1cDBgzQ0KFDi9RTp06dUuu9HFc/N/r376+pU6fq6aefVmpqquLj48v0GWYl7LmBJNlPcFuzZo297fz581q/fr2aNm3q9DgBAQEKDg52ODekoKBAmzZtuqL61q5dq7p16+rZZ59VmzZt1LBhQ/3www9lGuubb76x/3zq1CllZmYqIiKixP4RERG6cOGC/vvf/9rbTpw4oV27drn03DhTz8XpS+vx8PAo83kMgPTra/jiuWIXrVmzRlWqVNENN9xQpH+rVq1UUFCgo0ePqkGDBg6PkJAQSb/uXSjtEhA1atTQkSNH7NM5OTkl7tGQpNatW2v37t2qWbNmkXUGBASUZbPt2/nYY4/pvvvuU/PmzRUSElLqScrOat26tXbs2FGk1gYNGsjT07PYZSIiIhw+Yy/Wd6WfI4888oh++OEHvfbaa9qxY4f69OlzReNZAeEGkn7dGzNw4ECNHDlSy5Yt044dO5SQkKBz586pX79+Lo31+OOPKzk5WZ988ol27dqlYcOG6dSpU1f0n0TDhg114MABLViwQHv37tVrr72mjz76qExjvfDCC0pLS9P27dv12GOPKSgoyOGbXMWtu3v37kpISNDq1au1ZcsWPfLIIwoNDVX37t3LuEX/s2bNGk2YMEGZmZmaOnWq3n//fQ0bNsw+Pzw8XGlpacrKyrJ/EwVwxaBBg3Tw4EE9/vjj2rlzpz755BMlJSUpMTGx2MscNGrUSL1791ZcXJwWLVqkffv2ad26dUpOTtaSJUskSaNHj9b69es1aNAgbd26VTt37tS0adN0/PhxSdIdd9yhuXPn6uuvv9a2bdvUp0+fInuBLtW7d28FBQWpe/fu+vrrr7Vv3z6tXLlSQ4cOLfbQmbMaNmyoRYsWafPmzdqyZYv++te/lsve01GjRmnt2rUaMmSINm/erN27d+uTTz4p9YTikSNHas6cOZo2bZp2796tlJQULVq0SCNGjLiiWgIDA3X//fdr5MiRuuuuu4oNrH80hBvYjR8/Xn/5y1/06KOPqnXr1tqzZ48+++wzBQYGujTOqFGj9PDDDysuLk7R0dH2Y9He3t5lru3Pf/6zhg8friFDhigyMlJr167VP/7xjzKNNX78eA0bNkxRUVHKysrSv//97xL/07ooNTVVUVFR6tq1q6Kjo2WM0dKlS4vsPi6LJ598Uhs2bFCrVq304osvKiUlRbGxsfb5kyZN0vLlyxUWFqZWrVpd8frwxxMaGqqlS5dq3bp1atmypf7+97+rX79+GjNmTInLpKamKi4uTk8++aQaN26sHj16aP369fZDLo0aNdLnn3+uLVu2qG3btoqOjtYnn3yiSpV+Pdth9OjR6tixo7p27ap7771XPXr0cDgn7bd8fX21atUq1alTR/fff78iIiLUr18//fLLL/L39y/ztqekpCgwMFDt27dXt27dFBsbq9atW5d5vItatGihr776SpmZmbr11lvVqlUrjR07VrVr1y5xmR49eujVV1/VK6+8ohtvvFH/+te/lJqaqk6dOl1xPf369VN+fr7DN8X+yGzmtwdFgXJWWFioiIgIPfjggxV6VeKVK1fq9ttv16lTp1S1atUKq+NS4eHheuKJJ675Ze8BWMvcuXM1fPhwHT58+LL/rP0RcEIxyt0PP/ygzz//XB07dlReXp7eeOMN7du3T3/9618rujQAsJRz587pyJEjGj9+vAYMGECw+f84LIVy5+bmpjlz5uimm25Shw4dtG3bNq1YsaLUk3YBAK6bMGGCmjRpopCQEI0ePbqiy7lucFgKAABYCntuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBucN3Yv3+/bDabNm/e7PQyc+bMKfcL8pWlDlwbK1eulM1m008//XTN1vncc88pMjLymq3PKjp16sTFKVFhCDcoVwcPHlTfvn1Vu3ZteXp6qm7duho2bJhOnDhx2WXDwsJ05MgRNWvWzOn19erVS5mZmVdScpl06tRJNptNNptN3t7eatq0qd58881rXoezrkYIdMZjjz0mm82mv//970XmDR48WDabTY899tg1rwu4Wmw2mz7++OOKLuMPj3CDcvP999+rTZs22r17t959913t2bNH06dPV1pamqKjo3Xy5MkSl83Pz5e7u7tCQkLs96Zxho+Pj2rWrFke5bssISFBR44c0Y4dO/Tggw9q8ODBevfdd4vtm5+ff42ru36EhYVpwYIF+vnnn+1tv/zyi+bPn2+/TxFQHgoKCsrlppj4/SPcoNwMHjxYnp6e9lsv1KlTR126dNGKFSt06NAhPfvss/a+4eHhGjdunOLi4uTv76+//e1vxR4OWrx4sRo2bChvb2/dfvvtevvttx0OS/x2j8TFQwhz585VeHi4AgIC9NBDD+nMmTP2PsuWLdMtt9yiqlWrqnr16uratav27t3r8vb6+voqJCRE9erV03PPPaeGDRtq8eLFkn7dszNkyBA98cQTCgoKst8I86uvvlLbtm3l5eWlWrVq6emnn9aFCxfsY3bq1EmPP/64nnjiCQUGBio4OFgzZszQ2bNnFR8frypVqqhBgwb69NNP7ctcPFSzZMkStWjRQt7e3rr55pu1fft2+/z4+HidPn3avrfpueeeK7I9mZmZstls2rlzp0P75MmT7Tc8PHXqlHr37q0aNWrIx8dHDRs2VGpqaqnPU+vWrRUWFqZFixbZ2xYtWqQ6deoUuRFoXl6ehg4dqpo1a8rb21u33HKL1q9fX+r4q1ev1q233iofHx+FhYVp6NChOnv2rMOYo0aNUlhYmLy8vNSgQQPNmjVLUvF7tD7++OPL3sF+5syZioiIkLe3t5o0aXLZvXadOnXS0KFD9dRTT6latWoKCQkp8jtISUlR8+bNVblyZYWFhWnQoEHKzc21z79Y63/+8x81btxYvr6+6tmzp86dO6e3335b4eHhCgwM1NChQ1VQUOCw/SNGjFBoaKgqV66sdu3aaeXKlaXWe+DAAXXv3l1+fn7y9/fXgw8+qOzsbPt8Z95nl3rhhReK3SMbGRlZ4g1wL/e6vvQ5Wbx4sZo2bSovLy8dOHBAp06dUlxcnAIDA+Xr66suXbpo9+7dV/xcXvzcevjhh1W5cmWFhoZq6tSpDvMl6b777pPNZrNPowIYoBycOHHC2Gw2889//rPY+QkJCSYwMNAUFhYaY4ypW7eu8ff3N6+88orZs2eP2bNnj9m3b5+RZL799ltjjDHff/+98fDwMCNGjDA7d+407777rgkNDTWSzKlTp4wxxqSmppqAgAD7epKSkoyfn5+5//77zbZt28yqVatMSEiIeeaZZ+x9PvjgA/Phhx+a3bt3m2+//dZ069bNNG/e3BQUFBhjTJE6itOxY0czbNgwh7YWLVqY+++/3z7fz8/PjBw50uzcudPs3LnT/Pjjj8bX19cMGjTIZGRkmI8++sgEBQWZpKQkh3GrVKlixo0bZzIzM824ceOMu7u76dKli3nrrbdMZmamGThwoKlevbo5e/asMcaYL7/80kgyERER5vPPPzdbt241Xbt2NeHh4SY/P9/k5eWZKVOmGH9/f3PkyBFz5MgRc+bMmWK3q02bNmbMmDEObVFRUfa2wYMHm8jISLN+/Xqzb98+s3z5crN48eISn6c+ffqY7t27m5SUFNO5c2d7e+fOnc3kyZNN9+7dTZ8+feztQ4cONbVr1zZLly413333nenTp48JDAw0J06ccNjWi7//PXv2mMqVK5vJkyebzMxMs2bNGtOqVSvz2GOP2cd88MEHTVhYmFm0aJHZu3evWbFihVmwYIExpujrxxhjPvroI3PpR2NSUpJp2bKlffqdd94xtWrVMh9++KH5/vvvzYcffmiqVatm5syZU+Lz0LFjR+Pv72+ee+45k5mZad5++21js9nM559/bu8zefJk88UXX5h9+/aZtLQ007hxYzNw4ED7/NTUVOPh4WHuvPNOs2nTJvPVV1+Z6tWrm7vuuss8+OCD5rvvvjP//ve/jaenp337jDGmf//+pn379mbVqlVmz549ZuLEicbLy8tkZmYWW2tBQYGJjIw0t9xyi9mwYYP55ptvTFRUlOnYsaPDc3K599ml75GDBw8aNzc3s27dOvv8TZs2GZvNZvbu3VtsHZd7XV/6nLRv396sWbPG7Ny505w9e9b8+c9/NhEREWbVqlVm8+bNJjY21jRo0KDIcq4+l3Xr1jVVqlQxycnJZteuXea1114z7u7u9t/j0aNHjSSTmppqjhw5Yo4ePVriawJXF+EG5eKbb74xksxHH31U7PyUlBQjyWRnZxtjfv2Q6NGjh0Of34aKUaNGmWbNmjn0efbZZy8bbnx9fU1OTo69beTIkaZdu3Yl1n7s2DEjyWzbtq3YOopz6Qf3hQsXzNy5c40k88Ybb9jnt2rVymGZZ555xjRu3Nge8IwxZurUqcbPz88erDp27GhuueUW+/wLFy6YypUrm0cffdTeduTIESPJpKenG2P+90fg0g/hEydOGB8fH7Nw4cJin6eSTJ482dSvX98+vWvXLiPJZGRkGGOM6datm4mPj7/sOBddDDdHjx41Xl5eZv/+/Wb//v3G29vbHDt2zCHc5ObmGg8PDzNv3jz78vn5+aZ27dpmwoQJDtt68fffr18/87e//c1hnV9//bVxc3MzP//8s73+5cuXF1tfWcJN/fr1zfz58x2WGTdunImOji7xefjt79UYY2666SYzatSoEpd5//33TfXq1R1qlWT27NljbxswYIDx9fV1CKuxsbFmwIABxhhjfvjhB+Pu7m4OHTrkMHbnzp3N6NGji13v559/btzd3c2BAwfsbd99952RZA8nzrzPfvsPQJcuXRzC2uOPP246depU4vY7+7qWZDZv3mzvk5mZaSSZNWvW2NuOHz9ufHx8zHvvveewnCvPpTG/fm7dfffdDnX26tXLdOnSxT5d2ucgrh0OS6FcGRduVdamTZtS5+/atUs33XSTQ1vbtm0vO254eLiqVKlin65Vq5aOHj1qn969e7cefvhh1atXT/7+/vZdxwcOHHC6dkl688035efnJx8fHyUkJGj48OEaOHCgfX5UVJRD/4yMDEVHRzsc8ujQoYNyc3P1448/2ttatGhh/9nd3V3Vq1dX8+bN7W3BwcGS5LBNkhQdHW3/uVq1amrcuLEyMjJc2qaHHnpI+/fv1zfffCNJmjdvnlq3bq0mTZpIkgYOHKgFCxYoMjJSTz31lNauXevUuDVq1NC9996rOXPmKDU1Vffee6+CgoIc+uzdu1fnz59Xhw4d7G0eHh5q27ZtiduxZcsWzZkzR35+fvZHbGysCgsLtW/fPm3evFnu7u7q2LGjS89DSc6ePau9e/eqX79+Dut88cUXL3to89Lfq1T0dblixQp17txZoaGhqlKlih599FGdOHFC586ds/fx9fW1HyKUfn0thIeHy8/Pz6Ht4rjbtm1TQUGBGjVq5FDvV199VWK9GRkZCgsLU1hYmL2tadOmqlq1qsPv4XLvs99KSEjQu+++q19++UX5+fmaP3+++vbtW2L/iy73uvb09HR4bjMyMlSpUiW1a9fO3la9evUiy7n6XBZXz8VpV99nuPqcP3MTKEWDBg1ks9mUkZGh++67r8j8jIwMBQYGqkaNGva2ypUrX5VaPDw8HKZtNpvDSYbdunVT3bp1NWPGDNWuXVuFhYVq1qyZyyf99u7dW88++6x8fHxUq1Ytubk5/q9Q1u0rrv5L2y6Go6tx4mRISIjuuOMOzZ8/XzfffLPmz5/vENi6dOmiH374QUuXLtXy5cvVuXNnDR48WK+88splx+7bt6+GDBkiSQ7nKVyJ3NxcDRgwQEOHDi0yr06dOtqzZ0+py7u5uRUJ5OfPny91fZI0Y8YMhz+e0q9BtDSlvS7379+vrl27auDAgXrppZdUrVo1rV69Wv369VN+fr58fX1LHKO0cXNzc+Xu7q6NGzcWqe/SP+Jlcbn32W9169ZNXl5e+uijj+Tp6anz58+rZ8+eV1SD9OuXCi53jlRxXH0u8fvCnhuUi+rVq+vOO+/Um2++6fCtGEnKysrSvHnz1KtXL5c+hBo3bqwNGzY4tF3u5NLLOXHihHbt2qUxY8aoc+fOioiI0KlTp8o0VkBAgBo0aKDQ0NAiwaY4ERERSk9Pd/hjumbNGlWpUkU33HBDmWq41MW9LdKvJ/5mZmYqIiJC0q//3V56YmRpevfurYULFyo9PV3ff/+9HnroIYf5NWrUUJ8+ffTOO+9oypQpeuutt5wa9+6771Z+fr7Onz9vP8H6UvXr15enp6fWrFljbzt//rzWr1+vpk2bFjtm69attWPHDjVo0KDIw9PTU82bN1dhYaG++uqrYpevUaOGzpw543ACcmnXNwoODlbt2rX1/fffF1nfn/70J6eeh+Js3LhRhYWFmjRpkm6++WY1atRIhw8fLvN4F7Vq1UoFBQU6evRokXpDQkKKXSYiIkIHDx7UwYMH7W07duzQTz/9VOLvwRmVKlVSnz59lJqaqtTUVD300EPy8fG57HKlva5Lqv/ChQv673//a2+7+L6/kvqLq+fi9KX1eHh4OP1ew9VDuEG5eeONN5SXl6fY2FitWrVKBw8e1LJly3TnnXcqNDRUL730kkvjDRgwQDt37tSoUaOUmZmp9957T3PmzJGkMv2nJkmBgYGqXr263nrrLe3Zs0dffPGFEhMTyzSWqwYNGqSDBw/q8ccf186dO/XJJ58oKSlJiYmJToWjy3nhhReUlpam7du367HHHlNQUJB69Ogh6ddDCLm5uUpLS9Px48cdDnX81v33368zZ85o4MCBuv3221W7dm37vLFjx+qTTz7Rnj179N133+k///lPqX9oLuXu7q6MjAzt2LGj2L0clStX1sCBAzVy5EgtW7ZMO3bsUEJCgs6dO6d+/foVO+aoUaO0du1aDRkyRJs3b9bu3bv1ySef2PcQhYeHq0+fPurbt68+/vhj7du3TytXrtR7770nSWrXrp18fX31zDPPaO/evZo/f779NVaS559/XsnJyXrttdeUmZmpbdu2KTU1VSkpKU49D8Vp0KCBzp8/r9dff13ff/+95s6dq+nTp5d5vIsaNWqk3r17Ky4uTosWLdK+ffu0bt06JScna8mSJcUuExMTo+bNm6t3797atGmT1q1bp7i4OHXs2PGyh5Ivp3///vriiy+0bNkypw5JSaW/rovTsGFDde/eXQkJCVq9erW2bNmiRx55RKGhoerevfsV1S/9+g/JhAkTlJmZqalTp+r999/XsGHD7PPDw8OVlpamrKysMv/jhCtHuEG5adiwoTZs2KB69erpwQcfVP369fW3v/1Nt99+u9LT01WtWjWXxvvTn/6kDz74QIsWLVKLFi00bdo0+9fJvby8ylSjm5ubFixYoI0bN6pZs2YaPny4Jk6cWKaxXBUaGqqlS5dq3bp1atmypf7+97+rX79+GjNmTLmMP378eA0bNkxRUVHKysrSv//9b3l6ekqS2rdvr7///e/q1auXatSooQkTJpQ4TpUqVdStWzdt2bJFvXv3dpjn6emp0aNHq0WLFrrtttvk7u6uBQsWOF2jv7+//P39S92Gv/zlL3r00UfVunVr7dmzR5999pkCAwOL7d+iRQt99dVXyszM1K233qpWrVpp7NixDoFs2rRp6tmzpwYNGqQmTZooISHBvqemWrVqeuedd7R06VI1b95c7777brFfk79U//79NXPmTKWmpqp58+bq2LGj5syZc0V7blq2bKmUlBS9/PLLatasmebNm6fk5OQyj3ep1NRUxcXF6cknn1Tjxo3Vo0cPrV+/vsRrDNlsNn3yyScKDAzUbbfdppiYGNWrV08LFy684loaNmyo9u3bq0mTJkUO65WktNd1SVJTUxUVFaWuXbsqOjpaxhgtXbq0yGGnsnjyySe1YcMGtWrVSi+++KJSUlIc9kROmjRJy5cvV1hYWJFLHeDasRlXzgAFKthLL72k6dOnO+wy/6NbuXKlbr/9dp06dapCrkIMOMsYo4YNG2rQoEGX3WN6Pb6uw8PD9cQTT3Bbid8BTijGde3NN9/UTTfdpOrVq2vNmjWaOHGi/ZADgN+PY8eOacGCBcrKylJ8fHxFlwOLI9zgurZ79269+OKLOnnypOrUqaMnn3xSo0ePruiyALioZs2aCgoK0ltvvVXiYUagvHBYCgAAWAonFAMAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEv5f347L2781NKXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "ablated_prompt_auc_roc = {'original prompt': 0.74, 'molecule name only': 0.68}\n",
        "x = list(ablated_prompt_auc_roc.keys())\n",
        "y = list(ablated_prompt_auc_roc.values())\n",
        "plt.bar(x, y)\n",
        "plt.xlabel('Original Prompt vs Molecule name only prompt')\n",
        "plt.ylabel('AUC ROC Score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH75TNU71eRH"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe What was easy and What was difficult during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiVwNmDStG7Q"
      },
      "source": [
        "### Implications of the experimental results\n",
        "\n",
        "We are able to reproduce that zero-shot GIMLET model performs better than other zero-shot based models (KVPLM, MoMu, Galactica-125M, Galactica-1.3B).\n",
        "\n",
        "We are able to reproduce that few-shot GIMLET model performs better than zero-shot GIMLET model.\n",
        "\n",
        "However, we are not able to reproduce the exact RUC-AUC score reported in the paper. Our eval scores tend to be lower than what's reported in the paper but they are still higher than what the baseline models reported in the paper.\n",
        "\n",
        "We think there are two reasons behind the discrepency:\n",
        "* Due to the compute resources constraint and time limit on running the evals we only tried 20% of test dataset and 2% test dataset. In our experiments we found out 20% of test dataset reported higher RUC-AUC score than 2%. We expect if we run the full test dataset, we would see a higher RUC-AUC score.\n",
        "* The paper and the code repo doesn't provide detail on the choosen hyperparameters used in the training. We used the largest batch size that can be supported in our TPU."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What was easy\n",
        "\n",
        "* The paper using standard huggingface data and training library, standard T5 transformer architecture and library and it use pytorch and pytorch geometric library, which make it easy to find and read the APIs to reproduce and easy to get and search for help with similar issues.\n",
        "\n",
        "* The original repo provide clear instruction and scripts on where and how to get raw training and test data"
      ],
      "metadata": {
        "id": "bNsDYKTDH9E_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What was difficult\n",
        "\n",
        "* Model itself is complex, it is a transfomer based with graph encoding model. Because the model propsed new attention mechanism to attend to both molecule and text embeddings. We bascially need to rewrite the multi-head attention component of the transformer. And the molecule encoding it is non-trival. It is hard to implement and understand the model.\n",
        "\n",
        "* Because the model is complex, it is hard to train the model, which make it bascially impossible to train on CPU. We had to use 40GB TPU to train it."
      ],
      "metadata": {
        "id": "LVGPAgaOIBvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recommendations to the original author\n",
        "\n",
        "* Provide more detailed descriptions of model architecture.\n",
        "* Provide more clear instructions on training and evals including the hyperparameters used in training and evals."
      ],
      "metadata": {
        "id": "0gVtdW6DIIV4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31da256a6eba45cc8470e481c33a70d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78e7466ad3664cd990ce9b59e358b592",
              "IPY_MODEL_36794df33ea1448d87554644d71f2fc4",
              "IPY_MODEL_9bd153b895a140e298f199a64e9615a5"
            ],
            "layout": "IPY_MODEL_34899f80fe9640d2b04131d0218c5f8c"
          }
        },
        "78e7466ad3664cd990ce9b59e358b592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f689adee16442e8b959751f9e25046",
            "placeholder": "",
            "style": "IPY_MODEL_52d0584b16ba43c6adcb897539acbc9b",
            "value": "Runningtokenizerondatasetline_by_line:100%"
          }
        },
        "36794df33ea1448d87554644d71f2fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_814d6a9f9aa6421cbb05150660ee617d",
            "max": 4113,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa1072d9fc094813a414ebd25499a2b3",
            "value": 4113
          }
        },
        "9bd153b895a140e298f199a64e9615a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b693678feaaf4ce5be738cdbc6f92083",
            "placeholder": "",
            "style": "IPY_MODEL_a52109d410b9431e9263d1baf0a35ad7",
            "value": "4113/4113[00:04&lt;00:00,882.68examples/s]"
          }
        },
        "34899f80fe9640d2b04131d0218c5f8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f689adee16442e8b959751f9e25046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d0584b16ba43c6adcb897539acbc9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "814d6a9f9aa6421cbb05150660ee617d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa1072d9fc094813a414ebd25499a2b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b693678feaaf4ce5be738cdbc6f92083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52109d410b9431e9263d1baf0a35ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32ac15a966b44e8ab28a1fc6e56eebc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be23b2d74055424e9d2371076f2ef6e8",
              "IPY_MODEL_9e35251e81e4410e9a5e987f6cfc2ba5",
              "IPY_MODEL_f6f618f4028f4a03bf1a779eb318298f"
            ],
            "layout": "IPY_MODEL_9a2c561a24ab491ba537ddb78ea72b6f"
          }
        },
        "be23b2d74055424e9d2371076f2ef6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc2a2dfe2bb2494b904d26d614322f30",
            "placeholder": "",
            "style": "IPY_MODEL_6fd9244165f74b548dcfe1876aabc24a",
            "value": "Filter:100%"
          }
        },
        "9e35251e81e4410e9a5e987f6cfc2ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d67c6040b2b840ed8ab78c0e84620478",
            "max": 103425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20f606de59d947c88fcbceb34b6d3222",
            "value": 103425
          }
        },
        "f6f618f4028f4a03bf1a779eb318298f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e225a55ec9f64f02bd0aa4945b072d8a",
            "placeholder": "",
            "style": "IPY_MODEL_53e60239b50b48c6896a5651401caab0",
            "value": "103425/103425[00:15&lt;00:00,7665.61examples/s]"
          }
        },
        "9a2c561a24ab491ba537ddb78ea72b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2a2dfe2bb2494b904d26d614322f30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd9244165f74b548dcfe1876aabc24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d67c6040b2b840ed8ab78c0e84620478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20f606de59d947c88fcbceb34b6d3222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e225a55ec9f64f02bd0aa4945b072d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e60239b50b48c6896a5651401caab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2563afc7e8a420c8d66fa9576320359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9ca63f8105741d0b28e22db088ffcf3",
              "IPY_MODEL_a0b756f1344f4f4bad4993d872646a65",
              "IPY_MODEL_3f4c240bfd7a4392ad252e27695334f6"
            ],
            "layout": "IPY_MODEL_97710809bef24406b8b22a8a1d0994e9"
          }
        },
        "f9ca63f8105741d0b28e22db088ffcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9fb196ca21d4510887f0b44874c73ad",
            "placeholder": "",
            "style": "IPY_MODEL_6442f4b30d11430e93106b4d71454ec7",
            "value": "Filter:100%"
          }
        },
        "a0b756f1344f4f4bad4993d872646a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f87b377e69e4631bd67d5ab435af2e2",
            "max": 103425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05fb07a2cf2e40e19a748ddd9466c8ab",
            "value": 103425
          }
        },
        "3f4c240bfd7a4392ad252e27695334f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d67713ffec6640cd81f1923077e9c61a",
            "placeholder": "",
            "style": "IPY_MODEL_788a826771d5474aacbadbcd6e082a49",
            "value": "103425/103425[00:15&lt;00:00,8035.27examples/s]"
          }
        },
        "97710809bef24406b8b22a8a1d0994e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fb196ca21d4510887f0b44874c73ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6442f4b30d11430e93106b4d71454ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f87b377e69e4631bd67d5ab435af2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05fb07a2cf2e40e19a748ddd9466c8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d67713ffec6640cd81f1923077e9c61a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788a826771d5474aacbadbcd6e082a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0a947372b6f4992ba939e250b334b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17d0fd13e9bb4d5ba3e2f2e8d7403fda",
              "IPY_MODEL_58f2b80a60b94401a4541bb84c06374a",
              "IPY_MODEL_5e6ce1fdc4c94b91baaa934a05cec756"
            ],
            "layout": "IPY_MODEL_76bcb65946004f44862d0f1d3d8883c9"
          }
        },
        "17d0fd13e9bb4d5ba3e2f2e8d7403fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_999a2178326a442794547c507fa8a63e",
            "placeholder": "",
            "style": "IPY_MODEL_74a2ea4ee8ea4bffb3a17744fc2cbfa8",
            "value": "Filter:100%"
          }
        },
        "58f2b80a60b94401a4541bb84c06374a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85dca619e364411e90ff12c22e9cf171",
            "max": 103425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f7b575716a748b7b7dbbc1c4a47c6ee",
            "value": 103425
          }
        },
        "5e6ce1fdc4c94b91baaa934a05cec756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07b37ff7bbbd4a9eb5127f1c56d581ba",
            "placeholder": "",
            "style": "IPY_MODEL_4d9e8e8c4c0a450c8435801bd63a8cd2",
            "value": "103425/103425[00:15&lt;00:00,7809.83examples/s]"
          }
        },
        "76bcb65946004f44862d0f1d3d8883c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999a2178326a442794547c507fa8a63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a2ea4ee8ea4bffb3a17744fc2cbfa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85dca619e364411e90ff12c22e9cf171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7b575716a748b7b7dbbc1c4a47c6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07b37ff7bbbd4a9eb5127f1c56d581ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d9e8e8c4c0a450c8435801bd63a8cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aabe650555646388fc1edcb6d4ca0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddc8b8b7025142379cbe02a4ea131d1f",
              "IPY_MODEL_aa36e70da0c647cb8394072af91284f8",
              "IPY_MODEL_b21789b292094aedabcea7ed6bec626b"
            ],
            "layout": "IPY_MODEL_999d84fc098547f58152087740383494"
          }
        },
        "ddc8b8b7025142379cbe02a4ea131d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12689a03a3964859bc9f0691230deccf",
            "placeholder": "",
            "style": "IPY_MODEL_29c9878c060342c2ac2389e4e8f57f4b",
            "value": "Filter:100%"
          }
        },
        "aa36e70da0c647cb8394072af91284f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa5e5a8d551f453e9e374ad473a85241",
            "max": 103425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e8f83494f2548f1b3906bad3e8c3038",
            "value": 103425
          }
        },
        "b21789b292094aedabcea7ed6bec626b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3744df93f19426480b278def2b6fba2",
            "placeholder": "",
            "style": "IPY_MODEL_e989c1ef6e2c4ff3be0bb864bd116e4c",
            "value": "103425/103425[00:14&lt;00:00,8110.66examples/s]"
          }
        },
        "999d84fc098547f58152087740383494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12689a03a3964859bc9f0691230deccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c9878c060342c2ac2389e4e8f57f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa5e5a8d551f453e9e374ad473a85241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e8f83494f2548f1b3906bad3e8c3038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3744df93f19426480b278def2b6fba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e989c1ef6e2c4ff3be0bb864bd116e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "582379e4abe34703b7a7b63bff563060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cf756a02b574abea8e3c9fe1f073c52",
              "IPY_MODEL_3c12535b3ad54a269b9ce431eaedc0e5",
              "IPY_MODEL_3bbde523470a4c1b8f57fb6c9ac19230"
            ],
            "layout": "IPY_MODEL_e75af559f91e47ed805fd39ef18b05da"
          }
        },
        "1cf756a02b574abea8e3c9fe1f073c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_905ae9d373484d10a7c4ab563c1a54a6",
            "placeholder": "",
            "style": "IPY_MODEL_922661d0acd649fa9f4785cf342f820e",
            "value": "Filter:100%"
          }
        },
        "3c12535b3ad54a269b9ce431eaedc0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1feda1a343a14463bade6620462581b2",
            "max": 103425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f3192935cd24e438b7ee3d3c104eb9c",
            "value": 103425
          }
        },
        "3bbde523470a4c1b8f57fb6c9ac19230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2cdfe4aff9c41a5852aa535255fe614",
            "placeholder": "",
            "style": "IPY_MODEL_d5b3d010272b4a108d1494fec2166437",
            "value": "103425/103425[00:14&lt;00:00,8197.50examples/s]"
          }
        },
        "e75af559f91e47ed805fd39ef18b05da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "905ae9d373484d10a7c4ab563c1a54a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "922661d0acd649fa9f4785cf342f820e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1feda1a343a14463bade6620462581b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f3192935cd24e438b7ee3d3c104eb9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2cdfe4aff9c41a5852aa535255fe614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b3d010272b4a108d1494fec2166437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22ebeb2718644a5f96ca23f2ebc2e33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76b25667c70b4fbf8409c0e8a2dee34a",
              "IPY_MODEL_20d392f8cfae4690a0f95609278d759d",
              "IPY_MODEL_acbd423057954062a5203951698230b9"
            ],
            "layout": "IPY_MODEL_f02ae78f2d774fb0bbf1ea2fa28eb93c"
          }
        },
        "76b25667c70b4fbf8409c0e8a2dee34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5454244f06ff4d56a486a5fbe774d189",
            "placeholder": "",
            "style": "IPY_MODEL_c0c18971f9464a6bb811aa917217b3ab",
            "value": "Filter:100%"
          }
        },
        "20d392f8cfae4690a0f95609278d759d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cbb7f16c37b4f6781d3799457afd7d1",
            "max": 103425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a88758b866624b49a03a943afb8caf5c",
            "value": 103425
          }
        },
        "acbd423057954062a5203951698230b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a031c3dc644f20b267f51f769708e0",
            "placeholder": "",
            "style": "IPY_MODEL_07a560aa84e94e4f8c35fb561a340df5",
            "value": "103425/103425[00:15&lt;00:00,7920.05examples/s]"
          }
        },
        "f02ae78f2d774fb0bbf1ea2fa28eb93c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5454244f06ff4d56a486a5fbe774d189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c18971f9464a6bb811aa917217b3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cbb7f16c37b4f6781d3799457afd7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88758b866624b49a03a943afb8caf5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55a031c3dc644f20b267f51f769708e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a560aa84e94e4f8c35fb561a340df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}